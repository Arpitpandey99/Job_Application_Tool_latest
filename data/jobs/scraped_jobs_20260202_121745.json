[
  {
    "job_id": "linkedin_data-scientist-at-nielseniq-4324950702",
    "title": "Data Scientist",
    "company": "NielsenIQ",
    "location": "Vadodara, Gujarat, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "Job DescriptionData Scientist  Job Description  The Product Design and Enhancement (PDE) team is responsible for all design-related activities of the Data Science unit at NIQ, setting up the base for Retail Index reporting. The key responsibilities of PDE associate assigned to given market include: Sample Design, Universe Estimation and other design-related projects for the Retail Index Identification of quality risks and follow up on solutions Engagement with stakeholders on scope, execution, data exchange and outcomes for assigned projects Expert-level analysis of results and presentations with insights Teamwork in virtual multi-country environment requiring effective communication with colleagues located in various countries Usage of dedicated software supported by ad hoc programming and data mining Identification of opportunities for innovations and tools development in the dynamic work environment  Qualifications   Essential: Master's degree in Mathematics, Statistics, Economics, Operations Research or related fields Knowledge of Microsoft Office applications Competency in at least one programming language (Python or R) Organizational skills to manage projects (time management, prioritization, deadlines) Ability to engage and communicate effectively  Strong analytical and problem-solving skills Good command of English Eagerness to continuously learn and adapt to changing technologies and tools  Preferable: Work experience in FMCG, Market research, consumer research or similar industries Knowledge of statistical inference and survey-based research    Additional InformationOur BenefitsFlexible working environmentVolunteer time offLinkedIn LearningEmployee-Assistance-Program (EAP)About NIQNIQ is the world\u2019s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights\u2014delivered with advanced analytics through state-of-the-art platforms\u2014NIQ delivers the Full View\u2122. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world\u2019s population.For more information, visit NIQ.comWant to keep up with our latest updates?Follow us on: LinkedIn | Instagram | Twitter | FacebookOur commitment to Diversity, Equity, and InclusionAt NIQ, we are steadfast in our commitment to fostering an inclusive workplace that mirrors the rich diversity of the communities and markets we serve. We believe that embracing a wide range of perspectives drives innovation and excellence.  All employment decisions at NIQ are made without regard to race, color, religion, sex (including pregnancy, sexual orientation, or gender identity), national origin, age, disability, genetic information, marital status, veteran status, or any other characteristic protected by applicable laws. We invite individuals who share our dedication to inclusivity and equity to join us in making a meaningful impact. To learn more about our ongoing efforts in diversity and inclusion, please visit the https://nielseniq.com/global/en/news-center/diversity-inclusion",
    "requirements": "Job DescriptionData Scientist  Job Description  The Product Design and Enhancement (PDE) team is responsible for all design-related activities of the Data Science unit at NIQ, setting up the base for Retail Index reporting. The key responsibilities of PDE associate assigned to given market include: Sample Design, Universe Estimation and other design-related projects for the Retail Index Identification of quality risks and follow up on solutions Engagement with stakeholders on scope, execution, data exchange and outcomes for assigned projects Expert-level analysis of results and presentations with insights Teamwork in virtual multi-country environment requiring effective communication with colleagues located in various countries Usage of dedicated software supported by ad hoc programming and data mining Identification of opportunities for innovations and tools development in the dynamic work environment  Qualifications   Essential: Master's degree in Mathematics, Statistics, Economics, Operations Research or related fields Knowledge of Microsoft Office applications Competency in at least one programming language (Python or R) Organizational skills to manage projects (time management, prioritization, deadlines) Ability to engage and communicate effectively  Strong analytical and problem-solving skills Good command of English Eagerness to continuously learn and adapt to changing technologies and tools  Preferable: Work experience in FMCG, Market research, consumer research or similar industries Knowledge of statistical inference and survey-based research    Additional InformationOur BenefitsFlexible working environmentVolunteer time offLinkedIn LearningEmployee-Assistance-Program (EAP)About NIQNIQ is the world\u2019s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights\u2014delivered with advanced analytics through state-of-the-art platforms\u2014NIQ delivers the Full View\u2122. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world\u2019s population.For more information, visit NIQ.comWant to keep up with our latest updates?Follow us on: LinkedIn | Instagram | Twitter | FacebookOur commitment to Diversity, Equity, and InclusionAt NIQ, we are steadfast in our commitment to fostering an inclusive workplace that mirrors the rich diversity of the communities and markets we serve. We believe that embracing a wide range of perspectives drives innovation and excellence.  All employment decisions at NIQ are made without regard to race, color, religion, sex (including pregnancy, sexual orientation, or gender identity), national origin, age, disability, genetic information, marital status, veteran status, or any other characteristic protected by applicable laws. We invite individuals who share our dedication to inclusivity and equity to join us in making a meaningful impact. To learn more about our ongoing efforts in diversity and inclusion, please visit the https://nielseniq.com/global/en/news-center/diversity-inclusion",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/data-scientist-at-nielseniq-4324950702?position=1&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=h3Wy35EnKUTaa%2BlkEofEUQ%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:12:44.460121"
  },
  {
    "job_id": "linkedin_machine-learning-engineer-t25-at-ebay-4256644747",
    "title": "Machine Learning Engineer (T25)",
    "company": "eBay",
    "location": "Bengaluru, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "At eBay, we're more than a global ecommerce leader \u2014 we\u2019re changing the way the world shops and sells. Our platform empowers millions of buyers and sellers in more than 190 markets around the world. We\u2019re committed to pushing boundaries and leaving our mark as we reinvent the future of ecommerce for enthusiasts.Our customers are our compass, authenticity thrives, bold ideas are welcome, and everyone can bring their unique selves to work \u2014 every day. We're in this together, sustaining the future of our customers, our company, and our planet.Join a team of passionate thinkers, innovators, and dreamers \u2014 and help us connect people and build communities to create economic opportunity for all.Machine Learning Engineer (T25), Product KnowledgeDo you love Big Data? Deploying Machine Learning models? Challenging optimization problems? Knowledgeable, collaborative co-workers? Come work at eBay and help us redefine global, online commerce!Who Are We? The Product Knowledge team is at the epicenter of eBay\u2019s Tech-driven, Customer-centric overhaul. Our team is entrusted with creating and using eBay\u2019s Product Knowledge - a vast Big Data system which is built up of listings, transactions, products, knowledge graphs, and more. Our team has a mix of highly proficient people from multiple fields such as Machine Learning, Data Science, Software Engineering, Operations, and Big Data Analytics. We have a strong culture of collaboration, and plenty of opportunity to learn, make an impact, and grow!What Will You DoWe are looking for exceptional Engineers, who take pride in creating simple solutions to apparently-complex problems. Our Engineering tasks typically involve at least one of the following:Building a pipeline that processes up to billions of items, frequently employing ML models on these datasetsCreating services that provide Search or other Information Retrieval capabilities at low latency on datasets of hundreds of millions of itemsCrafting sound API design and driving integration between our Data layers and Customer-facing applications and componentsDesigning and running A/B tests in Production experiences in order to vet and measure the impact of any new or improved functionality If you love a good challenge, and are good at handling complexity - we\u2019d love to hear from you!eBay is an amazing company to work for. Being on the team, you can expect to benefit from:A competitive salary - including stock grants and a yearly bonusA healthy work culture that promotes business impact and at the same time highly values your personal well-beingBeing part of a force for good in this world - eBay truly cares about its employees, its customers, and the world\u2019s population, and takes every opportunity to make this clearly apparentJob ResponsibilitiesDesign, deliver, and maintain significant features in data pipelines, ML processing, and / or service infrastructureOptimize software performance to achieve the required throughput and / or latencyWork with your manager, peers, and Product Managers to scope projects and featuresCome up with a sound technical strategy, taking into consideration the project goals, timelines, and expected impactTake point on some cross-team efforts, taking ownership of a business problem and ensuring the different teams are in sync and working towards a coherent technical solutionTake active part in knowledge sharing across the organization - both teaching and learning from othersMinimum QualificationsPassion and commitment for technical excellence B.Sc. or M.Sc. in Computer Science or an equivalent professional experience 2+ years of software design and development experience, tackling non-trivial problems in backend services and / or data pipelinesA solid foundation in Data Structures, Algorithms, Object-Oriented Programming, Software Design, and core Statistics knowledgeExperience in production-grade coding in Java, and Python/Scala Experience in the close examination of data and computation of statistics Experience in using and operating Big Data processing pipelines, such as: Hadoop and SparkGood verbal and written communication and collaboration skillsPlease see the Talent Privacy Notice for information regarding how eBay handles your personal data collected when you use the eBay Careers website or apply for a job with eBay.eBay is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you have a need that requires accommodation, please contact us at talent@ebay.com. We will make every effort to respond to your request for accommodation as soon as possible. View our accessibility statement to learn more about eBay's commitment to ensuring digital accessibility for people with disabilities.The eBay Jobs website uses cookies to enhance your experience. By continuing to browse the site, you agree to our use of cookies. Visit our Privacy Center for more information.",
    "requirements": "At eBay, we're more than a global ecommerce leader \u2014 we\u2019re changing the way the world shops and sells. Our platform empowers millions of buyers and sellers in more than 190 markets around the world. We\u2019re committed to pushing boundaries and leaving our mark as we reinvent the future of ecommerce for enthusiasts.Our customers are our compass, authenticity thrives, bold ideas are welcome, and everyone can bring their unique selves to work \u2014 every day. We're in this together, sustaining the future of our customers, our company, and our planet.Join a team of passionate thinkers, innovators, and dreamers \u2014 and help us connect people and build communities to create economic opportunity for all.Machine Learning Engineer (T25), Product KnowledgeDo you love Big Data? Deploying Machine Learning models? Challenging optimization problems? Knowledgeable, collaborative co-workers? Come work at eBay and help us redefine global, online commerce!Who Are We? The Product Knowledge team is at the epicenter of eBay\u2019s Tech-driven, Customer-centric overhaul. Our team is entrusted with creating and using eBay\u2019s Product Knowledge - a vast Big Data system which is built up of listings, transactions, products, knowledge graphs, and more. Our team has a mix of highly proficient people from multiple fields such as Machine Learning, Data Science, Software Engineering, Operations, and Big Data Analytics. We have a strong culture of collaboration, and plenty of opportunity to learn, make an impact, and grow!What Will You DoWe are looking for exceptional Engineers, who take pride in creating simple solutions to apparently-complex problems. Our Engineering tasks typically involve at least one of the following:Building a pipeline that processes up to billions of items, frequently employing ML models on these datasetsCreating services that provide Search or other Information Retrieval capabilities at low latency on datasets of hundreds of millions of itemsCrafting sound API design and driving integration between our Data layers and Customer-facing applications and componentsDesigning and running A/B tests in Production experiences in order to vet and measure the impact of any new or improved functionality If you love a good challenge, and are good at handling complexity - we\u2019d love to hear from you!eBay is an amazing company to work for. Being on the team, you can expect to benefit from:A competitive salary - including stock grants and a yearly bonusA healthy work culture that promotes business impact and at the same time highly values your personal well-beingBeing part of a force for good in this world - eBay truly cares about its employees, its customers, and the world\u2019s population, and takes every opportunity to make this clearly apparentJob ResponsibilitiesDesign, deliver, and maintain significant features in data pipelines, ML processing, and / or service infrastructureOptimize software performance to achieve the required throughput and / or latencyWork with your manager, peers, and Product Managers to scope projects and featuresCome up with a sound technical strategy, taking into consideration the project goals, timelines, and expected impactTake point on some cross-team efforts, taking ownership of a business problem and ensuring the different teams are in sync and working towards a coherent technical solutionTake active part in knowledge sharing across the organization - both teaching and learning from othersMinimum QualificationsPassion and commitment for technical excellence B.Sc. or M.Sc. in Computer Science or an equivalent professional experience 2+ years of software design and development experience, tackling non-trivial problems in backend services and / or data pipelinesA solid foundation in Data Structures, Algorithms, Object-Oriented Programming, Software Design, and core Statistics knowledgeExperience in production-grade coding in Java, and Python/Scala Experience in the close examination of data and computation of statistics Experience in using and operating Big Data processing pipelines, such as: Hadoop and SparkGood verbal and written communication and collaboration skillsPlease see the Talent Privacy Notice for information regarding how eBay handles your personal data collected when you use the eBay Careers website or apply for a job with eBay.eBay is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you have a need that requires accommodation, please contact us at talent@ebay.com. We will make every effort to respond to your request for accommodation as soon as possible. View our accessibility statement to learn more about eBay's commitment to ensuring digital accessibility for people with disabilities.The eBay Jobs website uses cookies to enhance your experience. By continuing to browse the site, you agree to our use of cookies. Visit our Privacy Center for more information.",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/machine-learning-engineer-t25-at-ebay-4256644747?position=2&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=PYfTMj0Vbh4xE7jvmqMwfg%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:12:48.281180"
  },
  {
    "job_id": "linkedin_data-scientist-at-procdna-4367966724",
    "title": "Data Scientist",
    "company": "ProcDNA",
    "location": "Pune, Maharashtra, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "Job OverviewAs a Data Scientist, you will play a key role in delivering end-to-end data science solutions across pharmaceutical and healthcare engagements. The role demands a blend of technical depth, business acumen, and scientific curiosity. You will translate complex business problems into analytical frameworks, develop scalable machine learning and statistical solutions, and generate actionable insights that drive commercial, clinical, and operational impact for clients and patients worldwide. Beyond technical execution, you are expected to think strategically, framing business challenges, designing analytical approaches, and guiding clients toward the most effective data-driven decisions.Key ResponsibilitiesOwn day-to-day execution of data science projects from problem definition to deployment, ensuring methodological rigor, business relevance, and timely delivery.Build, tune, and validate advanced machine learning and statistical models, including supervised techniques (classification, regression, uplift), unsupervised methods (clustering, PCA, GMM), transformer models, and analytical frameworks (hypothesis testing, causal inference, survival analysis) using industry-standard librariesDevelop clean, modular, and production-ready code with reusable components, adhering to best practices in version control, documentation, and scalable pipeline design for deployment in production or client-facing environmentsSynthesize insights from diverse data sources, including claims, prescription (LAAD), lab, EMR, and unstructured text, into clear narratives driving client decisions tailored to patient, HCP, and market contextsCollaborate with consultants, domain experts, and engineers to structure analytical workflows that answer complex commercial or clinical questions.Present findings and insights to internal and client stakeholders in a clear, structured, and actionable manner.Actively participate in client discussions, supporting solution development and storyboarding for business audiencesContribute to internal capability building through reusable ML assets, accelerators, and documentation to strengthen the team\u2019s solution portfolio.Required SkillsStrong hands-on experience in Python, PySpark, and SQL for manipulating and handling large structured and unstructured datasets.Strong foundation in machine learning algorithms, feature engineering, model tuning, and evaluation techniquesProficiency in data visualization (Power BI, Tableau, MS Office suite or equivalent) and in translating analytical results effectively.Ability to structure ambiguous business problems, design analytical roadmaps, and communicate insights effectively to both technical and non-technical stakeholders.Strong collaboration and project-management skills for coordinating across multi-disciplinary teams.Preferred SkillsPrior experience in the pharmaceutical or life sciences industry, with familiarity across structured data sources such as LAAD, Lab, Sales, and unstructured datasets (e.g., market research, physician notes, publications).Experience with R, Rshiny, and data platforms such as Databricks, AWS, Azure, or Snowflake is an advantage.Exposure to MLOps frameworks, including MLflow, Docker, Airflow, or CI/CD pipelines, to automate model training, deployment, and monitoring in scalable production environments.Experience mentoring junior analysts or collaborating in cross-functional data science teams.QualificationsBachelor\u2019s or master\u2019s degree in computer science, Statistics, Mathematics, Data Science, or related fields.1-6 years of professional experience in data science, analytics, or advanced modeling rolesProven ability to balance analytical rigor with business understanding, delivering models that are explainable, actionable, and production-ready",
    "requirements": "Job OverviewAs a Data Scientist, you will play a key role in delivering end-to-end data science solutions across pharmaceutical and healthcare engagements. The role demands a blend of technical depth, business acumen, and scientific curiosity. You will translate complex business problems into analytical frameworks, develop scalable machine learning and statistical solutions, and generate actionable insights that drive commercial, clinical, and operational impact for clients and patients worldwide. Beyond technical execution, you are expected to think strategically, framing business challenges, designing analytical approaches, and guiding clients toward the most effective data-driven decisions.Key ResponsibilitiesOwn day-to-day execution of data science projects from problem definition to deployment, ensuring methodological rigor, business relevance, and timely delivery.Build, tune, and validate advanced machine learning and statistical models, including supervised techniques (classification, regression, uplift), unsupervised methods (clustering, PCA, GMM), transformer models, and analytical frameworks (hypothesis testing, causal inference, survival analysis) using industry-standard librariesDevelop clean, modular, and production-ready code with reusable components, adhering to best practices in version control, documentation, and scalable pipeline design for deployment in production or client-facing environmentsSynthesize insights from diverse data sources, including claims, prescription (LAAD), lab, EMR, and unstructured text, into clear narratives driving client decisions tailored to patient, HCP, and market contextsCollaborate with consultants, domain experts, and engineers to structure analytical workflows that answer complex commercial or clinical questions.Present findings and insights to internal and client stakeholders in a clear, structured, and actionable manner.Actively participate in client discussions, supporting solution development and storyboarding for business audiencesContribute to internal capability building through reusable ML assets, accelerators, and documentation to strengthen the team\u2019s solution portfolio.Required SkillsStrong hands-on experience in Python, PySpark, and SQL for manipulating and handling large structured and unstructured datasets.Strong foundation in machine learning algorithms, feature engineering, model tuning, and evaluation techniquesProficiency in data visualization (Power BI, Tableau, MS Office suite or equivalent) and in translating analytical results effectively.Ability to structure ambiguous business problems, design analytical roadmaps, and communicate insights effectively to both technical and non-technical stakeholders.Strong collaboration and project-management skills for coordinating across multi-disciplinary teams.Preferred SkillsPrior experience in the pharmaceutical or life sciences industry, with familiarity across structured data sources such as LAAD, Lab, Sales, and unstructured datasets (e.g., market research, physician notes, publications).Experience with R, Rshiny, and data platforms such as Databricks, AWS, Azure, or Snowflake is an advantage.Exposure to MLOps frameworks, including MLflow, Docker, Airflow, or CI/CD pipelines, to automate model training, deployment, and monitoring in scalable production environments.Experience mentoring junior analysts or collaborating in cross-functional data science teams.QualificationsBachelor\u2019s or master\u2019s degree in computer science, Statistics, Mathematics, Data Science, or related fields.1-6 years of professional experience in data science, analytics, or advanced modeling rolesProven ability to balance analytical rigor with business understanding, delivering models that are explainable, actionable, and production-ready",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/data-scientist-at-procdna-4367966724?position=3&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=5gBl%2BXUDM3tN%2Fp6%2BACw4RQ%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:12:52.096946"
  },
  {
    "job_id": "linkedin_machine-learning-engineer-bangalore-at-hyrezy-tech-solutions-4367793648",
    "title": "Machine Learning Engineer - Bangalore",
    "company": "HYrEzy Tech Solutions",
    "location": "Bengaluru, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "Machine Learning EngineerLocation: Bangalore (Work from Office)Type: Full-timeExperience: 0 - 4 YearsAbout The CompanyWe are the #1 Carbon Accounting Platform for Industrial Manufacturing, dedicated to transforming how heavy industries (like Steel, Cement, and Utilities) manage their environmental footprint. Our AI-driven SaaS platform helps global industrial leaders measure, report, and reduce their carbon emissions across the entire value chain.Founded by industry veterans from McKinsey, our mission is to solve the $1-2 trillion climate crisis by turning complex operational data into actionable sustainability roadmaps. Backed by top-tier investors like Avaana Capital and RPG Ventures, we are a fast-growing, product-led team building the digital backbone for global industrial sustainability.The RoleAs a Machine Learning Engineer, you will be at the heart of our mission, building the models that predict emissions, identify reduction levers, and automate complex industrial data analysis. Whether you are a fresh graduate from the 2024-25 batch or an experienced professional with up to 4 years of tenure, you will have the opportunity to build foundational AI solutions with real-world environmental impact.Key ResponsibilitiesModel Development: Design, train, and deploy machine learning models to analyze complex industrial datasets and predict carbon intensity. Data Engineering: Build and optimize data pipelines to handle large-scale, high-velocity data from global industrial manufacturing sites. Feature Engineering: Extract meaningful features from raw operational and supply chain data to improve model accuracy and interpretability. Deployment & Monitoring: Integrate ML models into our cloud-native platform (AWS/Azure) and monitor their performance in real-world production environments. Research & Innovation: Stay at the forefront of AI/ML research, particularly in areas like Time-Series forecasting, NLP for sustainability reporting, and industrial process optimization. Required QualificationsEducation: Degree in Computer Science, AI/ML, Data Science, or a related Engineering field. 2024 or 2025 pass-outs are highly encouraged to apply. Experience: 0 - 4 years of experience. For freshers, prior internship experience in AI/ML or Data Science is mandatory. Technical Foundation: Strong proficiency in Python and its ML ecosystem (Scikit-learn, TensorFlow, PyTorch, Pandas). Analytical Mindset: Deep understanding of linear algebra, probability, and statistical modeling. Cloud & Tools: Familiarity with AWS (preferred) or Azure and experience with SQL databases (PostgreSQL/MySQL). Soft Skills: Ability to translate technical findings into clear insights for product and business teams. Compensation & Benefits0 - 1 Year Experience (2024-25 Batch): Up to \u20b915,00,000 (15 LPA) Total Cash Compensation (includes a 10% Variable component). 2 - 4 Years Experience: Up to \u20b940,00,000 (40 LPA) Total Cash Compensation. Impact: Work on solutions that directly address global climate change. Culture: High-performance, collaborative startup environment with mentorship from world-class industry experts. Skills: rags,agentic ai,ml,machine learning,aws,mlops,learning,generative ai,llm",
    "requirements": "Machine Learning EngineerLocation: Bangalore (Work from Office)Type: Full-timeExperience: 0 - 4 YearsAbout The CompanyWe are the #1 Carbon Accounting Platform for Industrial Manufacturing, dedicated to transforming how heavy industries (like Steel, Cement, and Utilities) manage their environmental footprint. Our AI-driven SaaS platform helps global industrial leaders measure, report, and reduce their carbon emissions across the entire value chain.Founded by industry veterans from McKinsey, our mission is to solve the $1-2 trillion climate crisis by turning complex operational data into actionable sustainability roadmaps. Backed by top-tier investors like Avaana Capital and RPG Ventures, we are a fast-growing, product-led team building the digital backbone for global industrial sustainability.The RoleAs a Machine Learning Engineer, you will be at the heart of our mission, building the models that predict emissions, identify reduction levers, and automate complex industrial data analysis. Whether you are a fresh graduate from the 2024-25 batch or an experienced professional with up to 4 years of tenure, you will have the opportunity to build foundational AI solutions with real-world environmental impact.Key ResponsibilitiesModel Development: Design, train, and deploy machine learning models to analyze complex industrial datasets and predict carbon intensity. Data Engineering: Build and optimize data pipelines to handle large-scale, high-velocity data from global industrial manufacturing sites. Feature Engineering: Extract meaningful features from raw operational and supply chain data to improve model accuracy and interpretability. Deployment & Monitoring: Integrate ML models into our cloud-native platform (AWS/Azure) and monitor their performance in real-world production environments. Research & Innovation: Stay at the forefront of AI/ML research, particularly in areas like Time-Series forecasting, NLP for sustainability reporting, and industrial process optimization. Required QualificationsEducation: Degree in Computer Science, AI/ML, Data Science, or a related Engineering field. 2024 or 2025 pass-outs are highly encouraged to apply. Experience: 0 - 4 years of experience. For freshers, prior internship experience in AI/ML or Data Science is mandatory. Technical Foundation: Strong proficiency in Python and its ML ecosystem (Scikit-learn, TensorFlow, PyTorch, Pandas). Analytical Mindset: Deep understanding of linear algebra, probability, and statistical modeling. Cloud & Tools: Familiarity with AWS (preferred) or Azure and experience with SQL databases (PostgreSQL/MySQL). Soft Skills: Ability to translate technical findings into clear insights for product and business teams. Compensation & Benefits0 - 1 Year Experience (2024-25 Batch): Up to \u20b915,00,000 (15 LPA) Total Cash Compensation (includes a 10% Variable component). 2 - 4 Years Experience: Up to \u20b940,00,000 (40 LPA) Total Cash Compensation. Impact: Work on solutions that directly address global climate change. Culture: High-performance, collaborative startup environment with mentorship from world-class industry experts. Skills: rags,agentic ai,ml,machine learning,aws,mlops,learning,generative ai,llm",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/machine-learning-engineer-bangalore-at-hyrezy-tech-solutions-4367793648?position=4&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=ILm2EySoUJFFJJWghJ1Itw%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:12:55.413947"
  },
  {
    "job_id": "linkedin_data-engineer-python-associate-software-engineer-at-morgan-stanley-4359474410",
    "title": "Data Engineer Python- Associate- Software Engineer",
    "company": "Morgan Stanley",
    "location": "Bengaluru, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "Data Engineer Python - Associate- Software EngineeringWe\u2019re seeking someone to join our Institutional Securities Technology team as a Data Engineer Python, in Prime Brokerage AND Institutional Equity . The Prime Brokerage Technology team works very closely with the business to provide cutting-edge technology, expertise and products to the business. MSPB Client Reporting Technology is currently working on modernizing client reporting platform. The work provides high visibility and opportunities to learn the business. To this end, we are in the process of recruiting a highly motivated and talented data engineer developer. Responsibilities include requirements analysis, implementing quick reporting solutions with on-going renovation reporting platform applications, validation of data, user & job support. We expect the candidate to have an interest in the financial business. This is a great opportunity for learning about a high growth, industry leading business, while fully utilizing your database and reporting technology programming skills.In the Technology division, we leverage innovation to build the connections and capabilities that power our Firm, enabling our clients and colleagues to redefine markets and shape the future of our communities.This is Associate position that develops and maintains software solutions that support business needs.Since 1935, Morgan Stanley is known as a global leader in financial services, always evolving and innovating to better serve our clients and our communities in more than 40 countries around the world.What You\u2019ll Do In The Role Working with business users to understand requirements, analyze them in detail and write clear specs and convert them into technical design Implementing data and reporting solutions Enhancing existing solutions to meet new requirements Addressing ad-hoc requests by leveraging existing tools and infrastructure or implementing Investigate, resolve and provide feed-back on data-quality issues Providing L3 production supportWhat You\u2019ll Bring To The Role Experience in development of reporting systems Knowledge in one or all of theseRelational Databases (Sybase, DB2, Snowflake) (Mandatory)PL/SQL and Stored Procedures (Mandatory) Python (Mandatory) Java (Optional) Analytical, debugging and problem-solving skills Team player; highly motivated; excellent communication skills Years of experience 3-5 yearsWhat You Can Expect From Morgan StanleyWe are committed to maintaining the first-class service and high standard of excellence that have defined Morgan Stanley for over 89 years. Our values - putting clients first, doing the right thing, leading with exceptional ideas, committing to diversity and inclusion, and giving back - aren\u2019t just beliefs, they guide the decisions we make every day to do what's best for our clients, communities and more than 80,000 employees in 1,200 offices across 42 countries. At Morgan Stanley, you\u2019ll find an opportunity to work alongside the best and the brightest, in an environment where you are supported and empowered. Our teams are relentless collaborators and creative thinkers, fueled by their diverse backgrounds and experiences. We are proud to support our employees and their families at every point along their work-life journey, offering some of the most attractive and comprehensive employee benefits and perks in the industry. There\u2019s also ample opportunity to move about the business for those who show passion and grit in their work.To learn more about our offices across the globe, please copy and paste https://www.morganstanley.com/about-us/global-offices into your browser.Morgan Stanley is an equal opportunities employer. We work to provide a supportive and inclusive environment where all individuals can maximize their full potential. Our skilled and creative workforce is comprised of individuals drawn from a broad cross section of the global communities in which we operate and who reflect a variety of backgrounds, talents, perspectives, and experiences. Our strong commitment to a culture of inclusion is evident through our constant focus on recruiting, developing, and advancing individuals based on their skills and talents.",
    "requirements": "Data Engineer Python - Associate- Software EngineeringWe\u2019re seeking someone to join our Institutional Securities Technology team as a Data Engineer Python, in Prime Brokerage AND Institutional Equity . The Prime Brokerage Technology team works very closely with the business to provide cutting-edge technology, expertise and products to the business. MSPB Client Reporting Technology is currently working on modernizing client reporting platform. The work provides high visibility and opportunities to learn the business. To this end, we are in the process of recruiting a highly motivated and talented data engineer developer. Responsibilities include requirements analysis, implementing quick reporting solutions with on-going renovation reporting platform applications, validation of data, user & job support. We expect the candidate to have an interest in the financial business. This is a great opportunity for learning about a high growth, industry leading business, while fully utilizing your database and reporting technology programming skills.In the Technology division, we leverage innovation to build the connections and capabilities that power our Firm, enabling our clients and colleagues to redefine markets and shape the future of our communities.This is Associate position that develops and maintains software solutions that support business needs.Since 1935, Morgan Stanley is known as a global leader in financial services, always evolving and innovating to better serve our clients and our communities in more than 40 countries around the world.What You\u2019ll Do In The Role Working with business users to understand requirements, analyze them in detail and write clear specs and convert them into technical design Implementing data and reporting solutions Enhancing existing solutions to meet new requirements Addressing ad-hoc requests by leveraging existing tools and infrastructure or implementing Investigate, resolve and provide feed-back on data-quality issues Providing L3 production supportWhat You\u2019ll Bring To The Role Experience in development of reporting systems Knowledge in one or all of theseRelational Databases (Sybase, DB2, Snowflake) (Mandatory)PL/SQL and Stored Procedures (Mandatory) Python (Mandatory) Java (Optional) Analytical, debugging and problem-solving skills Team player; highly motivated; excellent communication skills Years of experience 3-5 yearsWhat You Can Expect From Morgan StanleyWe are committed to maintaining the first-class service and high standard of excellence that have defined Morgan Stanley for over 89 years. Our values - putting clients first, doing the right thing, leading with exceptional ideas, committing to diversity and inclusion, and giving back - aren\u2019t just beliefs, they guide the decisions we make every day to do what's best for our clients, communities and more than 80,000 employees in 1,200 offices across 42 countries. At Morgan Stanley, you\u2019ll find an opportunity to work alongside the best and the brightest, in an environment where you are supported and empowered. Our teams are relentless collaborators and creative thinkers, fueled by their diverse backgrounds and experiences. We are proud to support our employees and their families at every point along their work-life journey, offering some of the most attractive and comprehensive employee benefits and perks in the industry. There\u2019s also ample opportunity to move about the business for those who show passion and grit in their work.To learn more about our offices across the globe, please copy and paste https://www.morganstanley.com/about-us/global-offices into your browser.Morgan Stanley is an equal opportunities employer. We work to provide a supportive and inclusive environment where all individuals can maximize their full potential. Our skilled and creative workforce is comprised of individuals drawn from a broad cross section of the global communities in which we operate and who reflect a variety of backgrounds, talents, perspectives, and experiences. Our strong commitment to a culture of inclusion is evident through our constant focus on recruiting, developing, and advancing individuals based on their skills and talents.",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/data-engineer-python-associate-software-engineer-at-morgan-stanley-4359474410?position=5&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=nFkutC%2BJwNXFqxUlEVt0MQ%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:12:58.990883"
  },
  {
    "job_id": "linkedin_python%2B-gen-ai-lead-at-infosys-4351852503",
    "title": "Python+ Gen AI Lead",
    "company": "Infosys",
    "location": "Bengaluru East, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "Primary skills:Technology->Machine Learning->PythonA day in the life of an Infoscion As part of the Infosys delivery team, your primary role would be to interface with the client for quality assurance, issue resolution and ensuring high customer satisfaction. You will understand requirements, create and review designs, validate the architecture and ensure high levels of service offerings to clients in the technology domain. You will participate in project estimation, provide inputs for solution delivery, conduct technical risk planning, perform code reviews and unit test plan reviews. You will lead and guide your teams towards developing optimized high quality code deliverables, continual knowledge management and adherence to the organizational guidelines and processes. You would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! Knowledge of more than one technology Basics of Architecture and Design fundamentals Knowledge of Testing tools Knowledge of agile methodologies Understanding of Project life cycle activities on development and maintenance projects Understanding of one or more Estimation methodologies, Knowledge of Quality processes Basics of business domain to understand the business requirements Analytical abilities, Strong Technical Skills, Good communication skills Good understanding of the technology and domain Ability to demonstrate a sound understanding of software quality assurance principles, SOLID design principles and modelling methods Awareness of latest technologies and trends Excellent problem solving, analytical and debugging skills",
    "requirements": "Primary skills:Technology->Machine Learning->PythonA day in the life of an Infoscion As part of the Infosys delivery team, your primary role would be to interface with the client for quality assurance, issue resolution and ensuring high customer satisfaction. You will understand requirements, create and review designs, validate the architecture and ensure high levels of service offerings to clients in the technology domain. You will participate in project estimation, provide inputs for solution delivery, conduct technical risk planning, perform code reviews and unit test plan reviews. You will lead and guide your teams towards developing optimized high quality code deliverables, continual knowledge management and adherence to the organizational guidelines and processes. You would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! Knowledge of more than one technology Basics of Architecture and Design fundamentals Knowledge of Testing tools Knowledge of agile methodologies Understanding of Project life cycle activities on development and maintenance projects Understanding of one or more Estimation methodologies, Knowledge of Quality processes Basics of business domain to understand the business requirements Analytical abilities, Strong Technical Skills, Good communication skills Good understanding of the technology and domain Ability to demonstrate a sound understanding of software quality assurance principles, SOLID design principles and modelling methods Awareness of latest technologies and trends Excellent problem solving, analytical and debugging skills",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/python%2B-gen-ai-lead-at-infosys-4351852503?position=6&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=mR0%2Bfa%2F%2F8gnBX4Q3YJbg%2Fg%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:13:02.495785"
  },
  {
    "job_id": "linkedin_machine-learning-engineer-at-vayuz-technologies-4357411078",
    "title": "Machine Learning Engineer",
    "company": "VAYUZ Technologies",
    "location": "Bengaluru, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "Responsibilities\u25cf Design and develop machine learning models and algorithms for real-world applications.\u25cf Conduct experiments, evaluate results, and continuously optimize model performance.\u25cf Collaborate with data scientists and backend engineers to preprocess, clean, and structure data.\u25cf Build, maintain, and enhance robust ML pipelines and production-grade systems.\u25cf Deploy models into production environments and ensure scalability, reliability, and low latency.\u25cf Monitor production systems, identify bottlenecks, and proactively resolve performance issues.\u25cf Work with task management and messaging systems like Redis, RabbitMQ, and Celery.\u25cf Implement basic CI/CD practices for ML models and pipelines.\u25cf Use containerization tools like Docker to streamline deployment and testing.Qualifications:\u25cf Proficiency in programming languages, especially Python.\u25cf Strong experience with relational databases such as MSSQL.\u25cf Hands-on experience with Redis, RabbitMQ, Celery, or similar tools.\u25cf Working knowledge of Docker and containerized environments.\u25cf Good understanding of CI/CD principles and practices for ML workflows.\u25cf Familiarity with machine learning frameworks such as TensorFlow, PyTorch, or equivalent.\u25cf Solid foundational knowledge of statistics, algorithms, and data science concepts.\u25cf Ability to troubleshoot complex system issues and optimize system performance.\u25cf Strong problem-solving skills, attention to detail, and ability to work collaboratively.",
    "requirements": "Responsibilities\u25cf Design and develop machine learning models and algorithms for real-world applications.\u25cf Conduct experiments, evaluate results, and continuously optimize model performance.\u25cf Collaborate with data scientists and backend engineers to preprocess, clean, and structure data.\u25cf Build, maintain, and enhance robust ML pipelines and production-grade systems.\u25cf Deploy models into production environments and ensure scalability, reliability, and low latency.\u25cf Monitor production systems, identify bottlenecks, and proactively resolve performance issues.\u25cf Work with task management and messaging systems like Redis, RabbitMQ, and Celery.\u25cf Implement basic CI/CD practices for ML models and pipelines.\u25cf Use containerization tools like Docker to streamline deployment and testing.Qualifications:\u25cf Proficiency in programming languages, especially Python.\u25cf Strong experience with relational databases such as MSSQL.\u25cf Hands-on experience with Redis, RabbitMQ, Celery, or similar tools.\u25cf Working knowledge of Docker and containerized environments.\u25cf Good understanding of CI/CD principles and practices for ML workflows.\u25cf Familiarity with machine learning frameworks such as TensorFlow, PyTorch, or equivalent.\u25cf Solid foundational knowledge of statistics, algorithms, and data science concepts.\u25cf Ability to troubleshoot complex system issues and optimize system performance.\u25cf Strong problem-solving skills, attention to detail, and ability to work collaboratively.",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/machine-learning-engineer-at-vayuz-technologies-4357411078?position=7&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=oBFFCC0ekDs%2BfOON%2BU8SKQ%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:13:06.276237"
  },
  {
    "job_id": "linkedin_data-science-intern-at-bnp-paribas-4368135668",
    "title": "Data Science Intern",
    "company": "BNP Paribas",
    "location": "Mumbai, Maharashtra, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "About BNP Paribas India SolutionsEstablished in 2005, BNP Paribas India Solutions is a wholly owned subsidiary of BNP Paribas SA, European Union\u2019s leading bank with an international reach. With delivery centers located in Bengaluru, Chennai and Mumbai, we are a 24x7 global delivery center. India Solutions services three business lines: Corporate and Institutional Banking, Investment Solutions and Retail Banking for BNP Paribas across the Group. Driving innovation and growth, we are harnessing the potential of over 10000 employees, to provide support and develop best-in-class solutions.About BNP Paribas GroupBNP Paribas is the European Union\u2019s leading bank and key player in international banking. It operates in 65 countries and has nearly 185,000 employees, including more than 145,000 in Europe. The Group has key positions in its three main fields of activity: Commercial, Personal Banking & Services for the Group\u2019s commercial & personal banking and several specialised businesses including BNP Paribas Personal Finance and Arval; Investment & Protection Services for savings, investment, and protection solutions; and Corporate & Institutional Banking, focused on corporate and institutional clients. Based on its strong diversified and integrated model, the Group helps all its clients (individuals, community associations, entrepreneurs, SMEs, corporates and institutional clients) to realize their projects through solutions spanning financing, investment, savings and protection insurance. In Europe, BNP Paribas has four domestic markets: Belgium, France, Italy, and Luxembourg. The Group is rolling out its integrated commercial & personal banking model across several Mediterranean countries, Turkey, and Eastern Europe. As a key player in international banking, the Group has leading platforms and business lines in Europe, a strong presence in the Americas as well as a solid and fast-growing business in Asia-Pacific. BNP Paribas has implemented a Corporate Social Responsibility approach in all its activities, enabling it to contribute to the construction of a sustainable future, while ensuring the Group's performance and stabilityCommitment to Diversity and InclusionAt BNP Paribas, we passionately embrace diversity and are committed to fostering an inclusive workplace where all employees are valued, respected and can bring their authentic selves to work. We prohibit Discrimination and Harassment of any kind and our policies promote equal employment opportunity for all employees and applicants, irrespective of, but not limited to their gender, gender identity, sex, sexual orientation, ethnicity, race, colour, national origin, age, religion, social status, mental or physical disabilities, veteran status etc. As a global Bank, we truly believe that inclusion and diversity of our teams is key to our success in serving our clients and the communities we operate in.About Business Line/FunctionGlobal Markets is currently recruiting talented people to join one of the most challenging and exciting part of our Quantitative Research team, the Data and Artificial Intelligence Lab!We are currently recruiting interns (in Mumbai) for the Global Market Data and Artificial Intelligence Lab of BNP Paribas: Global Market is part of the Corporate and Investment Bank and deals with all market activities on Equity, Foreign Exchange and Local Markets, G10 Rates, Primary and Secondary Credit and Financing asset classes.The Lab mission is to leverage the latest techniques of Machine Learning (Deep Learning, Natural Language Processing) on the vast amount of structured and un-structured data we are collecting while doing our business as well as any other public source of information.Position PurposeWe are, among other things, building models to improve the service we give to our clients (issuing recommendation, anticipating their needs, bringing the relevant research\u2026), to help traders better understanding and managing their risks or leverage alternative data sources (social media, news, images\u2026) for the benefit of our strategists.We are looking for candidates with education in data science, who not only have experience in solving complex problems but as well understand how and why the model work the way they do.They need to be motivated with dealing with large amount of very diverse data and extracting valuable insights out of it.The right candidate needs to be able to adapt quickly to new challenges, not to be afraid to experiment many times and fail before finding the right solution, challenge themselves with the feedback of the users and they will have the excitement of seeing their work being used in real live by the business.For Internships, We Are Looking At Duration Of 6 Months And We Are Flexible On The Starting Date (the Earlier The Better!). The Intern Will Participate To The Life Of The LAB And Will Take Ownership Of One Or More Topic. We Have a Great Variety Of Topics, And Some Of The Historical Propositions Included Prediction of which products are the most likely to be interesting for a given client. Automated Generation of Market Comment. Optimal Risk Management of Interest Rates Swap Risk. Regime disentanglement for financial mixture of experts models. Generative modelling for model control. Transformers for quantitative investment strategies.Based on the skillset & business need, we can select a valuable proposition for you!ResponsibilitiesDirect Responsibilities Explore and examine data from multiple diverse data sources. Conceptual modeling, statistical analysis, predictive modeling and optimization design. Data cleanup, normalization and transformation. Hypothesis testing: being able to develop hypothesis and test with careful experiments.Contributing Responsibilities Help build workflows for extraction, transformation and loading of different data from a variety of sources and enable linking them to existing systems and datasets. Ensure the integrity and security of data.Technical & Behavioral Competencies Education in data science, who not only have experience in solving complex problems but as well understand how and why the model work the way they do. Knowledge of key concepts in Statistics and Mathematics such as Probability Theory, Inference, and Linear Algebra. Knowledge or experience in Machine Learning procedures and tasks such as Classification, Prediction, and Clustering. Programming skills\u202fin Python\u202fand knowledge of common numerical and machine-learning packages (NumPy,\u202fscikit-learn, pandas,\u202fKeras, TensorFlow,\u202fPyTorch, langchain). Ability to write clear and concise code in python. Intellectually curious and willing to learn challenging concepts daily. Involvement with the Data Science community through platforms such as Kaggle, Numerai, Open ML, or others. Knowledge of current Machine Learning/Artificial Intelligence literature.Skills ReferentialBehavioural Skills:Ability to collaborate / TeamworkCritical thinkingCommunication skills - oral & writtenAttention to detail / rigorTransversal SkillsAnalytical AbilityEducation Level: Bachelor\u2019s Degree or Master\u2019s Degree or equivalentExperience Level: Beginner",
    "requirements": "About BNP Paribas India SolutionsEstablished in 2005, BNP Paribas India Solutions is a wholly owned subsidiary of BNP Paribas SA, European Union\u2019s leading bank with an international reach. With delivery centers located in Bengaluru, Chennai and Mumbai, we are a 24x7 global delivery center. India Solutions services three business lines: Corporate and Institutional Banking, Investment Solutions and Retail Banking for BNP Paribas across the Group. Driving innovation and growth, we are harnessing the potential of over 10000 employees, to provide support and develop best-in-class solutions.About BNP Paribas GroupBNP Paribas is the European Union\u2019s leading bank and key player in international banking. It operates in 65 countries and has nearly 185,000 employees, including more than 145,000 in Europe. The Group has key positions in its three main fields of activity: Commercial, Personal Banking & Services for the Group\u2019s commercial & personal banking and several specialised businesses including BNP Paribas Personal Finance and Arval; Investment & Protection Services for savings, investment, and protection solutions; and Corporate & Institutional Banking, focused on corporate and institutional clients. Based on its strong diversified and integrated model, the Group helps all its clients (individuals, community associations, entrepreneurs, SMEs, corporates and institutional clients) to realize their projects through solutions spanning financing, investment, savings and protection insurance. In Europe, BNP Paribas has four domestic markets: Belgium, France, Italy, and Luxembourg. The Group is rolling out its integrated commercial & personal banking model across several Mediterranean countries, Turkey, and Eastern Europe. As a key player in international banking, the Group has leading platforms and business lines in Europe, a strong presence in the Americas as well as a solid and fast-growing business in Asia-Pacific. BNP Paribas has implemented a Corporate Social Responsibility approach in all its activities, enabling it to contribute to the construction of a sustainable future, while ensuring the Group's performance and stabilityCommitment to Diversity and InclusionAt BNP Paribas, we passionately embrace diversity and are committed to fostering an inclusive workplace where all employees are valued, respected and can bring their authentic selves to work. We prohibit Discrimination and Harassment of any kind and our policies promote equal employment opportunity for all employees and applicants, irrespective of, but not limited to their gender, gender identity, sex, sexual orientation, ethnicity, race, colour, national origin, age, religion, social status, mental or physical disabilities, veteran status etc. As a global Bank, we truly believe that inclusion and diversity of our teams is key to our success in serving our clients and the communities we operate in.About Business Line/FunctionGlobal Markets is currently recruiting talented people to join one of the most challenging and exciting part of our Quantitative Research team, the Data and Artificial Intelligence Lab!We are currently recruiting interns (in Mumbai) for the Global Market Data and Artificial Intelligence Lab of BNP Paribas: Global Market is part of the Corporate and Investment Bank and deals with all market activities on Equity, Foreign Exchange and Local Markets, G10 Rates, Primary and Secondary Credit and Financing asset classes.The Lab mission is to leverage the latest techniques of Machine Learning (Deep Learning, Natural Language Processing) on the vast amount of structured and un-structured data we are collecting while doing our business as well as any other public source of information.Position PurposeWe are, among other things, building models to improve the service we give to our clients (issuing recommendation, anticipating their needs, bringing the relevant research\u2026), to help traders better understanding and managing their risks or leverage alternative data sources (social media, news, images\u2026) for the benefit of our strategists.We are looking for candidates with education in data science, who not only have experience in solving complex problems but as well understand how and why the model work the way they do.They need to be motivated with dealing with large amount of very diverse data and extracting valuable insights out of it.The right candidate needs to be able to adapt quickly to new challenges, not to be afraid to experiment many times and fail before finding the right solution, challenge themselves with the feedback of the users and they will have the excitement of seeing their work being used in real live by the business.For Internships, We Are Looking At Duration Of 6 Months And We Are Flexible On The Starting Date (the Earlier The Better!). The Intern Will Participate To The Life Of The LAB And Will Take Ownership Of One Or More Topic. We Have a Great Variety Of Topics, And Some Of The Historical Propositions Included Prediction of which products are the most likely to be interesting for a given client. Automated Generation of Market Comment. Optimal Risk Management of Interest Rates Swap Risk. Regime disentanglement for financial mixture of experts models. Generative modelling for model control. Transformers for quantitative investment strategies.Based on the skillset & business need, we can select a valuable proposition for you!ResponsibilitiesDirect Responsibilities Explore and examine data from multiple diverse data sources. Conceptual modeling, statistical analysis, predictive modeling and optimization design. Data cleanup, normalization and transformation. Hypothesis testing: being able to develop hypothesis and test with careful experiments.Contributing Responsibilities Help build workflows for extraction, transformation and loading of different data from a variety of sources and enable linking them to existing systems and datasets. Ensure the integrity and security of data.Technical & Behavioral Competencies Education in data science, who not only have experience in solving complex problems but as well understand how and why the model work the way they do. Knowledge of key concepts in Statistics and Mathematics such as Probability Theory, Inference, and Linear Algebra. Knowledge or experience in Machine Learning procedures and tasks such as Classification, Prediction, and Clustering. Programming skills\u202fin Python\u202fand knowledge of common numerical and machine-learning packages (NumPy,\u202fscikit-learn, pandas,\u202fKeras, TensorFlow,\u202fPyTorch, langchain). Ability to write clear and concise code in python. Intellectually curious and willing to learn challenging concepts daily. Involvement with the Data Science community through platforms such as Kaggle, Numerai, Open ML, or others. Knowledge of current Machine Learning/Artificial Intelligence literature.Skills ReferentialBehavioural Skills:Ability to collaborate / TeamworkCritical thinkingCommunication skills - oral & writtenAttention to detail / rigorTransversal SkillsAnalytical AbilityEducation Level: Bachelor\u2019s Degree or Master\u2019s Degree or equivalentExperience Level: Beginner",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/data-science-intern-at-bnp-paribas-4368135668?position=8&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=U3jef4lzoiYYLI8SXzb3iQ%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:13:10.396792"
  },
  {
    "job_id": "linkedin_generative-ai-ai-ml-python-databricks-at-infosys-4367787291",
    "title": "Generative AI, AI/ML, Python, Databricks",
    "company": "Infosys",
    "location": "Bengaluru East, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "Technology->Data Engineering->Databricks,Technology->Machine Learning->Generative AI,Technology->OpenSystem->Python - OpenSystem->PythonWorking experience in Agile environment - knowledge on Cloud Infrastructure and data source integrations - Knowledge on relational Databases and Cognos Analytics - Self-motivated, be able to work independently as well as being a team player - Strong client service focus and willingness to respond to queries and provide deliverables within prompt timeframes.",
    "requirements": "Technology->Data Engineering->Databricks,Technology->Machine Learning->Generative AI,Technology->OpenSystem->Python - OpenSystem->PythonWorking experience in Agile environment - knowledge on Cloud Infrastructure and data source integrations - Knowledge on relational Databases and Cognos Analytics - Self-motivated, be able to work independently as well as being a team player - Strong client service focus and willingness to respond to queries and provide deliverables within prompt timeframes.",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/generative-ai-ai-ml-python-databricks-at-infosys-4367787291?position=9&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=2uAf61A0fWnQm3elaI%2BW%2FA%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:13:13.839513"
  },
  {
    "job_id": "linkedin_data-scientist-at-tata-consultancy-services-4367783869",
    "title": "Data Scientist",
    "company": "Tata Consultancy Services",
    "location": "Mumbai, Maharashtra, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "Greetings from TCS!!!Come and join us for an exciting career with TCS!!!TCS has always been in the spotlight for being adept in \u201cthe next big technologies\u201d. What we can offer you is a space to explore varied technologies and quench your techie soul.We are arranging a Virtual interview Drive at below mentioned details, please proceed with this job posting.Required Technical Skill Set - Data Scientist Date: - 3-February-2026Experience Range : 5-10 YearsLocation: Indore, Mumbai  Role Description  The Data Scientist will develop and optimize AI/ML models for predictive analytics, automation, and decision intelligence. This role works closely with data engineers and AI teams to extract insights from structured and unstructured data.  Responsibilities  Develop and deploy ML models for predictive analytics, NLP, and automation. Build and fine-tune large-scale AI models, including LLMs, reinforcement learning, and deep learning. Perform data mining, statistical modelling, and pattern recognition. Optimize ML models for scalability, accuracy, and real-time processing. Work with data engineers to ensure high-quality data pipelines. Implement MLOps best practices for AI model deployment and monitoring.  Must Have: 5+ years in data science, machine learning, or AI research. Strong experience with Python, R, TensorFlow, PyTorch, Scikit-learn, and Lang Chain. Expertise in NLP, deep learning, and generative AI. Experience with big data processing (Apache Spark, Databricks, Snowflake). Understanding of AI governance, ethics, and explainability.",
    "requirements": "Greetings from TCS!!!Come and join us for an exciting career with TCS!!!TCS has always been in the spotlight for being adept in \u201cthe next big technologies\u201d. What we can offer you is a space to explore varied technologies and quench your techie soul.We are arranging a Virtual interview Drive at below mentioned details, please proceed with this job posting.Required Technical Skill Set - Data Scientist Date: - 3-February-2026Experience Range : 5-10 YearsLocation: Indore, Mumbai  Role Description  The Data Scientist will develop and optimize AI/ML models for predictive analytics, automation, and decision intelligence. This role works closely with data engineers and AI teams to extract insights from structured and unstructured data.  Responsibilities  Develop and deploy ML models for predictive analytics, NLP, and automation. Build and fine-tune large-scale AI models, including LLMs, reinforcement learning, and deep learning. Perform data mining, statistical modelling, and pattern recognition. Optimize ML models for scalability, accuracy, and real-time processing. Work with data engineers to ensure high-quality data pipelines. Implement MLOps best practices for AI model deployment and monitoring.  Must Have: 5+ years in data science, machine learning, or AI research. Strong experience with Python, R, TensorFlow, PyTorch, Scikit-learn, and Lang Chain. Expertise in NLP, deep learning, and generative AI. Experience with big data processing (Apache Spark, Databricks, Snowflake). Understanding of AI governance, ethics, and explainability.",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/data-scientist-at-tata-consultancy-services-4367783869?position=10&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=0Kq6SQw2B7mATNv2nJlO6g%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:13:17.443262"
  },
  {
    "job_id": "linkedin_data-science-specialist-at-kotak-life-4368151843",
    "title": "Data Science Specialist",
    "company": "Kotak Life",
    "location": "Mumbai, Maharashtra, India",
    "job_type": "Full-time",
    "work_mode": "Hybrid",
    "salary": null,
    "description": "ML Ops Engineer / AI Platform EngineerJob Title: Chief Manager / Assistant Vice PresidentWork Location: Goregaon (East), Mumbai, (Hybrid)Experience: 7 years +________________________________________Role OverviewWe are seeking a MLOps / AI Platform Engineer to design and operate the Enterprise AI Platform powering mission-critical ML and GenAI systems across underwriting, claims, sales, and customer engagement.This role is fundamentally a distributed systems and platform engineering position, focused on building reliable, scalable, and compliant ML infrastructure. You will partner with research, data science, and product teams to move ML from experimentation to production at scale, while meeting the reliability, security, and auditability requirements of a regulated BFSI environment.________________________________________What You\u2019ll Do\u2022Build and maintain cloud infrastructure for ML workloads using Terraform or AWS CDK\u2022Deploy and operate Kubernetes-based ML workloads (EKS/GKE), including training and inference services\u2022Support GPU-backed workloads and assist with autoscaling, scheduling, and capacity planning\u2022Implement CI/CD pipelines for ML code, data pipelines, and model deployments\u2022Collaborate with senior platform engineers to follow standardized \u201cgolden paths\u201d for ML delivery\u2022Deploy and operate ML and LLM inference services using FastAPI and/or gRPC\u2022Support RAG-based GenAI systems, including integration with vector databases and search engines\u2022Assist with prompt versioning, evaluation, and monitoring for GenAI use cases\u2022Participate in A/B, canary, and shadow deployments for new models and prompts\u2022Optimize inference latency, throughput, and cost under guidance from senior engineers\u2022Build and operate ML pipelines using Airflow, Kubeflow Pipelines, or AWS Step Functions\u2022Integrate with model registries (MLflow or SageMaker) for versioning and controlled releases\u2022Support dataset tracking, experiment logging, and reproducibility\u2022Help implement human-in-the-loop workflows for sensitive or high-impact decisions\u2022Implement basic model and data monitoring (data drift, prediction quality, system health)\u2022Contribute to platform observability using CloudWatch, Prometheus, and Grafana\u2022Participate in on-call rotations, incident response, and root cause analysis\u2022Assist with cost optimization for compute, storage, and GPU usage________________________________________Minimum Qualifications\u2022Education:BS/MS/PhD in Computer Science, Computer Engineering, Electrical Engineering, or equivalent practical experience in distributed systems or ML platforms.\u2022Experience:o6+ years of professional software engineering experienceo3+ years focused on MLOps, ML Platform, or Infrastructure EngineeringoProven track record of shipping and operating production ML systems at scale\u2022Programming:oExpert-level PythonoStrong proficiency in Go or JavaoSolid systems fundamentals: CPU, memory, networking, concurrencyoExperience building services using FastAPI and/or gRPC\u2022Cloud & Containers:oDeep hands-on experience with AWS, GCP, or AzureoKubernetes (EKS/GKE), Docker, HelmoService mesh and traffic management using Istio/Envoy\u2022Data & Streaming:oExperience with Kafka/MSK, Kinesis, or Pub/SuboData lake/warehouse architectures and feature store designoCI/CD pipelines for data, models, and services________________________________________Preferred Qualifications\u2022Experience scaling LLMs and RAG systems in production, including prompt management and evaluation frameworks (Ragas, HF Evaluate)\u2022Hands-on knowledge of GPU scheduling, Triton, ONNX Runtime, model compression, and quantization\u2022Contributions to open-source projects (Ray, Kubeflow, MLflow, Evidently) or published systems/ML research\u2022Certifications:oAWS Certified Machine Learning \u2013 SpecialtyoCKA / CKADoGCP Professional Machine Learning Engineer\u2022Prior experience building systems in regulated environments (finance, insurance, healthcare)________________________________________Why Join Kotak Life\u2022Build enterprise-scale AI platforms that directly power core insurance decisions\u2022Work on distributed systems, GenAI, and ML SRE problems at real-world scale\u2022High ownership, high impact, and strong alignment with global engineering best practices\u2022Competitive compensation with growth into Staff / Principal-level platform roles",
    "requirements": "ML Ops Engineer / AI Platform EngineerJob Title: Chief Manager / Assistant Vice PresidentWork Location: Goregaon (East), Mumbai, (Hybrid)Experience: 7 years +________________________________________Role OverviewWe are seeking a MLOps / AI Platform Engineer to design and operate the Enterprise AI Platform powering mission-critical ML and GenAI systems across underwriting, claims, sales, and customer engagement.This role is fundamentally a distributed systems and platform engineering position, focused on building reliable, scalable, and compliant ML infrastructure. You will partner with research, data science, and product teams to move ML from experimentation to production at scale, while meeting the reliability, security, and auditability requirements of a regulated BFSI environment.________________________________________What You\u2019ll Do\u2022Build and maintain cloud infrastructure for ML workloads using Terraform or AWS CDK\u2022Deploy and operate Kubernetes-based ML workloads (EKS/GKE), including training and inference services\u2022Support GPU-backed workloads and assist with autoscaling, scheduling, and capacity planning\u2022Implement CI/CD pipelines for ML code, data pipelines, and model deployments\u2022Collaborate with senior platform engineers to follow standardized \u201cgolden paths\u201d for ML delivery\u2022Deploy and operate ML and LLM inference services using FastAPI and/or gRPC\u2022Support RAG-based GenAI systems, including integration with vector databases and search engines\u2022Assist with prompt versioning, evaluation, and monitoring for GenAI use cases\u2022Participate in A/B, canary, and shadow deployments for new models and prompts\u2022Optimize inference latency, throughput, and cost under guidance from senior engineers\u2022Build and operate ML pipelines using Airflow, Kubeflow Pipelines, or AWS Step Functions\u2022Integrate with model registries (MLflow or SageMaker) for versioning and controlled releases\u2022Support dataset tracking, experiment logging, and reproducibility\u2022Help implement human-in-the-loop workflows for sensitive or high-impact decisions\u2022Implement basic model and data monitoring (data drift, prediction quality, system health)\u2022Contribute to platform observability using CloudWatch, Prometheus, and Grafana\u2022Participate in on-call rotations, incident response, and root cause analysis\u2022Assist with cost optimization for compute, storage, and GPU usage________________________________________Minimum Qualifications\u2022Education:BS/MS/PhD in Computer Science, Computer Engineering, Electrical Engineering, or equivalent practical experience in distributed systems or ML platforms.\u2022Experience:o6+ years of professional software engineering experienceo3+ years focused on MLOps, ML Platform, or Infrastructure EngineeringoProven track record of shipping and operating production ML systems at scale\u2022Programming:oExpert-level PythonoStrong proficiency in Go or JavaoSolid systems fundamentals: CPU, memory, networking, concurrencyoExperience building services using FastAPI and/or gRPC\u2022Cloud & Containers:oDeep hands-on experience with AWS, GCP, or AzureoKubernetes (EKS/GKE), Docker, HelmoService mesh and traffic management using Istio/Envoy\u2022Data & Streaming:oExperience with Kafka/MSK, Kinesis, or Pub/SuboData lake/warehouse architectures and feature store designoCI/CD pipelines for data, models, and services________________________________________Preferred Qualifications\u2022Experience scaling LLMs and RAG systems in production, including prompt management and evaluation frameworks (Ragas, HF Evaluate)\u2022Hands-on knowledge of GPU scheduling, Triton, ONNX Runtime, model compression, and quantization\u2022Contributions to open-source projects (Ray, Kubeflow, MLflow, Evidently) or published systems/ML research\u2022Certifications:oAWS Certified Machine Learning \u2013 SpecialtyoCKA / CKADoGCP Professional Machine Learning Engineer\u2022Prior experience building systems in regulated environments (finance, insurance, healthcare)________________________________________Why Join Kotak Life\u2022Build enterprise-scale AI platforms that directly power core insurance decisions\u2022Work on distributed systems, GenAI, and ML SRE problems at real-world scale\u2022High ownership, high impact, and strong alignment with global engineering best practices\u2022Competitive compensation with growth into Staff / Principal-level platform roles",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/data-science-specialist-at-kotak-life-4368151843?position=11&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=aftTIjXJJ4iIKz2zFAzNjw%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:13:21.504466"
  },
  {
    "job_id": "linkedin_specialist-finance-data-scientist-at-harman-india-4313052910",
    "title": "Specialist - Finance Data Scientist",
    "company": "HARMAN India",
    "location": "Bengaluru, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Remote",
    "salary": null,
    "description": "Introduction: A Career at HARMAN AutomotiveWe\u2019re a global, multi-disciplinary team that\u2019s putting the innovative power of technology to work and transforming tomorrow. At HARMAN Automotive, we give you the keys to fast-track your career.Engineer audio systems and integrated technology platforms that augment the driving experienceCombine ingenuity, in-depth research, and a spirit of collaboration with design and engineering excellence. Advance in-vehicle infotainment, safety, efficiency, and enjoymentAbout The RoleWe are seeking a highly skilled and results-oriented Data Scientist to join our team, with a strong foundation in statistical modelling, machine learning, and data engineering collaboration. The ideal candidate will have a proven track record of delivering predictive and descriptive analytics use cases in the finance domain that have led to measurable improvements in profitability, revenue growth, and operational efficiency.What You Will DoCollaborate closely with finance stakeholders to translate business problems into data science solutions with quantifiable impact. Collaborate with stakeholders to understand business challenges and translate them into data-driven solutions. Develop and deploy predictive, descriptive, and prescriptive models to support finance-led initiatives (e.g. pricing, risk scoring, demand forecasting, customer segmentation). Write clean, efficient, and reproducible code in Python, R, or Scala for analytics and modelling tasks. Perform exploratory data analysis, data wrangling, feature engineering, and validation of data quality and integrity. Generate actionable insights and dashboards that drive decision-making in areas such as revenue growth, margin improvement, and cost optimization. Analyze large datasets to identify trends, patterns, and opportunities using statistical and machine learning techniques!Communicate technical results to non-technical audiences through compelling visualizations and storytelling. Partner with data engineers to define and design robust data pipelines and reusable data assets that power analytics and machine learning. Continuously evaluate and implement new modelling techniques, tools, and technologies to improve effectiveness and efficiency. What You Need To Be Successful3+ years of experience in data science roles, preferably with a focus on finance use cases. Strong proficiency in Python (preferred), R, SQL, and experience with libraries such as Pandas, Scikit-learn, TensorFlow, or PyTorch. Solid experience with statistical modelling, machine learning algorithms, and time-series forecasting. Familiarity with cloud platforms (e.g., AWS, GCP, or Azure) and big data tools (e.g., Spark, Databricks). Experience working alongside data engineers and understanding of data pipeline architecture and data governance. Ability to connect the dots between data insights and financial impact (e.g., ROI, profitability, growth metrics). Excellent communication skills with the ability to present complex data insights to non-technical stakeholders. Bonus Points if You Have Bachelor\u2019s or master\u2019s degree in data science, Computer Science, Statistics, Mathematics, or a related field. Experience with FinanceExperience with SAP Finance data, good understanding of SAP Finance data. What Makes You EligibleThis position requires up to 20% of travel. Be willing to work in Bangalore, India. What We OfferFlexible work environment, allowing for full-time remote work globally for positions that can be performed outside a HARMAN or customer location. Access to employee discounts on world-class products (JBL, HARMAN Kardon, AKG, and more)Extensive training opportunities through our own HARMAN UniversityCompetitive wellness benefitsTuition reimbursement\u201cBe Brilliant\u201d employee recognition and rewards program. An inclusive and diverse work environment that fosters and encourages professional and personal development.",
    "requirements": "Introduction: A Career at HARMAN AutomotiveWe\u2019re a global, multi-disciplinary team that\u2019s putting the innovative power of technology to work and transforming tomorrow. At HARMAN Automotive, we give you the keys to fast-track your career.Engineer audio systems and integrated technology platforms that augment the driving experienceCombine ingenuity, in-depth research, and a spirit of collaboration with design and engineering excellence. Advance in-vehicle infotainment, safety, efficiency, and enjoymentAbout The RoleWe are seeking a highly skilled and results-oriented Data Scientist to join our team, with a strong foundation in statistical modelling, machine learning, and data engineering collaboration. The ideal candidate will have a proven track record of delivering predictive and descriptive analytics use cases in the finance domain that have led to measurable improvements in profitability, revenue growth, and operational efficiency.What You Will DoCollaborate closely with finance stakeholders to translate business problems into data science solutions with quantifiable impact. Collaborate with stakeholders to understand business challenges and translate them into data-driven solutions. Develop and deploy predictive, descriptive, and prescriptive models to support finance-led initiatives (e.g. pricing, risk scoring, demand forecasting, customer segmentation). Write clean, efficient, and reproducible code in Python, R, or Scala for analytics and modelling tasks. Perform exploratory data analysis, data wrangling, feature engineering, and validation of data quality and integrity. Generate actionable insights and dashboards that drive decision-making in areas such as revenue growth, margin improvement, and cost optimization. Analyze large datasets to identify trends, patterns, and opportunities using statistical and machine learning techniques!Communicate technical results to non-technical audiences through compelling visualizations and storytelling. Partner with data engineers to define and design robust data pipelines and reusable data assets that power analytics and machine learning. Continuously evaluate and implement new modelling techniques, tools, and technologies to improve effectiveness and efficiency. What You Need To Be Successful3+ years of experience in data science roles, preferably with a focus on finance use cases. Strong proficiency in Python (preferred), R, SQL, and experience with libraries such as Pandas, Scikit-learn, TensorFlow, or PyTorch. Solid experience with statistical modelling, machine learning algorithms, and time-series forecasting. Familiarity with cloud platforms (e.g., AWS, GCP, or Azure) and big data tools (e.g., Spark, Databricks). Experience working alongside data engineers and understanding of data pipeline architecture and data governance. Ability to connect the dots between data insights and financial impact (e.g., ROI, profitability, growth metrics). Excellent communication skills with the ability to present complex data insights to non-technical stakeholders. Bonus Points if You Have Bachelor\u2019s or master\u2019s degree in data science, Computer Science, Statistics, Mathematics, or a related field. Experience with FinanceExperience with SAP Finance data, good understanding of SAP Finance data. What Makes You EligibleThis position requires up to 20% of travel. Be willing to work in Bangalore, India. What We OfferFlexible work environment, allowing for full-time remote work globally for positions that can be performed outside a HARMAN or customer location. Access to employee discounts on world-class products (JBL, HARMAN Kardon, AKG, and more)Extensive training opportunities through our own HARMAN UniversityCompetitive wellness benefitsTuition reimbursement\u201cBe Brilliant\u201d employee recognition and rewards program. An inclusive and diverse work environment that fosters and encourages professional and personal development.",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/specialist-finance-data-scientist-at-harman-india-4313052910?position=12&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=k4Q1qN5f8hfjTXsGktC%2BjQ%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:13:25.221950"
  },
  {
    "job_id": "linkedin_associate-data-scientist-at-anko-gcc-4367765255",
    "title": "Associate Data Scientist",
    "company": "Anko GCC",
    "location": "Bengaluru, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "Anko is the global capability centre for Kmart Group Australia, fuelling growth aspirations of iconic Australian retail brands Kmart, Target and Anko. Based in Bangalore, India, we strive to accelerate retail innovation by building competitive capabilities in Technology, Data Sciences and Business Services that enable our brands to deliver delightful experiences to our in-store and online customersBasic understanding of statistics - Conceptual understanding of Probability, hypotheses testing & data handling techniquesProgramming Languages such as PythonData extraction and manipulations using SQPerks And Benefits We\u2019ll Offer YouA place you can belongWe celebrate the rich diversity of the communities in which we operate. We are committed to creating inclusive and safe environments where all our team members can contribute and succeed. We believe that all team members should feel valued, respected, and safe, and strive to ensure our recruitment process is accessible and welcoming, with applications encouraged from all candidates.",
    "requirements": "Anko is the global capability centre for Kmart Group Australia, fuelling growth aspirations of iconic Australian retail brands Kmart, Target and Anko. Based in Bangalore, India, we strive to accelerate retail innovation by building competitive capabilities in Technology, Data Sciences and Business Services that enable our brands to deliver delightful experiences to our in-store and online customersBasic understanding of statistics - Conceptual understanding of Probability, hypotheses testing & data handling techniquesProgramming Languages such as PythonData extraction and manipulations using SQPerks And Benefits We\u2019ll Offer YouA place you can belongWe celebrate the rich diversity of the communities in which we operate. We are committed to creating inclusive and safe environments where all our team members can contribute and succeed. We believe that all team members should feel valued, respected, and safe, and strive to ensure our recruitment process is accessible and welcoming, with applications encouraged from all candidates.",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/associate-data-scientist-at-anko-gcc-4367765255?position=13&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=OltMLEUd1iO29%2BeCwUOj7g%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:13:29.182876"
  },
  {
    "job_id": "linkedin_data-scientist-remote-at-keystone-recruitment-4368105332",
    "title": "Data Scientist (Remote)",
    "company": "Keystone Recruitment",
    "location": "India",
    "job_type": "Full-time",
    "work_mode": "Remote",
    "salary": null,
    "description": "Title: Data Scientist (Remote)Rate: USD $14 /hourEngagement: Hourly contract (independent contractor)Location: Remote \u2013 candidates based in the United States, United Kingdom, Canada, Europe, Singapore, Dubai, or Australia who are legally able to work as independent contractors in their jurisdiction.Role OverviewOne of our clients is hiring a Data Scientist to support an advanced AI research partner focused on building intelligent, agent-based systems. In this role, you will design and maintain data pipelines, analytical models, and evaluation frameworks that power experimentation, benchmarking, and continuous learning for autonomous AI agents. This is an excellent opportunity for analytical professionals who thrive at the intersection of machine learning, data engineering, and real-world AI applications.Primary ObjectiveTo build data-driven infrastructure, models, and metrics that enable AI agents to be measured, optimized, and improved across simulated and real-world environments.Key ResponsibilitiesDevelop and maintain data pipelines for structured and unstructured data from AI agent simulationsBuild and refine machine learning models for performance prediction, behavior clustering, and outcome optimizationDesign dashboards and visualization tools to monitor benchmarks, trends, and agent performanceConduct statistical and experimental analyses to evaluate AI system effectivenessDefine and implement performance metrics such as precision, recall, F1-score, and ROC-AUCCollaborate with engineering and research teams to design KPIs, experiments, and evaluation frameworksCreate feedback loops that use data to improve agent accuracy, adaptability, and efficiencyTranslate experimental results into scalable, production-ready insightsRequired QualificationsStrong background in data science, machine learning, or applied statisticsProficiency in Python and SQLExperience with Pandas, NumPy, Scikit-learn, and PyTorch or TensorFlowSolid understanding of probabilistic modeling, statistical inference, and experimentation methods (A/B testing, causal inference)Experience collecting, cleaning, and transforming large, complex datasetsFamiliarity with large-scale data platforms such as Snowflake, BigQuery, or similar systemsAbility to collaborate effectively with cross-functional teamsWhy This Role Is ExcitingWork at the forefront of AI agent intelligence and data-driven decision-makingCombine machine learning, experimentation, and data engineering in one impactful roleCollaborate with top-tier AI researchers on advanced benchmarking and feedback systemsHelp shape how intelligent systems learn, adapt, and improve over timeContract & Payment TermsIndependent contractor roleFully remote with a flexible scheduleWeekly payments via Stripe or WiseProjects may be extended or adjusted based on performance and project needsOpen only to candidates residing in IndiaAPPLY NOW !",
    "requirements": "Title: Data Scientist (Remote)Rate: USD $14 /hourEngagement: Hourly contract (independent contractor)Location: Remote \u2013 candidates based in the United States, United Kingdom, Canada, Europe, Singapore, Dubai, or Australia who are legally able to work as independent contractors in their jurisdiction.Role OverviewOne of our clients is hiring a Data Scientist to support an advanced AI research partner focused on building intelligent, agent-based systems. In this role, you will design and maintain data pipelines, analytical models, and evaluation frameworks that power experimentation, benchmarking, and continuous learning for autonomous AI agents. This is an excellent opportunity for analytical professionals who thrive at the intersection of machine learning, data engineering, and real-world AI applications.Primary ObjectiveTo build data-driven infrastructure, models, and metrics that enable AI agents to be measured, optimized, and improved across simulated and real-world environments.Key ResponsibilitiesDevelop and maintain data pipelines for structured and unstructured data from AI agent simulationsBuild and refine machine learning models for performance prediction, behavior clustering, and outcome optimizationDesign dashboards and visualization tools to monitor benchmarks, trends, and agent performanceConduct statistical and experimental analyses to evaluate AI system effectivenessDefine and implement performance metrics such as precision, recall, F1-score, and ROC-AUCCollaborate with engineering and research teams to design KPIs, experiments, and evaluation frameworksCreate feedback loops that use data to improve agent accuracy, adaptability, and efficiencyTranslate experimental results into scalable, production-ready insightsRequired QualificationsStrong background in data science, machine learning, or applied statisticsProficiency in Python and SQLExperience with Pandas, NumPy, Scikit-learn, and PyTorch or TensorFlowSolid understanding of probabilistic modeling, statistical inference, and experimentation methods (A/B testing, causal inference)Experience collecting, cleaning, and transforming large, complex datasetsFamiliarity with large-scale data platforms such as Snowflake, BigQuery, or similar systemsAbility to collaborate effectively with cross-functional teamsWhy This Role Is ExcitingWork at the forefront of AI agent intelligence and data-driven decision-makingCombine machine learning, experimentation, and data engineering in one impactful roleCollaborate with top-tier AI researchers on advanced benchmarking and feedback systemsHelp shape how intelligent systems learn, adapt, and improve over timeContract & Payment TermsIndependent contractor roleFully remote with a flexible scheduleWeekly payments via Stripe or WiseProjects may be extended or adjusted based on performance and project needsOpen only to candidates residing in IndiaAPPLY NOW !",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/data-scientist-remote-at-keystone-recruitment-4368105332?position=14&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=0GOnZEHmEd3YHDsr0QH8QA%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:13:33.407495"
  },
  {
    "job_id": "linkedin_machine-learning-engineer-at-flexiple-4368161164",
    "title": "Machine Learning Engineer",
    "company": "Flexiple",
    "location": "India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "Company DetailsSpector.ai is an AI-driven industrial asset health and reliability platform that helps organizations transform how they manage and maintain critical equipment. It uses generative AI, multi-modal AI agents, and machine learning to integrate live and historical data from diverse sources into a unified Asset Health Knowledge Graph, enabling predictive maintenance, automated visual inspection, and real-time actionable insights across the asset lifecycle. The platform supports proactive identification of failures and anomalies, prescriptive recommendations for maintenance actions, automated work order generation, and integration with existing enterprise systems (like CMMS/EAM), helping industries such as oil & gas, manufacturing, power and energy, and infrastructure improve uptime, reduce unplanned downtime and maintenance costs, and extend asset life. Spector.ai\u2019s solutions are built to scale with industrial operations and provide a digital assistant experience that augments reliability engineers and maintenance teams, accelerating operational decision-making and boosting overall asset performance.Job Roles & Responsibilities- Design machine learning models using TensorFlow and PyTorch for industrial asset health management.- Implement predictive maintenance solutions for Oil & Gas and Manufacturing industries.- Optimize existing Scikit-Learn algorithms to improve asset health predictions.- Develop AI solutions to enhance visual inspection processes in various industries.- Collaborate with a small, dynamic team to deliver immediate, impactful solutions.- Test and validate machine learning models for accuracy and industry standards.- Integrate generative AI into predictive maintenance systems for enhanced performance.- Monitor deployed AI agents and adjust models for continuous improvement.Ideal candidate profile- Innovates in fast-paced product environments using TensorFlow expertise- Collaborates effectively across teams with immediate availability- Adapts AI solutions creatively with Scikit-Learn skills- Solves complex problems rapidly with PyTorch proficiency",
    "requirements": "Company DetailsSpector.ai is an AI-driven industrial asset health and reliability platform that helps organizations transform how they manage and maintain critical equipment. It uses generative AI, multi-modal AI agents, and machine learning to integrate live and historical data from diverse sources into a unified Asset Health Knowledge Graph, enabling predictive maintenance, automated visual inspection, and real-time actionable insights across the asset lifecycle. The platform supports proactive identification of failures and anomalies, prescriptive recommendations for maintenance actions, automated work order generation, and integration with existing enterprise systems (like CMMS/EAM), helping industries such as oil & gas, manufacturing, power and energy, and infrastructure improve uptime, reduce unplanned downtime and maintenance costs, and extend asset life. Spector.ai\u2019s solutions are built to scale with industrial operations and provide a digital assistant experience that augments reliability engineers and maintenance teams, accelerating operational decision-making and boosting overall asset performance.Job Roles & Responsibilities- Design machine learning models using TensorFlow and PyTorch for industrial asset health management.- Implement predictive maintenance solutions for Oil & Gas and Manufacturing industries.- Optimize existing Scikit-Learn algorithms to improve asset health predictions.- Develop AI solutions to enhance visual inspection processes in various industries.- Collaborate with a small, dynamic team to deliver immediate, impactful solutions.- Test and validate machine learning models for accuracy and industry standards.- Integrate generative AI into predictive maintenance systems for enhanced performance.- Monitor deployed AI agents and adjust models for continuous improvement.Ideal candidate profile- Innovates in fast-paced product environments using TensorFlow expertise- Collaborates effectively across teams with immediate availability- Adapts AI solutions creatively with Scikit-Learn skills- Solves complex problems rapidly with PyTorch proficiency",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/machine-learning-engineer-at-flexiple-4368161164?position=15&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=aEqbfkq1Aus6Ajcmh0ooJQ%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:13:37.475733"
  },
  {
    "job_id": "linkedin_ai-engineer-at-viraaj-hr-solutions-private-limited-4367718920",
    "title": "AI Engineer",
    "company": "Viraaj HR Solutions Private Limited",
    "location": "Pune, Maharashtra, India",
    "job_type": "Full-time",
    "work_mode": "On-site",
    "salary": null,
    "description": "Industry & Sector: HR Technology / Talent Solutions \u2014 building AI-driven products and analytics that automate talent discovery, candidate matching, and workforce intelligence for enterprise customers. This is an on-site engineering role based in India focused on production-grade AI/ML systems for the HR domain.Primary standardized title: Machine Learning EngineerAbout The OpportunityWe are hiring an AI Engineer to design, build, and productionize intelligent models and services that power next-generation recruitment and HR automation. You will work on end-to-end ML lifecycle tasks \u2014 from data preparation and model development to deployment, monitoring, and continuous improvement \u2014 in an on-site delivery environment.Role & ResponsibilitiesDesign and implement scalable ML/NLP models (classification, ranking, embeddings, LLM pipelines) that solve HR-specific problems like candidate matching, resume parsing, and semantic search.Build reliable model deployment pipelines and production services (APIs, batch/streaming pipelines) with observability, automated testing, and rollback strategies.Collaborate with product and data teams to translate business requirements into data-driven solutions and measurable KPIs.Optimize model performance for latency, throughput, and cost\u2014apply quantization, pruning, distillation and GPU/CPU optimizations where required.Implement MLOps best practices: CI/CD for models, versioning, monitoring for drift, automated retraining pipelines and alerting.Document solutions, enforce code quality, and mentor junior engineers to raise engineering standards across the team.Skills & QualificationsMust-HaveStrong software engineering experience with Python and production ML frameworks (PyTorch or TensorFlow).Practical experience with NLP and transformer-based models (Hugging Face Transformers) for tasks like NER, classification, semantic search, or summarization.Hands-on experience deploying models as services (REST APIs), containerizing with Docker and orchestrating with Kubernetes.Experience deploying and operating models on cloud platforms (AWS preferred) and familiarity with cloud networking and storage patterns.Proven track record of taking models to production: CI/CD for ML, model versioning, monitoring, and automated retraining.Strong debugging and performance-tuning skills for model inference (latency, memory, GPU utilization).PreferredExperience with MLOps tools: MLflow, Kubeflow, or similar orchestration and experiment-tracking frameworks.Previous exposure to Large Language Models (LLMs) and prompt engineering or agentic workflows.Domain experience in HRTech, recruitment systems, or enterprise search products.Benefits & Culture HighlightsOn-site role with a high-impact engineering culture and direct collaboration with product & data science teams.Opportunity to work on cutting-edge NLP/AI systems and influence product direction in the HRTech space.Competitive compensation, professional development, and fast career growth for high performers.Location: India (On-site). Keywords: AI Engineer, Machine Learning, NLP, Deep Learning, Model Deployment, MLOps, PyTorch, TensorFlow, Hugging Face, Docker, Kubernetes, AWS, REST APIs.Skills: ai ml,aws,data scientist,kubernetes,python,ai engineer,tensorflow,docker,pytorch",
    "requirements": "Industry & Sector: HR Technology / Talent Solutions \u2014 building AI-driven products and analytics that automate talent discovery, candidate matching, and workforce intelligence for enterprise customers. This is an on-site engineering role based in India focused on production-grade AI/ML systems for the HR domain.Primary standardized title: Machine Learning EngineerAbout The OpportunityWe are hiring an AI Engineer to design, build, and productionize intelligent models and services that power next-generation recruitment and HR automation. You will work on end-to-end ML lifecycle tasks \u2014 from data preparation and model development to deployment, monitoring, and continuous improvement \u2014 in an on-site delivery environment.Role & ResponsibilitiesDesign and implement scalable ML/NLP models (classification, ranking, embeddings, LLM pipelines) that solve HR-specific problems like candidate matching, resume parsing, and semantic search.Build reliable model deployment pipelines and production services (APIs, batch/streaming pipelines) with observability, automated testing, and rollback strategies.Collaborate with product and data teams to translate business requirements into data-driven solutions and measurable KPIs.Optimize model performance for latency, throughput, and cost\u2014apply quantization, pruning, distillation and GPU/CPU optimizations where required.Implement MLOps best practices: CI/CD for models, versioning, monitoring for drift, automated retraining pipelines and alerting.Document solutions, enforce code quality, and mentor junior engineers to raise engineering standards across the team.Skills & QualificationsMust-HaveStrong software engineering experience with Python and production ML frameworks (PyTorch or TensorFlow).Practical experience with NLP and transformer-based models (Hugging Face Transformers) for tasks like NER, classification, semantic search, or summarization.Hands-on experience deploying models as services (REST APIs), containerizing with Docker and orchestrating with Kubernetes.Experience deploying and operating models on cloud platforms (AWS preferred) and familiarity with cloud networking and storage patterns.Proven track record of taking models to production: CI/CD for ML, model versioning, monitoring, and automated retraining.Strong debugging and performance-tuning skills for model inference (latency, memory, GPU utilization).PreferredExperience with MLOps tools: MLflow, Kubeflow, or similar orchestration and experiment-tracking frameworks.Previous exposure to Large Language Models (LLMs) and prompt engineering or agentic workflows.Domain experience in HRTech, recruitment systems, or enterprise search products.Benefits & Culture HighlightsOn-site role with a high-impact engineering culture and direct collaboration with product & data science teams.Opportunity to work on cutting-edge NLP/AI systems and influence product direction in the HRTech space.Competitive compensation, professional development, and fast career growth for high performers.Location: India (On-site). Keywords: AI Engineer, Machine Learning, NLP, Deep Learning, Model Deployment, MLOps, PyTorch, TensorFlow, Hugging Face, Docker, Kubernetes, AWS, REST APIs.Skills: ai ml,aws,data scientist,kubernetes,python,ai engineer,tensorflow,docker,pytorch",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/ai-engineer-at-viraaj-hr-solutions-private-limited-4367718920?position=16&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=JFe8HEYPgAyFIIslx5aN9w%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:13:41.594683"
  },
  {
    "job_id": "linkedin_gcp-ai-ml-at-tata-consultancy-services-4367758474",
    "title": "GCP AI/ML",
    "company": "Tata Consultancy Services",
    "location": "Chennai, Tamil Nadu, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "TCS Hiring !!. Virtual Drive GCP AI/MLMust Have:Tensor flow, Machine Learning, python, ML Ops | Vertex Ai, google cloud, google cloud professional machine learning4-Feb-26TCS -4TO 10 Immediate JoinersChennai, GandhinagarPlease read Job description before ApplyingNOTE: If the skills/profile matches and interested, please reply to this email by attaching your latest updated CV and with below few details:Name:Contact Number:Email ID:Highest Qualification in: (Eg. B.Tech/B.E./M.Tech/MCA/M.Sc./MS/BCA/B.Sc./Etc.)Current Organization Name:Total IT Experience-Location: TCS: - Chennai, GandhinagarCurrent CTCExpected CTCNotice period: Immediate JoinerWhether worked with TCS - Y/NMust-Have**Tensor flow, Machine Learning, python, ML Ops | Vertex Ai, google cloud, google cloud professional machine learning",
    "requirements": "TCS Hiring !!. Virtual Drive GCP AI/MLMust Have:Tensor flow, Machine Learning, python, ML Ops | Vertex Ai, google cloud, google cloud professional machine learning4-Feb-26TCS -4TO 10 Immediate JoinersChennai, GandhinagarPlease read Job description before ApplyingNOTE: If the skills/profile matches and interested, please reply to this email by attaching your latest updated CV and with below few details:Name:Contact Number:Email ID:Highest Qualification in: (Eg. B.Tech/B.E./M.Tech/MCA/M.Sc./MS/BCA/B.Sc./Etc.)Current Organization Name:Total IT Experience-Location: TCS: - Chennai, GandhinagarCurrent CTCExpected CTCNotice period: Immediate JoinerWhether worked with TCS - Y/NMust-Have**Tensor flow, Machine Learning, python, ML Ops | Vertex Ai, google cloud, google cloud professional machine learning",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/gcp-ai-ml-at-tata-consultancy-services-4367758474?position=17&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=WQ%2FvElpjSNGwEwioEO59Iw%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:13:45.233476"
  },
  {
    "job_id": "linkedin_ai-ml-engineer-at-accenture-services-pvt-ltd-4367752955",
    "title": "AI / ML Engineer",
    "company": "Accenture services Pvt Ltd",
    "location": "Greater Bengaluru Area",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "Project Role : AI / ML EngineerProject Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing.Must have skills : Data ScienceGood to have skills : NAMinimum 7.5 Year(s) Of Experience Is RequiredEducational Qualification : 15 years full time educationSummary: Data Scientist with 5 to 7 years of experience, and at least 3+ years of genuine experience in building production-grade ML models (Regression, Forecasting, Classification etc.) and getting them deployed in production rather than just proof of concept or learning projects. Roles & Responsibilities: - At least 3+ years of relevant experience in data science, specifically in building and deploying production models (Regression, Forecasting, Classification etc.)) rather than just proof of concept or learning projects - Experience in building or training machine learning models to a production environment that are actively used by end-users or systems - Experience in maintaining or monitoring machine learning models in production for more than six months - Experience in working on projects where they had to retrain or redeploy models based on new data in a production setting - Experience in using version control systems (e.g., Git) for managing your data science projects in production - Experience in collaborating with DevOps or MLOps teams to deploy and scale machine learning models in production - Strong programming skills, particularly in Python - Experience in written Python codes (Data Science) that is currently running in a production environment - Experience in using Python for data manipulation, analysis and feature engineering in a production setting - Experience in working on end-to-end Data Science pipelines - Experience in creating environments for different libraries in production for different versions - Experience in optimizing Python code for performance in a production system - Ability to work in Agile environment and using tools like Git, Jira, Confluence etc - Experience of working in Azure ML Professional & Technical Skills: - Must To Have Skills: Data Science, Azure ML, Python Additional Information: - A 15 years full time education is required.",
    "requirements": "Project Role : AI / ML EngineerProject Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing.Must have skills : Data ScienceGood to have skills : NAMinimum 7.5 Year(s) Of Experience Is RequiredEducational Qualification : 15 years full time educationSummary: Data Scientist with 5 to 7 years of experience, and at least 3+ years of genuine experience in building production-grade ML models (Regression, Forecasting, Classification etc.) and getting them deployed in production rather than just proof of concept or learning projects. Roles & Responsibilities: - At least 3+ years of relevant experience in data science, specifically in building and deploying production models (Regression, Forecasting, Classification etc.)) rather than just proof of concept or learning projects - Experience in building or training machine learning models to a production environment that are actively used by end-users or systems - Experience in maintaining or monitoring machine learning models in production for more than six months - Experience in working on projects where they had to retrain or redeploy models based on new data in a production setting - Experience in using version control systems (e.g., Git) for managing your data science projects in production - Experience in collaborating with DevOps or MLOps teams to deploy and scale machine learning models in production - Strong programming skills, particularly in Python - Experience in written Python codes (Data Science) that is currently running in a production environment - Experience in using Python for data manipulation, analysis and feature engineering in a production setting - Experience in working on end-to-end Data Science pipelines - Experience in creating environments for different libraries in production for different versions - Experience in optimizing Python code for performance in a production system - Ability to work in Agile environment and using tools like Git, Jira, Confluence etc - Experience of working in Azure ML Professional & Technical Skills: - Must To Have Skills: Data Science, Azure ML, Python Additional Information: - A 15 years full time education is required.",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/ai-ml-engineer-at-accenture-services-pvt-ltd-4367752955?position=18&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=bbH9YcaqdQL%2FOJRW5KjNmQ%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:13:48.520681"
  },
  {
    "job_id": "linkedin_machine-learning-engineer-at-bornbhukkad-4367748892",
    "title": "Machine Learning Engineer",
    "company": "Bornbhukkad",
    "location": "Hyderabad, Telangana, India",
    "job_type": "Full-time",
    "work_mode": "Remote",
    "salary": null,
    "description": "Location: Remote / Hyderabad/ RourkelaCompany: Bornbhukkad & Kisansathi.techAbout BornbhukkadBornbhukkad is a food-tech and HoReCa intelligence platform leveraging AI to optimize food demand forecasting, inventory planning, and supply chain efficiency. We are building next-generation AI systems that reduce food waste and improve profitability for restaurants and food suppliers.Role OverviewWe are looking for a Machine Learning Engineers & Interns to design and build foundational ML models that power demand forecasting, menu intelligence, and supply chain optimization across the HoReCa ecosystem. You will work on large, multi-source datasets and develop scalable ML pipelines that serve real-world, high-frequency business decisions.Key ResponsibilitiesDesign and develop foundational machine learning models for:Item-level food demand forecastingSales pattern recognitionPrice sensitivity and margin optimizationInventory and wastage predictionBuild data pipelines to ingest restaurant POS, inventory, and transaction dataPerform feature engineering on time-series, seasonal, and behavioral datasetsTrain, validate, and deploy ML models in production environmentsImprove model accuracy using continuous learning and feedback loopsWork closely with product, engineering, and business teams to translate real-world problems into ML solutionsCreate model monitoring systems for performance drift and retrainingRequired Skills & QualificationsBachelor\u2019s/Master\u2019s in Computer Science, AI, Data Science, or related field1\u20135 years of hands-on ML development experienceStrong expertise in:Python, Pandas, NumPyScikit-learn, XGBoost, LightGBM, or similarTime-series forecasting (ARIMA, Prophet, LSTM, Transformers)Experience working with real-world noisy datasetsUnderstanding of ML model deployment (APIs, cloud, containers)Familiarity with SQL and data warehousingGood to HaveExperience in food-tech, retail, or supply chain analyticsKnowledge of deep learning frameworks (TensorFlow / PyTorch)Exposure to MLOps tools (MLflow, Airflow, Kubeflow, etc.)Experience handling streaming or near real-time dataWhat You\u2019ll Work On First (First 6 Months)Build Bornbhukkad\u2019s restaurant demand forecasting engineDevelop ML models to reduce food wastageCreate predictive tools for menu planning and procurement optimizationWhy Join UsWork on real-world AI with measurable impactOpportunity to build foundational IP in food intelligence",
    "requirements": "Location: Remote / Hyderabad/ RourkelaCompany: Bornbhukkad & Kisansathi.techAbout BornbhukkadBornbhukkad is a food-tech and HoReCa intelligence platform leveraging AI to optimize food demand forecasting, inventory planning, and supply chain efficiency. We are building next-generation AI systems that reduce food waste and improve profitability for restaurants and food suppliers.Role OverviewWe are looking for a Machine Learning Engineers & Interns to design and build foundational ML models that power demand forecasting, menu intelligence, and supply chain optimization across the HoReCa ecosystem. You will work on large, multi-source datasets and develop scalable ML pipelines that serve real-world, high-frequency business decisions.Key ResponsibilitiesDesign and develop foundational machine learning models for:Item-level food demand forecastingSales pattern recognitionPrice sensitivity and margin optimizationInventory and wastage predictionBuild data pipelines to ingest restaurant POS, inventory, and transaction dataPerform feature engineering on time-series, seasonal, and behavioral datasetsTrain, validate, and deploy ML models in production environmentsImprove model accuracy using continuous learning and feedback loopsWork closely with product, engineering, and business teams to translate real-world problems into ML solutionsCreate model monitoring systems for performance drift and retrainingRequired Skills & QualificationsBachelor\u2019s/Master\u2019s in Computer Science, AI, Data Science, or related field1\u20135 years of hands-on ML development experienceStrong expertise in:Python, Pandas, NumPyScikit-learn, XGBoost, LightGBM, or similarTime-series forecasting (ARIMA, Prophet, LSTM, Transformers)Experience working with real-world noisy datasetsUnderstanding of ML model deployment (APIs, cloud, containers)Familiarity with SQL and data warehousingGood to HaveExperience in food-tech, retail, or supply chain analyticsKnowledge of deep learning frameworks (TensorFlow / PyTorch)Exposure to MLOps tools (MLflow, Airflow, Kubeflow, etc.)Experience handling streaming or near real-time dataWhat You\u2019ll Work On First (First 6 Months)Build Bornbhukkad\u2019s restaurant demand forecasting engineDevelop ML models to reduce food wastageCreate predictive tools for menu planning and procurement optimizationWhy Join UsWork on real-world AI with measurable impactOpportunity to build foundational IP in food intelligence",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/machine-learning-engineer-at-bornbhukkad-4367748892?position=19&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=RdXx5A4LYDjtOSoGJyoIHA%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:13:52.224669"
  },
  {
    "job_id": "linkedin_sde-3-at-simplilearn-4357491028",
    "title": "SDE-3",
    "company": "Simplilearn",
    "location": "Bengaluru South, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "Position: SDE-3 (FullStack)About SimplilearnSimplilearn is the world\u2019s #1 live online training company focused on digital skills. Founded in 2010, with offices in San Francisco, California, and Bangalore, India, and backed by the Blackstone Group, we drive talent transformation for over 500 global organizations, including Amazon, Bosch, Dell, and EY. We are disrupting the talent development market with our one-of-a-kind online subscription product, Simplilearn Learning Hub+, which enables organizations to offer their workforce unlimited live and interactive learning led by experts, along with a comprehensive library of on-demand content and hands-on projects\u2014all in one single plan. Our award-winning content and curriculum, designed and updated by renowned industry and academic experts, cover all the digital skills required by organizations, including AI, ML, Data Science, Cyber Security, Software Engineering, Project Management, and more. We are authorized training partners for over 15 certification bodies, including PMI, PeopleCert, Scaled Agile, and industry partners of AWS, Microsoft, and more. Our goal is to enable organizations to deliver a highly impactful and engaging learning experience to their workforce, driving talent transformation for business success.Job DescriptionWe are looking for a highly skilled SDE-3 - Full Stack Developer (4+ years) with strong expertise in Next.js/Angular.js (Version- 14+), Express.js and Node.js. This role involves end-to-end delivery from frontend interfaces to backend services using modern full-stack technologies. You should be passionate about crafting clean, maintainable code and delivering user-friendly experiences.Key ResponsibilitiesDevelop and maintain web applications using Next.js/Angular, Node.jsContribute to solutioning for complex problem statements and drive technical decisions.Design, develop, modify, implement, and support software components across the fullstack development stack.Collaborate with designers, frontend & backend developers, and product managersAssist in task planning, estimation, and scheduling to ensure timely delivery.Perform root-cause analysis for critical issues and implement long-term fixes.Develop clean, reusable, and well-documented code and scalable maintainable solutions.Ensure cross-browser and mobile compatibility for frontend components.Required Skills4+ years of professional software development experience (3+ years with Node.js, Next.js, MongoDB, MySQL, ReactJS stack)Strong expertise in full-stack TypeScript development with Node.js, Express.js, and Next.js (App Router, SSR, SSG, ISR)Strong experience in data modeling and performance tuning across relational (MySQL) and NoSQL databases (MongoDB, Firebase).Proficient in HTML5, CSS3, SASS/LESS, and building reusable UI componentsSolid understanding of REST APIs, microservices, and distributed systems.Excellent analytical and problem-solving skillsNice To HaveExperience with TurboRepo, monorepos, and caching layers (Redis, Memcached)Familiarity with infrastructure monitoring and profiling (CloudWatch, Chrome DevTools, React Profiler)Familiarity with Agile & DevOps practicesExposure to containerization and orchestration tools like Docker is a plus.Educational Qualification: Bachelor's degree in Computer Science, Engineering, or related field (or equivalent experience)",
    "requirements": "Position: SDE-3 (FullStack)About SimplilearnSimplilearn is the world\u2019s #1 live online training company focused on digital skills. Founded in 2010, with offices in San Francisco, California, and Bangalore, India, and backed by the Blackstone Group, we drive talent transformation for over 500 global organizations, including Amazon, Bosch, Dell, and EY. We are disrupting the talent development market with our one-of-a-kind online subscription product, Simplilearn Learning Hub+, which enables organizations to offer their workforce unlimited live and interactive learning led by experts, along with a comprehensive library of on-demand content and hands-on projects\u2014all in one single plan. Our award-winning content and curriculum, designed and updated by renowned industry and academic experts, cover all the digital skills required by organizations, including AI, ML, Data Science, Cyber Security, Software Engineering, Project Management, and more. We are authorized training partners for over 15 certification bodies, including PMI, PeopleCert, Scaled Agile, and industry partners of AWS, Microsoft, and more. Our goal is to enable organizations to deliver a highly impactful and engaging learning experience to their workforce, driving talent transformation for business success.Job DescriptionWe are looking for a highly skilled SDE-3 - Full Stack Developer (4+ years) with strong expertise in Next.js/Angular.js (Version- 14+), Express.js and Node.js. This role involves end-to-end delivery from frontend interfaces to backend services using modern full-stack technologies. You should be passionate about crafting clean, maintainable code and delivering user-friendly experiences.Key ResponsibilitiesDevelop and maintain web applications using Next.js/Angular, Node.jsContribute to solutioning for complex problem statements and drive technical decisions.Design, develop, modify, implement, and support software components across the fullstack development stack.Collaborate with designers, frontend & backend developers, and product managersAssist in task planning, estimation, and scheduling to ensure timely delivery.Perform root-cause analysis for critical issues and implement long-term fixes.Develop clean, reusable, and well-documented code and scalable maintainable solutions.Ensure cross-browser and mobile compatibility for frontend components.Required Skills4+ years of professional software development experience (3+ years with Node.js, Next.js, MongoDB, MySQL, ReactJS stack)Strong expertise in full-stack TypeScript development with Node.js, Express.js, and Next.js (App Router, SSR, SSG, ISR)Strong experience in data modeling and performance tuning across relational (MySQL) and NoSQL databases (MongoDB, Firebase).Proficient in HTML5, CSS3, SASS/LESS, and building reusable UI componentsSolid understanding of REST APIs, microservices, and distributed systems.Excellent analytical and problem-solving skillsNice To HaveExperience with TurboRepo, monorepos, and caching layers (Redis, Memcached)Familiarity with infrastructure monitoring and profiling (CloudWatch, Chrome DevTools, React Profiler)Familiarity with Agile & DevOps practicesExposure to containerization and orchestration tools like Docker is a plus.Educational Qualification: Bachelor's degree in Computer Science, Engineering, or related field (or equivalent experience)",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/sde-3-at-simplilearn-4357491028?position=21&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=ob0l%2BwF4MMGq3uKmQ3un4g%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:13:59.850716"
  },
  {
    "job_id": "linkedin_data-science-intern-at-inficore-soft-4367720964",
    "title": "Data Science Intern",
    "company": "Inficore Soft",
    "location": "India",
    "job_type": "Full-time",
    "work_mode": "Remote",
    "salary": null,
    "description": "Data Science InternCompany: Inficore SoftDuration: 1 to 3 monthsEmployment Type: Full-time, InternshipLocation: RemoteStipend: \u20b914,500 per monthAbout CompanyInficore Soft leverages data-driven insights to help businesses make informed decisions. Our data science team works on projects ranging from analytics to predictive modeling.About the RoleWe are seeking a Data Science Intern to assist with data analysis, visualization, and predictive modeling.Responsibilities* Clean and preprocess datasets.* Perform exploratory data analysis.* Build predictive models and evaluate performance.* Visualize insights using charts and dashboards.Requirements* Pursuing/completed degree in Computer Science, Statistics, or related field.* Strong knowledge of Python or R.* Familiarity with Pandas, NumPy, and visualization libraries.* Basic SQL knowledge.Benefits* Real-world data science project experience.* Mentorship from experienced data scientists.* Flexible remote work environment.* Monthly stipend of \u20b914,500.",
    "requirements": "Data Science InternCompany: Inficore SoftDuration: 1 to 3 monthsEmployment Type: Full-time, InternshipLocation: RemoteStipend: \u20b914,500 per monthAbout CompanyInficore Soft leverages data-driven insights to help businesses make informed decisions. Our data science team works on projects ranging from analytics to predictive modeling.About the RoleWe are seeking a Data Science Intern to assist with data analysis, visualization, and predictive modeling.Responsibilities* Clean and preprocess datasets.* Perform exploratory data analysis.* Build predictive models and evaluate performance.* Visualize insights using charts and dashboards.Requirements* Pursuing/completed degree in Computer Science, Statistics, or related field.* Strong knowledge of Python or R.* Familiarity with Pandas, NumPy, and visualization libraries.* Basic SQL knowledge.Benefits* Real-world data science project experience.* Mentorship from experienced data scientists.* Flexible remote work environment.* Monthly stipend of \u20b914,500.",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/data-science-intern-at-inficore-soft-4367720964?position=22&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=dSxA%2Bb6s239Coo%2B0EcenOw%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:14:03.035292"
  },
  {
    "job_id": "linkedin_ai-ml-testing-specialist-at-rapidbrains-4367806018",
    "title": "AI/ML Testing Specialist",
    "company": "RapidBrains",
    "location": "Delhi, India",
    "job_type": "Full-time",
    "work_mode": "On-site",
    "salary": null,
    "description": "Job title: AI/ML Testing SpecialistExperience: 5+ YearsLocation: New Delhi (Onsite)Employment Type: ContractNotice Period: Immediate joiners preferredWe are hiring experienced AI/ML Testing Specialists to support the Government e-Marketplace (GEM) project in New Delhi. This role focuses on validating AI/ML models used in large-scale, data-driven marketplace systems. The candidate will ensure accuracy, fairness, transparency, robustness, and compliance across critical use cases such as bid scoring, supplier ranking, recommendations, and fraud detection within a regulated environment.Key ResponsibilitiesTest and validate AI/ML models across NLP, recommendation systems, fraud detection, and advanced analyticsEnsure models meet standards for accuracy, performance, bias mitigation, fairness, and explainability (XAI)Validate training, inference, and data pipelines for alignment with business rules and procurement policiesDesign and execute AI/ML testing strategies including:Boundary and edge-case testingAdversarial and misuse scenario simulationData and model drift monitoringAnalyze model behavior to ensure reliability, transparency, and auditabilityIdentify and mitigate risks such as biased scoring, algorithm manipulation, or marketplace misuseIntegrate AI/ML testing frameworks into CI/CD pipelines for continuous validationCollaborate with Data Science, Engineering, QA, and Business teams to meet functional and regulatory requirementsRequired Qualifications5+ years of hands-on experience testing AI/ML models and data-driven systemsStrong experience in testing:NLP modelsRecommendation enginesFraud detection modelsAdvanced analytics pipelinesSolid understanding of:Model accuracy and performance testingBias, fairness, and ethical AI validationExplainable AI (XAI)Experience validating data pipelines, training workflows, and inference outputsAbility to design testing strategies for complex and regulated AI systemsExperience integrating testing into automated CI/CD environmentsStrong understanding of AI risks in marketplace ecosystemsBachelor\u2019s or Master\u2019s degree in Engineering, Computer Science, IT, Data Science, or related field",
    "requirements": "Job title: AI/ML Testing SpecialistExperience: 5+ YearsLocation: New Delhi (Onsite)Employment Type: ContractNotice Period: Immediate joiners preferredWe are hiring experienced AI/ML Testing Specialists to support the Government e-Marketplace (GEM) project in New Delhi. This role focuses on validating AI/ML models used in large-scale, data-driven marketplace systems. The candidate will ensure accuracy, fairness, transparency, robustness, and compliance across critical use cases such as bid scoring, supplier ranking, recommendations, and fraud detection within a regulated environment.Key ResponsibilitiesTest and validate AI/ML models across NLP, recommendation systems, fraud detection, and advanced analyticsEnsure models meet standards for accuracy, performance, bias mitigation, fairness, and explainability (XAI)Validate training, inference, and data pipelines for alignment with business rules and procurement policiesDesign and execute AI/ML testing strategies including:Boundary and edge-case testingAdversarial and misuse scenario simulationData and model drift monitoringAnalyze model behavior to ensure reliability, transparency, and auditabilityIdentify and mitigate risks such as biased scoring, algorithm manipulation, or marketplace misuseIntegrate AI/ML testing frameworks into CI/CD pipelines for continuous validationCollaborate with Data Science, Engineering, QA, and Business teams to meet functional and regulatory requirementsRequired Qualifications5+ years of hands-on experience testing AI/ML models and data-driven systemsStrong experience in testing:NLP modelsRecommendation enginesFraud detection modelsAdvanced analytics pipelinesSolid understanding of:Model accuracy and performance testingBias, fairness, and ethical AI validationExplainable AI (XAI)Experience validating data pipelines, training workflows, and inference outputsAbility to design testing strategies for complex and regulated AI systemsExperience integrating testing into automated CI/CD environmentsStrong understanding of AI risks in marketplace ecosystemsBachelor\u2019s or Master\u2019s degree in Engineering, Computer Science, IT, Data Science, or related field",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/ai-ml-testing-specialist-at-rapidbrains-4367806018?position=25&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=JmftUiCrydPJfl6Cm%2BARUw%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:14:13.456221"
  },
  {
    "job_id": "linkedin_data-scientist-at-smiths-detection-4367795675",
    "title": "Data Scientist",
    "company": "Smiths Detection",
    "location": "Bengaluru, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "Job Title: Data ScientistOverview: Smiths Detection is seeking a Data Scientist with strong expertise in AI/ML/DL to contribute as a Machine Learning Engineer. The role focuses on developing and enhancing the technical architecture of the iCMORE product within the Automated Detection group, supporting global security operations through advanced data science solutions.Key Responsibilities:Design and implement ML systems, algorithms, and applicationsDevelop data pipelines, perform statistical analysis, and fine\u2011tune modelsConduct experiments, train/retrain systems, and extend ML frameworksCollaborate with engineering, product, and cross\u2011functional teamsStay updated on AI/ML advancements and apply them effectivelyQualifications & Skills:Bachelor\u2019s degree in Engineering/Computer Science or equivalentMinimum 1 year of relevant experience required.Strong coding skills in Python, C, C++Experience with ML frameworks (TensorFlow, PyTorch, scikit\u2011learn)Knowledge of data structures, modeling, probability, and statisticsAnalytical problem\u2011solving skills and ability to work in a teamExcellent communication, collaboration, and global mindset",
    "requirements": "Job Title: Data ScientistOverview: Smiths Detection is seeking a Data Scientist with strong expertise in AI/ML/DL to contribute as a Machine Learning Engineer. The role focuses on developing and enhancing the technical architecture of the iCMORE product within the Automated Detection group, supporting global security operations through advanced data science solutions.Key Responsibilities:Design and implement ML systems, algorithms, and applicationsDevelop data pipelines, perform statistical analysis, and fine\u2011tune modelsConduct experiments, train/retrain systems, and extend ML frameworksCollaborate with engineering, product, and cross\u2011functional teamsStay updated on AI/ML advancements and apply them effectivelyQualifications & Skills:Bachelor\u2019s degree in Engineering/Computer Science or equivalentMinimum 1 year of relevant experience required.Strong coding skills in Python, C, C++Experience with ML frameworks (TensorFlow, PyTorch, scikit\u2011learn)Knowledge of data structures, modeling, probability, and statisticsAnalytical problem\u2011solving skills and ability to work in a teamExcellent communication, collaboration, and global mindset",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/data-scientist-at-smiths-detection-4367795675?position=27&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=94FcepF%2BAjhVsi1HjbnzuQ%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:14:21.102608"
  },
  {
    "job_id": "linkedin_data-science-intern-at-dexter-s-tech-4367788692",
    "title": "Data Science Intern",
    "company": "Dexter's Tech",
    "location": "India",
    "job_type": "Full-time",
    "work_mode": "Remote",
    "salary": null,
    "description": "Data Science Intern (Paid)Company: Dexter\u2019s TechLocation: RemoteDuration: 3 MonthsOpportunity & Benefits\ud83d\udcb0 Performance-based stipend up to \u20b97,499\ud83c\udf81 Swags and goodies\ud83d\udcdc Internship Certificate\u2709\ufe0f Letter of Recommendation (based on performance)\ud83c\udf1f Potential full-time role based on performance\ud83d\udcc8 Hands-on experience with real-world data science projectsAbout Dexter\u2019s TechDexter\u2019s Tech empowers aspiring data professionals by providing practical, industry-relevant experience in data science. The internship focuses on building strong foundations in analytics, statistics, and machine learning through live projects aligned with real-world business and technology challenges.Roles & ResponsibilitiesCollect, preprocess, and analyze large datasetsPerform Exploratory Data Analysis (EDA) to uncover meaningful insightsBuild predictive models and machine learning algorithmsCreate data visualizations and dashboards for effective storytellingCollaborate with cross-functional teams to deliver data-driven solutionsRequirementsCurrently enrolled in or graduated from Data Science, Computer Science, Statistics, or related fieldsProficiency in Python or R for data analysis and modelingFamiliarity with scikit-learn, TensorFlow, or PyTorch (preferred)Experience with visualization tools such as Tableau, Power BI, or MatplotlibStrong analytical, problem-solving, and communication skillsWhat You Will GainReal-world exposure to data science workflowsPerformance-based stipend up to \u20b97,499Swags and goodiesInternship Certificate upon completionLetter of Recommendation based on performanceOpportunity to build a strong data science portfolioPotential full-time role based on performanceHow to ApplySubmit your resume and cover letter with the subject line:\u201cData Science Intern Application\u201d\ud83d\udcc5 Application Deadline: 03rd February 2026Equal Opportunity StatementDexter\u2019s Tech is an equal opportunity organization and encourages applications from candidates of all backgrounds.",
    "requirements": "Data Science Intern (Paid)Company: Dexter\u2019s TechLocation: RemoteDuration: 3 MonthsOpportunity & Benefits\ud83d\udcb0 Performance-based stipend up to \u20b97,499\ud83c\udf81 Swags and goodies\ud83d\udcdc Internship Certificate\u2709\ufe0f Letter of Recommendation (based on performance)\ud83c\udf1f Potential full-time role based on performance\ud83d\udcc8 Hands-on experience with real-world data science projectsAbout Dexter\u2019s TechDexter\u2019s Tech empowers aspiring data professionals by providing practical, industry-relevant experience in data science. The internship focuses on building strong foundations in analytics, statistics, and machine learning through live projects aligned with real-world business and technology challenges.Roles & ResponsibilitiesCollect, preprocess, and analyze large datasetsPerform Exploratory Data Analysis (EDA) to uncover meaningful insightsBuild predictive models and machine learning algorithmsCreate data visualizations and dashboards for effective storytellingCollaborate with cross-functional teams to deliver data-driven solutionsRequirementsCurrently enrolled in or graduated from Data Science, Computer Science, Statistics, or related fieldsProficiency in Python or R for data analysis and modelingFamiliarity with scikit-learn, TensorFlow, or PyTorch (preferred)Experience with visualization tools such as Tableau, Power BI, or MatplotlibStrong analytical, problem-solving, and communication skillsWhat You Will GainReal-world exposure to data science workflowsPerformance-based stipend up to \u20b97,499Swags and goodiesInternship Certificate upon completionLetter of Recommendation based on performanceOpportunity to build a strong data science portfolioPotential full-time role based on performanceHow to ApplySubmit your resume and cover letter with the subject line:\u201cData Science Intern Application\u201d\ud83d\udcc5 Application Deadline: 03rd February 2026Equal Opportunity StatementDexter\u2019s Tech is an equal opportunity organization and encourages applications from candidates of all backgrounds.",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/data-science-intern-at-dexter-s-tech-4367788692?position=28&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=qLJm%2F2k33rkHBC50afXQpA%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:14:24.570378"
  },
  {
    "job_id": "linkedin_machine-learning-engineer-at-sourcingxpress-4367124842",
    "title": "Machine Learning Engineer",
    "company": "SourcingXPress",
    "location": "Bengaluru, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "Company: Hashone CareersWebsite: Visit WebsiteBusiness Type: StartupCompany Type: ProductBusiness Model: B2BFunding Stage: Pre-seedIndustry: HospitalitySalary Range: \u20b9 10-50 Lacs PAJob DescriptionThis is a permanent role with one of the product firm in Hospitality domain - A valued client of Hashone.About The RoleWe\u2019re looking for a Machine Learning Engineer to join the Data Science & Machine Learning team at LodgIQ. You'll be responsible for building systems and frameworks that power our machine learning applications, working closely with team members to deploy and scale their solutions.What You\u2019ll DoDesign and implement automated training and inference pipelines including building a model registry system to track model artifacts, versioning, and lineageDevelop frameworks for on-demand model training and architect parallel processing systems for inference and event-driven architectures with multi-optimization supportDesign and develop sophisticated APIs that expose ML model capabilitiesBuild ETL pipelines specifically tailored for ML applications and develop preprocessing frameworksImplement comprehensive monitoring solutions to identify system bottlenecks, optimize for enhanced scalabilityCreate infrastructure for offline and online experimentationBuild internal frameworks and tools that standardize ML workflows across the organizationStay current with developments in machine learning engineering and MLOps, evaluating and recommending new technologies and best practicesContribute to technical decision-making and architecture discussions to shape the future of our ML infrastructureRequired QualificationsBachelor's degree in Computer Science, Engineering, or related technical field (or equivalent experience)3+ years of experience in software engineering with a focus on ML systemsStrong programming skills in Python and experience with ML frameworks (TensorFlow, PyTorch, Scikit-learn)Experience building and maintaining production ML pipelinesProficiency with containerization technologies (Docker, Kubernetes)Experience with cloud platforms (AWS, GCP, or Azure) and their ML servicesUnderstanding of software engineering best practices including version control, CI/CD, and testingExperience with data processing frameworksStrong problem-solving skills and ability to work independently on complex technical challengesExcellent communication skills to collaborate with cross-functional teams",
    "requirements": "Company: Hashone CareersWebsite: Visit WebsiteBusiness Type: StartupCompany Type: ProductBusiness Model: B2BFunding Stage: Pre-seedIndustry: HospitalitySalary Range: \u20b9 10-50 Lacs PAJob DescriptionThis is a permanent role with one of the product firm in Hospitality domain - A valued client of Hashone.About The RoleWe\u2019re looking for a Machine Learning Engineer to join the Data Science & Machine Learning team at LodgIQ. You'll be responsible for building systems and frameworks that power our machine learning applications, working closely with team members to deploy and scale their solutions.What You\u2019ll DoDesign and implement automated training and inference pipelines including building a model registry system to track model artifacts, versioning, and lineageDevelop frameworks for on-demand model training and architect parallel processing systems for inference and event-driven architectures with multi-optimization supportDesign and develop sophisticated APIs that expose ML model capabilitiesBuild ETL pipelines specifically tailored for ML applications and develop preprocessing frameworksImplement comprehensive monitoring solutions to identify system bottlenecks, optimize for enhanced scalabilityCreate infrastructure for offline and online experimentationBuild internal frameworks and tools that standardize ML workflows across the organizationStay current with developments in machine learning engineering and MLOps, evaluating and recommending new technologies and best practicesContribute to technical decision-making and architecture discussions to shape the future of our ML infrastructureRequired QualificationsBachelor's degree in Computer Science, Engineering, or related technical field (or equivalent experience)3+ years of experience in software engineering with a focus on ML systemsStrong programming skills in Python and experience with ML frameworks (TensorFlow, PyTorch, Scikit-learn)Experience building and maintaining production ML pipelinesProficiency with containerization technologies (Docker, Kubernetes)Experience with cloud platforms (AWS, GCP, or Azure) and their ML servicesUnderstanding of software engineering best practices including version control, CI/CD, and testingExperience with data processing frameworksStrong problem-solving skills and ability to work independently on complex technical challengesExcellent communication skills to collaborate with cross-functional teams",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/machine-learning-engineer-at-sourcingxpress-4367124842?position=29&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=yeqgYS9MMkAdG%2Bd8bOQfMg%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:14:28.581039"
  },
  {
    "job_id": "linkedin_senior-data-scientist-at-tata-consultancy-services-4331524615",
    "title": "Senior Data Scientist",
    "company": "Tata Consultancy Services",
    "location": "Delhi, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "Greetings from TCS!We are looking for - Sr Data Scientist Experience: 6 to 15 YearsLocation: Kolkata, Kochi, DelhiA candidate for this position must have had at least 10 years of working experience working with in data science capacity within a fast-paced and complex business setting, preferably working as a Senior Data Scientist. The candidate will have hands-on experience in production implementation of generative AI infused analytics solution The candidate will also have experience working with natural language processing as well as experience working with machine learning libraries, for example, xgboost, OpenCV, sklearn, among others. The candidate must also have had substantial experience working on strategy or full-life cycle data science as well as experience working with data mining tools such as SAS, Python, SPSS, and R. A suitable candidate for this position will also have had experience in data mining and predictive modeling inclusive of linear and non-Linear regression, logistic regression, and time series analysis models. The candidate will also have had experience working with deep learning algorithms and large datasets as well as experience working with unstructured data and experience cleaning and manipulating data. The Senior Data Scientist will also be required to have exceptional communication skills in his collaborative role and in the delivery of clear, engaging, and understandable reports. The Senior Data Scientist must be capable of tailoring complex messages into simplified and business applicable material for key stakeholders and senior data science management Statistics & Data mining Generative AI and LLM (Open AI, Vertex, Llama etc.) Regression, Clustering, Classification & Recommendation engine Deep Neural networks NLP Well versed with R, Python, and preferably Scala Preferably exposure/ experience to Cloud native AI/ML services (AWS, Azure, GCP) Preferably exposure/ experience to BI tools like Tableau, power BI Business acumen in any domain\u2013 Finance, Supply Chain, Manufacturing, Life Sc., Healthcare, Utility or Telecom Domain knowledge Should have proven thought leadership in solving complex AI/ Data Science problems and consult with stakeholders to initiate projects aligned to business needs Work with business and customer stakeholders (both internal and external) to define product objectives and requirements applying data science principles to products and solutions across business units Liaise with data engineers on building end to end solution (data mining, data cleansing and data preparation activities) as part of end-to-end data lifecycle Evangelize AI/ML works done by the team internally and externally Interact with industry experts to understand and incorporate latest technology innovation, best practices in data sciences, data mining, and software development. Should have effective communication and interpersonal skills, with proven ability to take initiative and build strong, productive relationships. Responsibility of / Expectations from the Role  Customer Centric Work closely with client teams to understand project requirements and translate into technical design Experience working in scrum or with scrum teams Internal Collaboration Work with project teams and guide the end to end project lifecycle, resolve technical queries Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data needs. Soft Skills Good communication skills Ability to interact with various internal groups and CoEs",
    "requirements": "Greetings from TCS!We are looking for - Sr Data Scientist Experience: 6 to 15 YearsLocation: Kolkata, Kochi, DelhiA candidate for this position must have had at least 10 years of working experience working with in data science capacity within a fast-paced and complex business setting, preferably working as a Senior Data Scientist. The candidate will have hands-on experience in production implementation of generative AI infused analytics solution The candidate will also have experience working with natural language processing as well as experience working with machine learning libraries, for example, xgboost, OpenCV, sklearn, among others. The candidate must also have had substantial experience working on strategy or full-life cycle data science as well as experience working with data mining tools such as SAS, Python, SPSS, and R. A suitable candidate for this position will also have had experience in data mining and predictive modeling inclusive of linear and non-Linear regression, logistic regression, and time series analysis models. The candidate will also have had experience working with deep learning algorithms and large datasets as well as experience working with unstructured data and experience cleaning and manipulating data. The Senior Data Scientist will also be required to have exceptional communication skills in his collaborative role and in the delivery of clear, engaging, and understandable reports. The Senior Data Scientist must be capable of tailoring complex messages into simplified and business applicable material for key stakeholders and senior data science management Statistics & Data mining Generative AI and LLM (Open AI, Vertex, Llama etc.) Regression, Clustering, Classification & Recommendation engine Deep Neural networks NLP Well versed with R, Python, and preferably Scala Preferably exposure/ experience to Cloud native AI/ML services (AWS, Azure, GCP) Preferably exposure/ experience to BI tools like Tableau, power BI Business acumen in any domain\u2013 Finance, Supply Chain, Manufacturing, Life Sc., Healthcare, Utility or Telecom Domain knowledge Should have proven thought leadership in solving complex AI/ Data Science problems and consult with stakeholders to initiate projects aligned to business needs Work with business and customer stakeholders (both internal and external) to define product objectives and requirements applying data science principles to products and solutions across business units Liaise with data engineers on building end to end solution (data mining, data cleansing and data preparation activities) as part of end-to-end data lifecycle Evangelize AI/ML works done by the team internally and externally Interact with industry experts to understand and incorporate latest technology innovation, best practices in data sciences, data mining, and software development. Should have effective communication and interpersonal skills, with proven ability to take initiative and build strong, productive relationships. Responsibility of / Expectations from the Role  Customer Centric Work closely with client teams to understand project requirements and translate into technical design Experience working in scrum or with scrum teams Internal Collaboration Work with project teams and guide the end to end project lifecycle, resolve technical queries Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data needs. Soft Skills Good communication skills Ability to interact with various internal groups and CoEs",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/senior-data-scientist-at-tata-consultancy-services-4331524615?position=30&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=mAmHP%2BTsK9tD7RtTbbBaMw%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:14:31.989276"
  },
  {
    "job_id": "linkedin_ai-data-scientist-at-best-job-tool-4368147356",
    "title": "Ai Data Scientist",
    "company": "Best Job Tool",
    "location": "India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "AI Data Scientist Job DescriptionAbout The CompanyVerdantas is a leading consulting and engineering firm dedicated to providing innovative solutions across various sectors including environmental, infrastructure, and technology. With a commitment to excellence and sustainability, Verdantas leverages cutting-edge technologies and industry expertise to deliver impactful results for its clients worldwide. The company fosters a collaborative and inclusive work environment that encourages professional growth and continuous learning. As a top-ranked firm recognized among the top 81 in its industry, Verdantas prides itself on maintaining high standards of quality, integrity, and innovation in all its projects.About The RoleWe are seeking a highly skilled and motivated AI Data Scientist to join our dynamic team in Pune. This role is pivotal in driving our data-driven initiatives and leveraging artificial intelligence to solve complex business challenges. The ideal candidate will have a strong background in data science, machine learning, and AI frameworks, along with the ability to work collaboratively with cross-functional teams. As an AI Data Scientist at Verdantas, you will be responsible for developing advanced models, analyzing large datasets, and deploying AI solutions that enhance our operational efficiency and client offerings. This position offers an excellent opportunity to work on innovative projects using the latest AI technologies, including LangChain, Semantic Kernel, and Azure OpenAI Service, in a supportive and forward-thinking environment.QualificationsThe successful candidate should possess a bachelor\u2019s or master\u2019s degree in computer science, statistics, mathematics, or a related field. You should have between 3 to 5 years of professional experience in IT, data science, or related domains. Proven experience with AI frameworks such as LangChain, Semantic Kernel, and Azure OpenAI Service is essential. A strong foundation in statistics, data mining, and algorithm design is required to excel in this role. Proficiency in programming languages like Python, R, or SQL, along with experience working with REST APIs, is necessary. Familiarity with machine learning frameworks such as Scikit-learn and TensorFlow is expected. Additionally, experience working with cloud platforms like Azure, AWS, or GCP will be highly advantageous. Candidates must demonstrate excellent problem-solving skills, analytical thinking, and the ability to communicate complex insights effectively. Strong collaboration skills are vital to work seamlessly with multidisciplinary teams and stakeholders.ResponsibilitiesDevelop and implement advanced statistical models and machine learning algorithms to address business challenges and optimize processes.Clean, process, and analyze large and complex datasets from various sources, ensuring data quality and integrity.Create compelling data visualizations and reports using tools like Power BI, Tableau, or Python visualization libraries to communicate insights clearly to stakeholders.Collaborate closely with AI engineers and software developers to deploy models into production environments, ensuring scalability, robustness, and high performance.Monitor and evaluate model performance continuously, making improvements to enhance accuracy and efficiency.Stay updated with the latest advancements in AI and data science, applying innovative techniques to ongoing projects.Document methodologies, processes, and results to facilitate knowledge sharing and reproducibility across teams.BenefitsVerdantas offers a comprehensive benefits package designed to support your professional and personal well-being. Employees enjoy competitive salary packages, health insurance coverage, and retirement plans. The company promotes a healthy work-life balance through flexible working hours and paid time off. You will have access to ongoing training and development programs, including certifications, workshops, and conferences, to enhance your skills and career growth. Verdantas also fosters a collaborative and inclusive culture, encouraging innovation and diversity. Additional perks may include wellness programs, employee assistance programs, and opportunities for international exposure and project involvement.Equal OpportunityVerdantas is an equal opportunity employer committed to fostering an inclusive environment for all employees. We do not discriminate based on race, color, religion, gender, gender identity, sexual orientation, national origin, age, disability, or any other protected characteristic. We believe that diversity drives innovation and excellence, and we are dedicated to creating a workplace where everyone feels valued, respected, and empowered to contribute their best.",
    "requirements": "AI Data Scientist Job DescriptionAbout The CompanyVerdantas is a leading consulting and engineering firm dedicated to providing innovative solutions across various sectors including environmental, infrastructure, and technology. With a commitment to excellence and sustainability, Verdantas leverages cutting-edge technologies and industry expertise to deliver impactful results for its clients worldwide. The company fosters a collaborative and inclusive work environment that encourages professional growth and continuous learning. As a top-ranked firm recognized among the top 81 in its industry, Verdantas prides itself on maintaining high standards of quality, integrity, and innovation in all its projects.About The RoleWe are seeking a highly skilled and motivated AI Data Scientist to join our dynamic team in Pune. This role is pivotal in driving our data-driven initiatives and leveraging artificial intelligence to solve complex business challenges. The ideal candidate will have a strong background in data science, machine learning, and AI frameworks, along with the ability to work collaboratively with cross-functional teams. As an AI Data Scientist at Verdantas, you will be responsible for developing advanced models, analyzing large datasets, and deploying AI solutions that enhance our operational efficiency and client offerings. This position offers an excellent opportunity to work on innovative projects using the latest AI technologies, including LangChain, Semantic Kernel, and Azure OpenAI Service, in a supportive and forward-thinking environment.QualificationsThe successful candidate should possess a bachelor\u2019s or master\u2019s degree in computer science, statistics, mathematics, or a related field. You should have between 3 to 5 years of professional experience in IT, data science, or related domains. Proven experience with AI frameworks such as LangChain, Semantic Kernel, and Azure OpenAI Service is essential. A strong foundation in statistics, data mining, and algorithm design is required to excel in this role. Proficiency in programming languages like Python, R, or SQL, along with experience working with REST APIs, is necessary. Familiarity with machine learning frameworks such as Scikit-learn and TensorFlow is expected. Additionally, experience working with cloud platforms like Azure, AWS, or GCP will be highly advantageous. Candidates must demonstrate excellent problem-solving skills, analytical thinking, and the ability to communicate complex insights effectively. Strong collaboration skills are vital to work seamlessly with multidisciplinary teams and stakeholders.ResponsibilitiesDevelop and implement advanced statistical models and machine learning algorithms to address business challenges and optimize processes.Clean, process, and analyze large and complex datasets from various sources, ensuring data quality and integrity.Create compelling data visualizations and reports using tools like Power BI, Tableau, or Python visualization libraries to communicate insights clearly to stakeholders.Collaborate closely with AI engineers and software developers to deploy models into production environments, ensuring scalability, robustness, and high performance.Monitor and evaluate model performance continuously, making improvements to enhance accuracy and efficiency.Stay updated with the latest advancements in AI and data science, applying innovative techniques to ongoing projects.Document methodologies, processes, and results to facilitate knowledge sharing and reproducibility across teams.BenefitsVerdantas offers a comprehensive benefits package designed to support your professional and personal well-being. Employees enjoy competitive salary packages, health insurance coverage, and retirement plans. The company promotes a healthy work-life balance through flexible working hours and paid time off. You will have access to ongoing training and development programs, including certifications, workshops, and conferences, to enhance your skills and career growth. Verdantas also fosters a collaborative and inclusive culture, encouraging innovation and diversity. Additional perks may include wellness programs, employee assistance programs, and opportunities for international exposure and project involvement.Equal OpportunityVerdantas is an equal opportunity employer committed to fostering an inclusive environment for all employees. We do not discriminate based on race, color, religion, gender, gender identity, sexual orientation, national origin, age, disability, or any other protected characteristic. We believe that diversity drives innovation and excellence, and we are dedicated to creating a workplace where everyone feels valued, respected, and empowered to contribute their best.",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/ai-data-scientist-at-best-job-tool-4368147356?position=31&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=RsT1larGoMkPfWxFE7%2Bsmw%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:14:35.752523"
  },
  {
    "job_id": "linkedin_senior-machine-learning-engineer-at-r3-consultant-4368114683",
    "title": "Senior Machine Learning Engineer",
    "company": "r3 Consultant",
    "location": "Bengaluru, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Hybrid",
    "salary": null,
    "description": "Senior Machine Learning Engineer \u2013 Job DescriptionPosition: Senior Machine Learning EngineerExperience: 7+ yearsLocation: Bengaluru (Hybrid)Skills: Python, Machine Learning, Flask/FastAPI/Django, SQL, Data Pipelines, MLOpsRole SummaryThe Senior Machine Learning Engineer will design, build, and productionize machine learning solutions end to end, from data pipelines and model development to scalable deployment and monitoring. The role combines strong software engineering fundamentals with deep ML expertise and ownership of production systems, including reliability, performance, and cost.Key ResponsibilitiesMachine Learning & ModelingDesign, develop, and deploy machine learning models and algorithms for production use with clear SLAs and business impact.Perform exploratory data analysis to uncover insights, define hypotheses, and guide feature and model design.Develop robust feature engineering workflows; manage feature definitions, lineage, and reuse across teams and projects. Define and monitor offline and online metrics, ensuring rigorous evaluation, experiment design, and statistical testing.Data Engineering & PipelinesBuild and maintain scalable, reliable batch and streaming data pipelines for training and inference.Work with large, complex datasets using SQL and data processing frameworks (Spark/Beam/Flink) and streaming platforms (Kafka/Kinesis).Ensure data quality, integrity, and consistency, including proactive monitoring for data drift and anomalies.MLOps, Deployment & ObservabilityImplement model serving as APIs/services (REST/gRPC) using Flask/FastAPI/Django with proper versioning and rollback strategies.Establish CI/CD for ML: automated testing, packaging, model artifact management, and safe deployment (canary/blue\u2011green).Set up experiment tracking, model registry, and reproducible training workflows.Implement observability across data, models, and services (latency, throughput, drift, data quality, and cost).Participate in incident response and on\u2011call rotations for ML services; troubleshoot and resolve production issues.Collaboration, Leadership & GovernanceCollaborate with product, data, and platform teams to translate business requirements into technical designs, roadmaps, and detailed user stories.Mentor and guide junior engineers; set and review FAST goals (Frequently discussed, Ambitious, Specific, Transparent) for self and team.Conduct and participate in code reviews, design reviews, and technical discussions to maintain high engineering standards. Communicate complex technical topics clearly to non\u2011technical stakeholders, including through presentations and customer calls.Required Qualifications & SkillsTechnical SkillsMinimum 7 years of hands\u2011on experience in machine learning, data analysis, and feature engineering with production ownership.Strong proficiency in Python and core libraries (NumPy, pandas, scikit\u2011learn); exposure to deep learning frameworks is a plus.Experience with at least one web framework such as Flask, FastAPI, or Django to build production\u2011grade APIs.Solid understanding of ML algorithms, evaluation techniques, experiment design, and statistical testing.Strong software engineering skills: modular design, type hints, unit/integration testing (e.g., pytest), logging, and profiling.Proficiency in SQL and data modeling; experience with performance optimization on large datasets.Hands\u2011on experience with data processing frameworks (Spark/Beam/Flink) and streaming platforms (Kafka/Kinesis).Experience with containers and orchestration (Docker, Kubernetes) and infrastructure\u2011as\u2011code concepts.Familiarity with CI/CD tools (GitHub Actions, GitLab CI, Jenkins, etc.) for automating ML builds and releases.Monitoring/observability experience (Prometheus, Grafana, OpenTelemetry) and implementing data quality checks/drift detection.Nice to HaveExperience with cloud platforms (AWS preferred) and services such as S3, ECR, ECS/EKS, Lambda/Batch, and IAM.Experience with MLOps tools and practices: feature stores, data/model versioning (DVC, LakeFS), workflow orchestrators (Airflow, Dagster, etc.).Experience in one or more domains: NLP, computer vision, recommendation/ranking systems, or time\u2011series forecasting.Familiarity with dashboarding and visualization tools (Matplotlib, Plotly, Grafana, Streamlit) for analysis and monitoring.Behavioral & Leadership CompetenciesStrong analytical and problem\u2011solving skills with the ability to break down complex problems into logical components. Ability to work under pressure, handle multiple tasks, and manage dependencies and risks effectively. Excellent verbal and written communication; high standard of business etiquette in emails, documentation, and customer interactions. Proven ability to build trust with stakeholders by delivering high\u2011quality solutions on time and with measurable value.Proactive, collaborative mindset: asks for and offers help, drives alignment across teams, and maintains high team motivation and engagement.Education & CertificationsBachelor\u2019s or Master\u2019s degree in Computer Science, Data Science, Engineering, or a related field.Relevant certifications in cloud, data engineering, or MLOps/ML are an added advantage.",
    "requirements": "Senior Machine Learning Engineer \u2013 Job DescriptionPosition: Senior Machine Learning EngineerExperience: 7+ yearsLocation: Bengaluru (Hybrid)Skills: Python, Machine Learning, Flask/FastAPI/Django, SQL, Data Pipelines, MLOpsRole SummaryThe Senior Machine Learning Engineer will design, build, and productionize machine learning solutions end to end, from data pipelines and model development to scalable deployment and monitoring. The role combines strong software engineering fundamentals with deep ML expertise and ownership of production systems, including reliability, performance, and cost.Key ResponsibilitiesMachine Learning & ModelingDesign, develop, and deploy machine learning models and algorithms for production use with clear SLAs and business impact.Perform exploratory data analysis to uncover insights, define hypotheses, and guide feature and model design.Develop robust feature engineering workflows; manage feature definitions, lineage, and reuse across teams and projects. Define and monitor offline and online metrics, ensuring rigorous evaluation, experiment design, and statistical testing.Data Engineering & PipelinesBuild and maintain scalable, reliable batch and streaming data pipelines for training and inference.Work with large, complex datasets using SQL and data processing frameworks (Spark/Beam/Flink) and streaming platforms (Kafka/Kinesis).Ensure data quality, integrity, and consistency, including proactive monitoring for data drift and anomalies.MLOps, Deployment & ObservabilityImplement model serving as APIs/services (REST/gRPC) using Flask/FastAPI/Django with proper versioning and rollback strategies.Establish CI/CD for ML: automated testing, packaging, model artifact management, and safe deployment (canary/blue\u2011green).Set up experiment tracking, model registry, and reproducible training workflows.Implement observability across data, models, and services (latency, throughput, drift, data quality, and cost).Participate in incident response and on\u2011call rotations for ML services; troubleshoot and resolve production issues.Collaboration, Leadership & GovernanceCollaborate with product, data, and platform teams to translate business requirements into technical designs, roadmaps, and detailed user stories.Mentor and guide junior engineers; set and review FAST goals (Frequently discussed, Ambitious, Specific, Transparent) for self and team.Conduct and participate in code reviews, design reviews, and technical discussions to maintain high engineering standards. Communicate complex technical topics clearly to non\u2011technical stakeholders, including through presentations and customer calls.Required Qualifications & SkillsTechnical SkillsMinimum 7 years of hands\u2011on experience in machine learning, data analysis, and feature engineering with production ownership.Strong proficiency in Python and core libraries (NumPy, pandas, scikit\u2011learn); exposure to deep learning frameworks is a plus.Experience with at least one web framework such as Flask, FastAPI, or Django to build production\u2011grade APIs.Solid understanding of ML algorithms, evaluation techniques, experiment design, and statistical testing.Strong software engineering skills: modular design, type hints, unit/integration testing (e.g., pytest), logging, and profiling.Proficiency in SQL and data modeling; experience with performance optimization on large datasets.Hands\u2011on experience with data processing frameworks (Spark/Beam/Flink) and streaming platforms (Kafka/Kinesis).Experience with containers and orchestration (Docker, Kubernetes) and infrastructure\u2011as\u2011code concepts.Familiarity with CI/CD tools (GitHub Actions, GitLab CI, Jenkins, etc.) for automating ML builds and releases.Monitoring/observability experience (Prometheus, Grafana, OpenTelemetry) and implementing data quality checks/drift detection.Nice to HaveExperience with cloud platforms (AWS preferred) and services such as S3, ECR, ECS/EKS, Lambda/Batch, and IAM.Experience with MLOps tools and practices: feature stores, data/model versioning (DVC, LakeFS), workflow orchestrators (Airflow, Dagster, etc.).Experience in one or more domains: NLP, computer vision, recommendation/ranking systems, or time\u2011series forecasting.Familiarity with dashboarding and visualization tools (Matplotlib, Plotly, Grafana, Streamlit) for analysis and monitoring.Behavioral & Leadership CompetenciesStrong analytical and problem\u2011solving skills with the ability to break down complex problems into logical components. Ability to work under pressure, handle multiple tasks, and manage dependencies and risks effectively. Excellent verbal and written communication; high standard of business etiquette in emails, documentation, and customer interactions. Proven ability to build trust with stakeholders by delivering high\u2011quality solutions on time and with measurable value.Proactive, collaborative mindset: asks for and offers help, drives alignment across teams, and maintains high team motivation and engagement.Education & CertificationsBachelor\u2019s or Master\u2019s degree in Computer Science, Data Science, Engineering, or a related field.Relevant certifications in cloud, data engineering, or MLOps/ML are an added advantage.",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/senior-machine-learning-engineer-at-r3-consultant-4368114683?position=32&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=rJxVlaGhBprapmu3GSe8NQ%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:14:39.598964"
  },
  {
    "job_id": "linkedin_machine-learning-engineer-iii-recommendation-systems-at-glance-4367798411",
    "title": "Machine Learning Engineer III - Recommendation Systems",
    "company": "Glance",
    "location": "Bengaluru, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "What you will be doingWe are looking for a Data Scientist who can operate at the intersection of classical machine learning, large-scale recommendation systems, and modern agentic AI systems.You will design, build, and deploy intelligent systems that power Glance\u2019s personalized lock screen and live entertainment experiences. This role blends deep ML craftsmanship with forward-looking innovation in autonomous/agentic systems.Your responsibilities will include:Classical ML & Recommendation SystemsDesign and develop large-scale recommendation systems using advanced ML, statistical modelling, ranking algorithms, and deep learning.Build and operate machine learning models on diverse, high-volume data sources for personalization, prediction, and content understanding.Develop rapid experimentation workflows to validate hypotheses and measure real-world business impact.Own data preparation, model training, evaluation, and deployment pipelines in collaboration with engineering counterparts.Monitor ML model performance using statistical techniques; identify drifts, failure modes, and improvement opportunities.Agentic Systems & Next-Gen AIBuild and experiment with agentic AI systems that autonomously observe model performance, trigger experiments, tune hyperparameters, improve ranking policies, or orchestrate ML workflows with minimal human intervention.Apply LLMs, embeddings, retrieval-augmented architectures, and multimodal generative models for semantic understanding, content classification, and user preference modelling.Design intelligent agents that can automate repetitive decision-making tasks\u2014e.g., candidate generation tuning, feature selection, or context-aware content curation.Explore reinforcement learning, contextual bandits, and self-improving systems to power next-generation personalization.Cross-functional impactCollaborate with Designers, UX Researchers, Product Managers, and Software Engineers to integrate ML and GenAI-driven features into Glance\u2019s consumer experiences.Contribute to Glance\u2019s ML/AI thought leadership\u2014blogs, case studies, internal tech talks, and industry conferences.Thrive in a multi-functional, highly collaborative team environment with engineering, product, business, and creative teams.Plus: Interface with stakeholders across Product, Business, Data, and Infrastructure to align ML initiatives with strategic priorities.We are seeking candidates with deep expertise in ML, recommendation systems, and a strong appetite for building agentic AI systems.You should have experience with:Large-scale ML and recommendation systems (collaborative filtering, ranking models, content-based approaches, embeddings).Classical ML and deep learning techniques across NLP, sequence modelling, RL, clustering, and time series.Experience in deploying ML workflows/models in production systemBig data processing (Spark, distributed data systems) and cloud computing.Designing end-to-end ML solutions\u2014from prototype to production.Plus: Building or experimenting with LLMs, generative models, and agentic AI workflows (e.g., autonomous evaluators, self-improving pipelines, automated experiment agents).QualificationsBachelor\u2019s/master\u2019s in computer science, Statistics, Mathematics, Electrical Engineering, Operations Research, Economics, Analytics, or related fields. PhD is a plus.6+ years of industry experience in ML/Data Science, ideally in large-scale recommendation systems or personalization.Experience with LLMs, retrieval systems, generative models, or agentic/autonomous ML systems is highly desirable.Expertise with algorithms in NLP, Reinforcement Learning, Time Series, and Deep Learning, applied on real-world datasets.Proficient in Python and comfortable with statistical tools (R, NumPy, SciPy, PyTorch/TensorFlow, etc.).Strong experience with the big data ecosystem (Spark, Hadoop) and cloud platforms (Azure, AWS, GCP/Vertex AI).Comfortable working in cross-functional teams.Familiarity with privacy-preserving ML and identity-less ecosystems (especially on iOS and Android).Excellent communication skills with the ability to simplify complex technical concepts. We value curiosity, problem-solving ability, and a strong bias toward experimentation and production impact.Our team includes engineers, physicists, economists, mathematicians, and social scientists\u2014a great data scientist can come from anywhere.",
    "requirements": "What you will be doingWe are looking for a Data Scientist who can operate at the intersection of classical machine learning, large-scale recommendation systems, and modern agentic AI systems.You will design, build, and deploy intelligent systems that power Glance\u2019s personalized lock screen and live entertainment experiences. This role blends deep ML craftsmanship with forward-looking innovation in autonomous/agentic systems.Your responsibilities will include:Classical ML & Recommendation SystemsDesign and develop large-scale recommendation systems using advanced ML, statistical modelling, ranking algorithms, and deep learning.Build and operate machine learning models on diverse, high-volume data sources for personalization, prediction, and content understanding.Develop rapid experimentation workflows to validate hypotheses and measure real-world business impact.Own data preparation, model training, evaluation, and deployment pipelines in collaboration with engineering counterparts.Monitor ML model performance using statistical techniques; identify drifts, failure modes, and improvement opportunities.Agentic Systems & Next-Gen AIBuild and experiment with agentic AI systems that autonomously observe model performance, trigger experiments, tune hyperparameters, improve ranking policies, or orchestrate ML workflows with minimal human intervention.Apply LLMs, embeddings, retrieval-augmented architectures, and multimodal generative models for semantic understanding, content classification, and user preference modelling.Design intelligent agents that can automate repetitive decision-making tasks\u2014e.g., candidate generation tuning, feature selection, or context-aware content curation.Explore reinforcement learning, contextual bandits, and self-improving systems to power next-generation personalization.Cross-functional impactCollaborate with Designers, UX Researchers, Product Managers, and Software Engineers to integrate ML and GenAI-driven features into Glance\u2019s consumer experiences.Contribute to Glance\u2019s ML/AI thought leadership\u2014blogs, case studies, internal tech talks, and industry conferences.Thrive in a multi-functional, highly collaborative team environment with engineering, product, business, and creative teams.Plus: Interface with stakeholders across Product, Business, Data, and Infrastructure to align ML initiatives with strategic priorities.We are seeking candidates with deep expertise in ML, recommendation systems, and a strong appetite for building agentic AI systems.You should have experience with:Large-scale ML and recommendation systems (collaborative filtering, ranking models, content-based approaches, embeddings).Classical ML and deep learning techniques across NLP, sequence modelling, RL, clustering, and time series.Experience in deploying ML workflows/models in production systemBig data processing (Spark, distributed data systems) and cloud computing.Designing end-to-end ML solutions\u2014from prototype to production.Plus: Building or experimenting with LLMs, generative models, and agentic AI workflows (e.g., autonomous evaluators, self-improving pipelines, automated experiment agents).QualificationsBachelor\u2019s/master\u2019s in computer science, Statistics, Mathematics, Electrical Engineering, Operations Research, Economics, Analytics, or related fields. PhD is a plus.6+ years of industry experience in ML/Data Science, ideally in large-scale recommendation systems or personalization.Experience with LLMs, retrieval systems, generative models, or agentic/autonomous ML systems is highly desirable.Expertise with algorithms in NLP, Reinforcement Learning, Time Series, and Deep Learning, applied on real-world datasets.Proficient in Python and comfortable with statistical tools (R, NumPy, SciPy, PyTorch/TensorFlow, etc.).Strong experience with the big data ecosystem (Spark, Hadoop) and cloud platforms (Azure, AWS, GCP/Vertex AI).Comfortable working in cross-functional teams.Familiarity with privacy-preserving ML and identity-less ecosystems (especially on iOS and Android).Excellent communication skills with the ability to simplify complex technical concepts. We value curiosity, problem-solving ability, and a strong bias toward experimentation and production impact.Our team includes engineers, physicists, economists, mathematicians, and social scientists\u2014a great data scientist can come from anywhere.",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/machine-learning-engineer-iii-recommendation-systems-at-glance-4367798411?position=33&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=GPHZa777iuW6BvHlNBe4mQ%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:14:43.499168"
  },
  {
    "job_id": "linkedin_quality-assurance-engineer-at-bennett-coleman-co-ltd-the-times-of-india-4367774747",
    "title": "Quality Assurance Engineer",
    "company": "Bennett Coleman & Co. Ltd. (The Times of India)",
    "location": "Delhi, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "About Bennett, Coleman & Co. Ltd. (The Times of India)We are India's largest media conglomerate, known for our leading publications such as The Times of India, The Economic Times, and many others. With a rich heritage of over 180 years, we are dedicated to delivering news, information, and entertainment to millions of readers across the country. Our commitment to journalistic excellence, innovation, and integrity makes us a trusted name in the industry.As our reputation precedes us, we are a Print++ company, with print being our core, on a transformative journey to bring newer content consumption experiences.Come be a part of our growing family!About the Hiring FunctionThe Product and Technology team is integral to our organization, driving innovation and the development of print and digital products that enhance reader engagement and operational efficiency. The hiring function within this team is dedicated to attracting and retaining top talent across various roles, including product management, software development, UX/UI design, and data analytics.About the Role We are looking for a modern, engineering-focused QA Engineer to be an integral part of a cross-functional POD driving transformation across newsroom and digital publishing platforms. This role goes beyond traditional manual testing, with a strong emphasis on automation, quality engineering, and shift-left testing practices. You will work closely with developers, product managers, and designers to embed quality throughout the development lifecycle, proactively identify risks, and ensure the delivery of high-quality, reliable, and scalable systems that support fast-paced newsroom operations.Roles & Responsibilities: Quality Engineering & AutomationDesign, develop, and maintain automated test suites for web applications and APIs.Implement test automation across functional, regression, integration, and smoke testingContribute to test automation frameworks and reusable test components.Validate APIs, backend services, and data flows using automated and exploratory approaches.POD Collaboration & Shift-Left QA Work closely with engineers and product managers from early design stages to embed quality into development.Participate in requirement reviews, sprint planning, and design discussions to identify quality risks early.Collaborate with developers to define acceptance criteria and test coverage.CI/CD & DevOps Integration Integrate automated tests into CI/CD pipelines to enable continuous testing.Ensure test execution, reporting, and failure analysis are part of the deployment workflow.Actively participate in release validation and production readiness activities.Manual & Exploratory Testing Perform focused exploratory and scenario-based testing where automation is not sufficient.Validate user journeys, newsroom workflows, and edge cases critical to editorial operations.Support UAT and production verification when required.Education and Experience Required:B.Tech in Computer Science or MCA/BCA from a reputed institute.2\u20134 years of experience in software quality assurance or quality engineering.Knowledge and Skills:Strong understanding of modern QA practices, including shift-left testing and test pyramid concepts.Hands-on experience with test automation tools/frameworks (e.g., Selenium, Cypress, Playwright, WebdriverIO, etc.) Experience testing RESTful or GraphQL APIs using tools such as Postman, RestAssured, or similar.Basic to intermediate proficiency in at least one programming or scripting language (e.g., Java, JavaScript, Python, etc.) Experience working with CI/CD pipelines (e.g., Jenkins, GitHub Actions, GitLab CI, etc.) Solid understanding of test design techniques, defect management, and test reporting.Good to Have:Experience with performance or load testing tools (e.g., JMeter, k6, Gatling)Familiarity with containerized environments (Docker) and cloud-based testing setup.Experience testing content-heavy, high-traffic web platforms.Exposure to accessibility testing, cross-browser testing, and mobile web testing.Experience working in Agile/Scrum teams.What is in it For You?Inclusive Workplace: We are an inclusive place to work, where diversity is valued, and everyone feels welcomed. We embrace everyone with open hearts and minds. Embracing Change: We welcome change and encourage innovative thinking and adaptability in our dynamic environment.Growth Opportunities: We believe we grow when our people grow, offering numerous opportunities for professional and personal development.People-Centric Policies: Our policies are designed with our people in mind, including a creche facility, comprehensive leave policies, flexible work hours, guest house facility, a robust POSH (Prevention of Sexual Harassment) policy, to name a few.Collaborative Culture: We foster a positive and collaborative culture, where employees are encouraged to share ideas, support each other, and work together towards common goals. At BCCL, we are more than colleagues; we are a family.",
    "requirements": "About Bennett, Coleman & Co. Ltd. (The Times of India)We are India's largest media conglomerate, known for our leading publications such as The Times of India, The Economic Times, and many others. With a rich heritage of over 180 years, we are dedicated to delivering news, information, and entertainment to millions of readers across the country. Our commitment to journalistic excellence, innovation, and integrity makes us a trusted name in the industry.As our reputation precedes us, we are a Print++ company, with print being our core, on a transformative journey to bring newer content consumption experiences.Come be a part of our growing family!About the Hiring FunctionThe Product and Technology team is integral to our organization, driving innovation and the development of print and digital products that enhance reader engagement and operational efficiency. The hiring function within this team is dedicated to attracting and retaining top talent across various roles, including product management, software development, UX/UI design, and data analytics.About the Role We are looking for a modern, engineering-focused QA Engineer to be an integral part of a cross-functional POD driving transformation across newsroom and digital publishing platforms. This role goes beyond traditional manual testing, with a strong emphasis on automation, quality engineering, and shift-left testing practices. You will work closely with developers, product managers, and designers to embed quality throughout the development lifecycle, proactively identify risks, and ensure the delivery of high-quality, reliable, and scalable systems that support fast-paced newsroom operations.Roles & Responsibilities: Quality Engineering & AutomationDesign, develop, and maintain automated test suites for web applications and APIs.Implement test automation across functional, regression, integration, and smoke testingContribute to test automation frameworks and reusable test components.Validate APIs, backend services, and data flows using automated and exploratory approaches.POD Collaboration & Shift-Left QA Work closely with engineers and product managers from early design stages to embed quality into development.Participate in requirement reviews, sprint planning, and design discussions to identify quality risks early.Collaborate with developers to define acceptance criteria and test coverage.CI/CD & DevOps Integration Integrate automated tests into CI/CD pipelines to enable continuous testing.Ensure test execution, reporting, and failure analysis are part of the deployment workflow.Actively participate in release validation and production readiness activities.Manual & Exploratory Testing Perform focused exploratory and scenario-based testing where automation is not sufficient.Validate user journeys, newsroom workflows, and edge cases critical to editorial operations.Support UAT and production verification when required.Education and Experience Required:B.Tech in Computer Science or MCA/BCA from a reputed institute.2\u20134 years of experience in software quality assurance or quality engineering.Knowledge and Skills:Strong understanding of modern QA practices, including shift-left testing and test pyramid concepts.Hands-on experience with test automation tools/frameworks (e.g., Selenium, Cypress, Playwright, WebdriverIO, etc.) Experience testing RESTful or GraphQL APIs using tools such as Postman, RestAssured, or similar.Basic to intermediate proficiency in at least one programming or scripting language (e.g., Java, JavaScript, Python, etc.) Experience working with CI/CD pipelines (e.g., Jenkins, GitHub Actions, GitLab CI, etc.) Solid understanding of test design techniques, defect management, and test reporting.Good to Have:Experience with performance or load testing tools (e.g., JMeter, k6, Gatling)Familiarity with containerized environments (Docker) and cloud-based testing setup.Experience testing content-heavy, high-traffic web platforms.Exposure to accessibility testing, cross-browser testing, and mobile web testing.Experience working in Agile/Scrum teams.What is in it For You?Inclusive Workplace: We are an inclusive place to work, where diversity is valued, and everyone feels welcomed. We embrace everyone with open hearts and minds. Embracing Change: We welcome change and encourage innovative thinking and adaptability in our dynamic environment.Growth Opportunities: We believe we grow when our people grow, offering numerous opportunities for professional and personal development.People-Centric Policies: Our policies are designed with our people in mind, including a creche facility, comprehensive leave policies, flexible work hours, guest house facility, a robust POSH (Prevention of Sexual Harassment) policy, to name a few.Collaborative Culture: We foster a positive and collaborative culture, where employees are encouraged to share ideas, support each other, and work together towards common goals. At BCCL, we are more than colleagues; we are a family.",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/quality-assurance-engineer-at-bennett-coleman-co-ltd-the-times-of-india-4367774747?position=34&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=jRenU7mqjGcIZfIC4H80zg%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:14:47.213448"
  },
  {
    "job_id": "linkedin_data-scientist-at-enterprise-bot-4357480014",
    "title": "Data Scientist",
    "company": "Enterprise Bot",
    "location": "Bengaluru, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "Enterprise Bot is the leading provider of GenAI, Conversational AI, and automation software, headquartered in Zurich, Switzerland. Our intelligent virtual assistants and automation tools help organizations improve efficiency, reduce costs, and deliver exceptional customer experiences across industries such as banking, insurance, and logistics. Our mission is to become the world\u2019s #1 AI-driven automation software provider within the next five years.We work with leading companies such as the SIX Group (Swiss Stock Exchange), SWICA, Generali, and others to enhance customer interactions and automate business processes using our cutting-edge Conversational AI technology.Our global team includes more than 70 highly skilled professionals from diverse backgrounds.We foster an open, progressive company culture with state-of-the-art technology and flat hierarchies. At Enterprise Bot, you\u2019ll experience a unique blend of passion, purpose, challenge, and fun.TasksWe are looking for a full-time Data Scientist for our Bangalore office. As an integral part of the team, you will work within multi-disciplinary teams and with external collaborators to identify opportunities for leveraging data, developing proof-of-value prototypes and implementing data science and AI solutions that solve R&D enterprise level problems.Role & Responsibilities:The data scientist will be responsible for design and development of deep learning & LLM based models on unstructured and Structured Data.Will focus on not just on designing the algorithm but also on delivering it at scale.Will build and deploy deep learning techniques in production.Design and develop software modules that perform data ingest, data transform, and analytics tasks.Deliver customized solutions in a timely manner.Monitor and maintain high quality and accuracy of models during deployment.RequirementsCandidates should have 2-3 years of experience in the fields of machine learning, deep learning, LLM-based models, NLP, and data science.Strong skills in Python.Hands-on experience in developing & running machine learning applications in production.Familiarity with training and serving large language models in production.Hands on experience in building and implementing advanced statistical analysis and machine learning and data mining.Strong understanding of fundamentals of Computer Science.BenefitsBe part of a rapidly growing company at the forefront of AI automation and conversational AI solutions used by leading global enterprises.Shape solutions that make a measurable impact for Fortune 500 clients and leading European enterprises.A culture comprised of diverse, global teams who have a passion for collaboration, creativity, and excellence in client serviceA competitive salary and scope for further advancement.A great environment that promotes open feedback and a flat hierarchy, working at Enterprise Bot is a refreshing mix of purpose, challenge, and fun.If you\u2019re passionate about technology, love solving complex problems, and are eager to be part of a dynamic, innovative team, your journey starts here. Join us in harnessing cutting-edge AI solutions to drive data-driven insights and make a lasting impact.",
    "requirements": "Enterprise Bot is the leading provider of GenAI, Conversational AI, and automation software, headquartered in Zurich, Switzerland. Our intelligent virtual assistants and automation tools help organizations improve efficiency, reduce costs, and deliver exceptional customer experiences across industries such as banking, insurance, and logistics. Our mission is to become the world\u2019s #1 AI-driven automation software provider within the next five years.We work with leading companies such as the SIX Group (Swiss Stock Exchange), SWICA, Generali, and others to enhance customer interactions and automate business processes using our cutting-edge Conversational AI technology.Our global team includes more than 70 highly skilled professionals from diverse backgrounds.We foster an open, progressive company culture with state-of-the-art technology and flat hierarchies. At Enterprise Bot, you\u2019ll experience a unique blend of passion, purpose, challenge, and fun.TasksWe are looking for a full-time Data Scientist for our Bangalore office. As an integral part of the team, you will work within multi-disciplinary teams and with external collaborators to identify opportunities for leveraging data, developing proof-of-value prototypes and implementing data science and AI solutions that solve R&D enterprise level problems.Role & Responsibilities:The data scientist will be responsible for design and development of deep learning & LLM based models on unstructured and Structured Data.Will focus on not just on designing the algorithm but also on delivering it at scale.Will build and deploy deep learning techniques in production.Design and develop software modules that perform data ingest, data transform, and analytics tasks.Deliver customized solutions in a timely manner.Monitor and maintain high quality and accuracy of models during deployment.RequirementsCandidates should have 2-3 years of experience in the fields of machine learning, deep learning, LLM-based models, NLP, and data science.Strong skills in Python.Hands-on experience in developing & running machine learning applications in production.Familiarity with training and serving large language models in production.Hands on experience in building and implementing advanced statistical analysis and machine learning and data mining.Strong understanding of fundamentals of Computer Science.BenefitsBe part of a rapidly growing company at the forefront of AI automation and conversational AI solutions used by leading global enterprises.Shape solutions that make a measurable impact for Fortune 500 clients and leading European enterprises.A culture comprised of diverse, global teams who have a passion for collaboration, creativity, and excellence in client serviceA competitive salary and scope for further advancement.A great environment that promotes open feedback and a flat hierarchy, working at Enterprise Bot is a refreshing mix of purpose, challenge, and fun.If you\u2019re passionate about technology, love solving complex problems, and are eager to be part of a dynamic, innovative team, your journey starts here. Join us in harnessing cutting-edge AI solutions to drive data-driven insights and make a lasting impact.",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/data-scientist-at-enterprise-bot-4357480014?position=35&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=Nd7JEmQFaF37Q6%2BTdgIf7g%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:14:50.726750"
  },
  {
    "job_id": "linkedin_senior-data-scientist-at-hellowork-consultants-4357441027",
    "title": "Senior Data Scientist",
    "company": "Hellowork Consultants",
    "location": "Bengaluru, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Hybrid",
    "salary": null,
    "description": "\u2728Role: Sr Data Scientist\ud83d\udccd Location: Bangalore/Hyderabad\ud83e\udde0 Experience: 6+ Years\ud83d\udd52 Notice Period: 0\u201330 Days\ud83d\udcbc Work Mode: Hybrid\ud83c\udfa5 Interview Mode: Virtual or F2F(Maybe for Final Round)Roles & responsibilities:Here are some of the key responsibilities of Sr Data Scientist:1. Model Development Support: You will support the design, development, and implementation of generative AI models and systems. This involves understanding the problem domain, assisting in selecting appropriate models, helping in training them on large datasets, and fine-tuning hyperparameters under supervision.2. Algorithm Support: You will assist in optimizing generative AI algorithms to improve their efficiency, scalability, and computational performance. This may involve learning about parallelization, distributed computing, and hardware acceleration techniques.3. Data Preprocessing and Feature Engineering: You will assist in working with large datasets, preprocess them, and perform feature engineering to extract relevant information for generative AI models. This includes learning about data cleaning, normalization, dimensionality reduction, and feature selection.4. Model Evaluation and Validation: You will assist in evaluating the performance of generative AI models using appropriate metrics and validation techniques. This involves conducting experiments, analyzing results, and iteratively refining models under the guidance of senior team members.5. Collaboration and Teamwork: You will collaborate with cross-functional teams, including data scientists, software engineers, and domain experts, to understand requirements, gather feedback, and integrate generative AI models into larger systems or applications.6. Learning and Development: As an associate, you will focus on learning and developing your skills in generative AI. This includes receiving mentoring, having your work reviewed, and gaining hands-on experience.7. Documentation and Reporting: You will assist in documenting work, including model architectures, methodologies, and experimental results. You may also be responsible for preparing reports under supervision.8. Ethical Considerations: You will learn about the ethical implications of generative AI models, such as generating biased or inappropriate content. As an associate, you should be aware of these considerations and ensure that your work adheres to ethical guidelines and principles under the guidance of senior team members.Mandatory technical & functional skills:\u00b7 In depth knowledge on ML, Deep Learning and NLP algorithms, LLMs ( BERT, GEPT, etc.) and hands-on LangChain, OpenAI LLM Libraries , VectorDBs (Chroma, FAISS, etc),\u00b7 Hands-on ML platforms offered through GCP : Vertex AI or Azure : AI Foundry or AWS SageMaker\u00b7 Proficiency in Python, Java, or C++, and machine learning frameworks like TensorFlow or PyTorch developing deep learning projects is crucial.\u00b7 Develop and optimize generative AI models, collaborating with cross-functional teams and researching cutting-edge techniques\u00b7 Ensure scalability and efficiency, handle data tasks, stay current with AI trends, and contribute to model documentation for internal and external audiences.\u00b7 Cloud computing experience, particularly with Google/Azure Cloud Platform, is essential. With strong foundation in understating Data Analytics Services offered by Google or Azure ( BigQuery/Synapse)Preferred technical & functional skills:\u2014 Good knowledge on Azure Cognitive Search, Google Cloud Search, AWS Kendra\u2014 Large scale deployment of ML projects, with good understanding of DevOps /MLOps /LLM Ops\u2014 Strong oral and written communication skills with the ability to communicate technical and non-technical concepts to peers and stakeholders\u2014 Ability to work independently with minimal supervision, and escalate when needed",
    "requirements": "\u2728Role: Sr Data Scientist\ud83d\udccd Location: Bangalore/Hyderabad\ud83e\udde0 Experience: 6+ Years\ud83d\udd52 Notice Period: 0\u201330 Days\ud83d\udcbc Work Mode: Hybrid\ud83c\udfa5 Interview Mode: Virtual or F2F(Maybe for Final Round)Roles & responsibilities:Here are some of the key responsibilities of Sr Data Scientist:1. Model Development Support: You will support the design, development, and implementation of generative AI models and systems. This involves understanding the problem domain, assisting in selecting appropriate models, helping in training them on large datasets, and fine-tuning hyperparameters under supervision.2. Algorithm Support: You will assist in optimizing generative AI algorithms to improve their efficiency, scalability, and computational performance. This may involve learning about parallelization, distributed computing, and hardware acceleration techniques.3. Data Preprocessing and Feature Engineering: You will assist in working with large datasets, preprocess them, and perform feature engineering to extract relevant information for generative AI models. This includes learning about data cleaning, normalization, dimensionality reduction, and feature selection.4. Model Evaluation and Validation: You will assist in evaluating the performance of generative AI models using appropriate metrics and validation techniques. This involves conducting experiments, analyzing results, and iteratively refining models under the guidance of senior team members.5. Collaboration and Teamwork: You will collaborate with cross-functional teams, including data scientists, software engineers, and domain experts, to understand requirements, gather feedback, and integrate generative AI models into larger systems or applications.6. Learning and Development: As an associate, you will focus on learning and developing your skills in generative AI. This includes receiving mentoring, having your work reviewed, and gaining hands-on experience.7. Documentation and Reporting: You will assist in documenting work, including model architectures, methodologies, and experimental results. You may also be responsible for preparing reports under supervision.8. Ethical Considerations: You will learn about the ethical implications of generative AI models, such as generating biased or inappropriate content. As an associate, you should be aware of these considerations and ensure that your work adheres to ethical guidelines and principles under the guidance of senior team members.Mandatory technical & functional skills:\u00b7 In depth knowledge on ML, Deep Learning and NLP algorithms, LLMs ( BERT, GEPT, etc.) and hands-on LangChain, OpenAI LLM Libraries , VectorDBs (Chroma, FAISS, etc),\u00b7 Hands-on ML platforms offered through GCP : Vertex AI or Azure : AI Foundry or AWS SageMaker\u00b7 Proficiency in Python, Java, or C++, and machine learning frameworks like TensorFlow or PyTorch developing deep learning projects is crucial.\u00b7 Develop and optimize generative AI models, collaborating with cross-functional teams and researching cutting-edge techniques\u00b7 Ensure scalability and efficiency, handle data tasks, stay current with AI trends, and contribute to model documentation for internal and external audiences.\u00b7 Cloud computing experience, particularly with Google/Azure Cloud Platform, is essential. With strong foundation in understating Data Analytics Services offered by Google or Azure ( BigQuery/Synapse)Preferred technical & functional skills:\u2014 Good knowledge on Azure Cognitive Search, Google Cloud Search, AWS Kendra\u2014 Large scale deployment of ML projects, with good understanding of DevOps /MLOps /LLM Ops\u2014 Strong oral and written communication skills with the ability to communicate technical and non-technical concepts to peers and stakeholders\u2014 Ability to work independently with minimal supervision, and escalate when needed",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/senior-data-scientist-at-hellowork-consultants-4357441027?position=36&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=Y%2BBLvCsIoD7sLsHV9TE3UA%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:14:54.436060"
  },
  {
    "job_id": "linkedin_machine-learning-engineer-ii-recommendation-systems-at-glance-4367804358",
    "title": "Machine Learning Engineer II- Recommendation Systems",
    "company": "Glance",
    "location": "Bengaluru, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "What you will be doingWe are looking for a Data Scientist who can operate at the intersection of classical machine learning, large-scale recommendation systems, and modern agentic AI systems.You will design, build, and deploy intelligent systems that power Glance\u2019s personalized lock screen and live entertainment experiences. This role blends deep ML craftsmanship with forward-looking innovation in autonomous/agentic systems.Your responsibilities will include:Classical ML & Recommendation SystemsDesign and develop large-scale recommendation systems using advanced ML, statistical modeling, ranking algorithms, and deep learning.Build and operate machine learning models on diverse, high-volume data sources for personalization, prediction, and content understanding.Develop rapid experimentation workflows to validate hypotheses and measure real-world business impact.Own data preparation, model training, evaluation, and deployment pipelines in collaboration with engineering counterparts.Monitor ML model performance using statistical techniques; identify drifts, failure modes, and improvement opportunities.Agentic Systems & Next-Gen AIBuild and experiment with agentic AI systems that autonomously observe model performance, trigger experiments, tune hyperparameters, improve ranking policies, or orchestrate ML workflows with minimal human intervention.Apply LLMs, embeddings, retrieval-augmented architectures, and multimodal generative models for semantic understanding, content classification, and user preference modeling.Design intelligent agents that can automate repetitive decision-making tasks\u2014e.g., candidate generation tuning, feature selection, or context-aware content curation.Explore reinforcement learning, contextual bandits, and self-improving systems to power next-generation personalization.",
    "requirements": "What you will be doingWe are looking for a Data Scientist who can operate at the intersection of classical machine learning, large-scale recommendation systems, and modern agentic AI systems.You will design, build, and deploy intelligent systems that power Glance\u2019s personalized lock screen and live entertainment experiences. This role blends deep ML craftsmanship with forward-looking innovation in autonomous/agentic systems.Your responsibilities will include:Classical ML & Recommendation SystemsDesign and develop large-scale recommendation systems using advanced ML, statistical modeling, ranking algorithms, and deep learning.Build and operate machine learning models on diverse, high-volume data sources for personalization, prediction, and content understanding.Develop rapid experimentation workflows to validate hypotheses and measure real-world business impact.Own data preparation, model training, evaluation, and deployment pipelines in collaboration with engineering counterparts.Monitor ML model performance using statistical techniques; identify drifts, failure modes, and improvement opportunities.Agentic Systems & Next-Gen AIBuild and experiment with agentic AI systems that autonomously observe model performance, trigger experiments, tune hyperparameters, improve ranking policies, or orchestrate ML workflows with minimal human intervention.Apply LLMs, embeddings, retrieval-augmented architectures, and multimodal generative models for semantic understanding, content classification, and user preference modeling.Design intelligent agents that can automate repetitive decision-making tasks\u2014e.g., candidate generation tuning, feature selection, or context-aware content curation.Explore reinforcement learning, contextual bandits, and self-improving systems to power next-generation personalization.",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/machine-learning-engineer-ii-recommendation-systems-at-glance-4367804358?position=37&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=woDZaWB%2FbxkLAkT2b2epCw%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:14:58.505323"
  },
  {
    "job_id": "linkedin_data-science-intern-at-zetheta-algorithms-private-limited-4367804497",
    "title": "Data Science Intern",
    "company": "Zetheta Algorithms Private Limited",
    "location": "India",
    "job_type": "Full-time",
    "work_mode": "Remote",
    "salary": null,
    "description": "About the CompanyZeTheta Algorithms Private Limited is a FinTech start-up which has been recently set up and is developing innovative AI tools.https://www.instagram.com/zetheta.officialAbout the RoleAs a Data Scientist intern, you will work on cutting-edge projects involving financial data analysis, investment research, and risk modelling. You will have the opportunity to engage in multiple mini-projects or take up a focused innovation-based research project. The project experience is designed to provide practical exposure to data science in the context of asset management, trading, and financial technology. We provide problem statements, methodology and after you submit your solution to develop the solutions/ model, we also showcase to you sample solution. You can use our sample solution to modify your project submission and expand further based on suggestions given in our sample solution. You can opt for your own research based data science solution to develop/ model.ResponsibilitiesConduct data cleaning, wrangling, and pre-processing for financial datasets.Assist investment teams in equity research, fixed income research, portfolio management, and economic analysis.Apply statistical techniques to financial problems such as credit risk modelling, probability of default, and value-at-risk estimation.Work with big data sources including financial reports, macroeconomic datasets, and alternative investment data.Use either one \u2013 Python, Excel or R to analyse, visualize, and model financial data.Participate in research projects related to quantitative trading, financial derivatives, and portfolio optimization.Who Should Apply?Any student even without coding skills can upskill (self learning) to develop Data Science Solutions. Some basic knowledge of Excel or Python or R script can help complete the projects quicker. We permit the use of all LLMs/ NLPs to help students to develop the solutions.Strong problem-solving and analytical skills.Able to self-learn and work independently in a remote, flexible environment.Internship DetailsDuration: Option of 15 days and 1 months to 6 monthsTiming: Self-paced.Type: Unpaid",
    "requirements": "About the CompanyZeTheta Algorithms Private Limited is a FinTech start-up which has been recently set up and is developing innovative AI tools.https://www.instagram.com/zetheta.officialAbout the RoleAs a Data Scientist intern, you will work on cutting-edge projects involving financial data analysis, investment research, and risk modelling. You will have the opportunity to engage in multiple mini-projects or take up a focused innovation-based research project. The project experience is designed to provide practical exposure to data science in the context of asset management, trading, and financial technology. We provide problem statements, methodology and after you submit your solution to develop the solutions/ model, we also showcase to you sample solution. You can use our sample solution to modify your project submission and expand further based on suggestions given in our sample solution. You can opt for your own research based data science solution to develop/ model.ResponsibilitiesConduct data cleaning, wrangling, and pre-processing for financial datasets.Assist investment teams in equity research, fixed income research, portfolio management, and economic analysis.Apply statistical techniques to financial problems such as credit risk modelling, probability of default, and value-at-risk estimation.Work with big data sources including financial reports, macroeconomic datasets, and alternative investment data.Use either one \u2013 Python, Excel or R to analyse, visualize, and model financial data.Participate in research projects related to quantitative trading, financial derivatives, and portfolio optimization.Who Should Apply?Any student even without coding skills can upskill (self learning) to develop Data Science Solutions. Some basic knowledge of Excel or Python or R script can help complete the projects quicker. We permit the use of all LLMs/ NLPs to help students to develop the solutions.Strong problem-solving and analytical skills.Able to self-learn and work independently in a remote, flexible environment.Internship DetailsDuration: Option of 15 days and 1 months to 6 monthsTiming: Self-paced.Type: Unpaid",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/data-science-intern-at-zetheta-algorithms-private-limited-4367804497?position=38&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=I9T5OS%2B2Jr9HvptBvntS3A%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:15:02.327390"
  },
  {
    "job_id": "linkedin_senior-engineer-python-data-ai-at-tide-4321182293",
    "title": "Senior Engineer, Python (Data & AI)",
    "company": "Tide",
    "location": "Bengaluru, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Remote",
    "salary": null,
    "description": "About TideAt Tide we help SMEs save time (and money) in the running of their businesses by not only offering business accounts and related banking services, but also a comprehensive set of highly usable and connected administrative solutions from invoicing to accounting.Tide is transforming the small business banking market with over 1.8 million members globally across the UK, India, Germany and France.Using advanced technology, all solutions are designed with SMEs in mind. With quick onboarding, low fees and innovative features, we thrive on making data-driven decisions to serve our mission: to help SMEs save both time (and money) so they can get back to doing what they love.Tide FactsTide is available for UK, Indian, German and French SMEsOver 1.8 million members: 800,000 UK and 1,000,000 in India and growing rapidlyOver $300 million raised in fundingOver 2,500 Tideans globally - we\u2019re diversity champions!We have offices in Central London, with a member support and technology centre in Sofia, Bulgaria, technology centres in Serbia, Romania, Lithuania and Hyderabad and offices in Gurugram and New Delhi, and in Berlin, Paris and Luxembourg.About The RoleAs a ML Engineer you\u2019ll be:Working closely with product owners, other backend (Java & Python) engineers, data scientist and other business members to translate requirements into well-engineered solutionsArchitect, design, test, implement, deploy, monitor and maintain end-to-end backend services. You build it, you own it mentality.Integrate already trained ML models in some of the services you develop.Work with people from other teams and departments on a day to day basis to ensure efficient project execution with a focus on delivering value to our members.Regularly aligning your team\u2019s vision and roadmap with the target architecture within your domain and to ensure the success of complex multi domain initiativesWhat We Are Looking ForYou have 5+ years of experience as a Backend Python Engineer (Senior/Lead)You have understanding of software engineering fundamentals (OOP, SOLID, etc.)You have hands-on experience with frameworks such as Django, FastAPI or FlaskYou have extensive experience integrating with or creating REST APIsYou have experience with creating and maintaining CI/CD pipelines - we use GitHub Actions.You have experience with event-driven architecturesYou have experience with AWS(Great to have) Experience with Databricks, ML feature store solutions, Kafka (or other message brokers)OUR TECH STACK (You don\u2019t have to excel in all, but willing to learn them):Databricks on AWS Python FlaskSnowflakeTecton - feature store Fiddler - model observability platformWhat You Will Get In ReturnOur location-specific employee benefits are designed to cater to the unique needs of Tideans:Competitive Compensation - competitive salary and share optionsTime Off \u2013 Generous annual leave on top of bank holidays.Parental Leave \u2013 Paid maternity, paternity, and adoption leave to support your family journey.Sabbatical \u2013 Extended unpaid and paid leave options after completing milestone years with Tide.Health Insurance \u2013 Private family insurance with additional OPD coverage and top-up options.Life & Accident Cover \u2013 Comprehensive accidental and life insurance protection.Mental Wellbeing \u2013 Access to therapy sessions, courses, meditations, and workshops.Volunteering & Development Days \u2013 Paid days annually for volunteering or personal growth.Learning & Development \u2013 Annual budget for books, courses, coaching, and more.WOO (Work Outside the Office) \u2013 Work from abroad for up to 90 days annually.Home Office Setup \u2013 Contribution towards setting up your home officeLaptop Ownership \u2013 Keep your old laptop and get a new one when it\u2019s time for a replacement.Snacks & Meals \u2013 Office perks with snacks, coffee, tea, and lunch (location dependent)Tidean Ways Of WorkingAt Tide, we champion a flexible workplace model that supports both in-person and remote work to cater to the specific needs of our different teams.While remote work is supported, we believe in the power of face-to-face interactions to foster team spirit and collaboration. Our offices are designed as hubs for innovation and team-building, where we encourage regular in-person gatherings to foster a strong sense of community.TIDE IS A PLACE FOR EVERYONEAt Tide, we believe that we can only succeed if we let our differences enrich our culture. Our Tideans come from a variety of backgrounds and experience levels. We consider everyone irrespective of their ethnicity, religion, sexual orientation, gender identity, family or parental status, national origin, veteran, neurodiversity or differently-abled status. We celebrate diversity in our workforce as a cornerstone of our success. Our commitment to a broad spectrum of ideas and backgrounds is what enables us to build products that resonate with our members\u2019 diverse needs and lives.We are One Team and foster a transparent and inclusive environment, where everyone\u2019s voice is heard.At Tide, we thrive on diversity, embracing various backgrounds and experiences. We welcome all individuals regardless of ethnicity, religion, sexual orientation, gender identity, or disability. Our inclusive culture is key to our success, helping us build products that meet our members' diverse needs. We are One Team, committed to transparency and ensuring everyone\u2019s voice is heard.DisclaimerIt Has Come To Our Attention That Individuals Or Agencies Are Falsely Claiming To Represent Tide And Are Reaching Out To Candidates Regarding Job Opportunities. Please Be Aware ThatTide does not charge any fees at any stage of the recruitment process.All official Tide job opportunities are listed exclusively on our Careers Page and applications should be submitted through this channel.Communication from Tide will only come from an official @tide.co email address.Tide does not work with agencies or recruiters without prior formal engagement, and we do not authorize third parties to make job offers on our behalf.If you are contacted by anyone misrepresenting Tide or requesting payment, please treat it as fraudulent and report it to us immediately at talent@tide.coYour safety and trust are important to us, and we are committed to ensuring a fair and transparent recruitment process.Tide leverages AI to enhance our hiring experience. You can read more about how we use AI in our recruitment process in our AI Policy.Your personal data will be processed by Tide for recruitment purposes and in accordance with Tide's Recruitment Privacy Notice.",
    "requirements": "About TideAt Tide we help SMEs save time (and money) in the running of their businesses by not only offering business accounts and related banking services, but also a comprehensive set of highly usable and connected administrative solutions from invoicing to accounting.Tide is transforming the small business banking market with over 1.8 million members globally across the UK, India, Germany and France.Using advanced technology, all solutions are designed with SMEs in mind. With quick onboarding, low fees and innovative features, we thrive on making data-driven decisions to serve our mission: to help SMEs save both time (and money) so they can get back to doing what they love.Tide FactsTide is available for UK, Indian, German and French SMEsOver 1.8 million members: 800,000 UK and 1,000,000 in India and growing rapidlyOver $300 million raised in fundingOver 2,500 Tideans globally - we\u2019re diversity champions!We have offices in Central London, with a member support and technology centre in Sofia, Bulgaria, technology centres in Serbia, Romania, Lithuania and Hyderabad and offices in Gurugram and New Delhi, and in Berlin, Paris and Luxembourg.About The RoleAs a ML Engineer you\u2019ll be:Working closely with product owners, other backend (Java & Python) engineers, data scientist and other business members to translate requirements into well-engineered solutionsArchitect, design, test, implement, deploy, monitor and maintain end-to-end backend services. You build it, you own it mentality.Integrate already trained ML models in some of the services you develop.Work with people from other teams and departments on a day to day basis to ensure efficient project execution with a focus on delivering value to our members.Regularly aligning your team\u2019s vision and roadmap with the target architecture within your domain and to ensure the success of complex multi domain initiativesWhat We Are Looking ForYou have 5+ years of experience as a Backend Python Engineer (Senior/Lead)You have understanding of software engineering fundamentals (OOP, SOLID, etc.)You have hands-on experience with frameworks such as Django, FastAPI or FlaskYou have extensive experience integrating with or creating REST APIsYou have experience with creating and maintaining CI/CD pipelines - we use GitHub Actions.You have experience with event-driven architecturesYou have experience with AWS(Great to have) Experience with Databricks, ML feature store solutions, Kafka (or other message brokers)OUR TECH STACK (You don\u2019t have to excel in all, but willing to learn them):Databricks on AWS Python FlaskSnowflakeTecton - feature store Fiddler - model observability platformWhat You Will Get In ReturnOur location-specific employee benefits are designed to cater to the unique needs of Tideans:Competitive Compensation - competitive salary and share optionsTime Off \u2013 Generous annual leave on top of bank holidays.Parental Leave \u2013 Paid maternity, paternity, and adoption leave to support your family journey.Sabbatical \u2013 Extended unpaid and paid leave options after completing milestone years with Tide.Health Insurance \u2013 Private family insurance with additional OPD coverage and top-up options.Life & Accident Cover \u2013 Comprehensive accidental and life insurance protection.Mental Wellbeing \u2013 Access to therapy sessions, courses, meditations, and workshops.Volunteering & Development Days \u2013 Paid days annually for volunteering or personal growth.Learning & Development \u2013 Annual budget for books, courses, coaching, and more.WOO (Work Outside the Office) \u2013 Work from abroad for up to 90 days annually.Home Office Setup \u2013 Contribution towards setting up your home officeLaptop Ownership \u2013 Keep your old laptop and get a new one when it\u2019s time for a replacement.Snacks & Meals \u2013 Office perks with snacks, coffee, tea, and lunch (location dependent)Tidean Ways Of WorkingAt Tide, we champion a flexible workplace model that supports both in-person and remote work to cater to the specific needs of our different teams.While remote work is supported, we believe in the power of face-to-face interactions to foster team spirit and collaboration. Our offices are designed as hubs for innovation and team-building, where we encourage regular in-person gatherings to foster a strong sense of community.TIDE IS A PLACE FOR EVERYONEAt Tide, we believe that we can only succeed if we let our differences enrich our culture. Our Tideans come from a variety of backgrounds and experience levels. We consider everyone irrespective of their ethnicity, religion, sexual orientation, gender identity, family or parental status, national origin, veteran, neurodiversity or differently-abled status. We celebrate diversity in our workforce as a cornerstone of our success. Our commitment to a broad spectrum of ideas and backgrounds is what enables us to build products that resonate with our members\u2019 diverse needs and lives.We are One Team and foster a transparent and inclusive environment, where everyone\u2019s voice is heard.At Tide, we thrive on diversity, embracing various backgrounds and experiences. We welcome all individuals regardless of ethnicity, religion, sexual orientation, gender identity, or disability. Our inclusive culture is key to our success, helping us build products that meet our members' diverse needs. We are One Team, committed to transparency and ensuring everyone\u2019s voice is heard.DisclaimerIt Has Come To Our Attention That Individuals Or Agencies Are Falsely Claiming To Represent Tide And Are Reaching Out To Candidates Regarding Job Opportunities. Please Be Aware ThatTide does not charge any fees at any stage of the recruitment process.All official Tide job opportunities are listed exclusively on our Careers Page and applications should be submitted through this channel.Communication from Tide will only come from an official @tide.co email address.Tide does not work with agencies or recruiters without prior formal engagement, and we do not authorize third parties to make job offers on our behalf.If you are contacted by anyone misrepresenting Tide or requesting payment, please treat it as fraudulent and report it to us immediately at talent@tide.coYour safety and trust are important to us, and we are committed to ensuring a fair and transparent recruitment process.Tide leverages AI to enhance our hiring experience. You can read more about how we use AI in our recruitment process in our AI Policy.Your personal data will be processed by Tide for recruitment purposes and in accordance with Tide's Recruitment Privacy Notice.",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/senior-engineer-python-data-ai-at-tide-4321182293?position=39&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=yIs9E%2FGoI%2FtaboXLmOQirA%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:15:06.127256"
  },
  {
    "job_id": "linkedin_data-science-intern-at-skoollage-4368148919",
    "title": "Data Science Intern",
    "company": "SKOOLLAGE",
    "location": "India",
    "job_type": "Full-time",
    "work_mode": "Remote",
    "salary": null,
    "description": "Data Science InternCompany: SKOOLAGELocation: RemoteDuration: 3 MonthsStipend: Up to \u20b97,500 (Paid | Performance-Based)Employment Opportunity: Potential full-time role based on performance + Certificate of InternshipAbout SKOOLAGESKOOLAGE is a technology-driven learning and career-readiness platform that delivers practical training and internship programs across Artificial Intelligence, Machine Learning, Data Science, and emerging digital technologies. The organization focuses on real-world exposure, industry-relevant projects, and guided mentorship to prepare learners for successful careers in data-driven fields.Role OverviewAs a Data Science Intern at SKOOLAGE, you will work on end-to-end data science projects involving data preprocessing, exploratory analysis, machine learning model development, and predictive analytics. This internship is ideal for candidates aiming to strengthen their applied data science and AI skills through hands-on experience.Key ResponsibilitiesPerform data cleaning, preprocessing, feature engineering, and Exploratory Data Analysis (EDA)Build, train, test, and evaluate machine learning models using Scikit-learnVisualize data insights using tools such as Matplotlib, Seaborn, or Power BIWork with real-world datasets to develop predictive and analytical solutionsCollaborate with mentors to improve model accuracy, performance, and scalabilityDocument findings and present insights in a clear, structured mannerEligibility & RequirementsWorking knowledge of Python, Pandas, NumPy, Scikit-learn, and MatplotlibUnderstanding of machine learning algorithms, data preprocessing techniques, and evaluation metricsFamiliarity with SQL and Jupyter NotebooksStrong analytical thinking, curiosity, and problem-solving skillsPrior coursework, certifications, or personal projects in data science or ML are an added advantageWhat You Will GainPaid stipend of up to \u20b97,500 (Performance-Based)Certificate of Internship from SKOOLAGEHands-on experience with real-world AI and machine learning projectsMentorship from experienced data science professionalsOpportunity to build portfolio-ready data science projectsNetworking opportunities, career guidance, and placement supportPotential full-time employment opportunity based on performance",
    "requirements": "Data Science InternCompany: SKOOLAGELocation: RemoteDuration: 3 MonthsStipend: Up to \u20b97,500 (Paid | Performance-Based)Employment Opportunity: Potential full-time role based on performance + Certificate of InternshipAbout SKOOLAGESKOOLAGE is a technology-driven learning and career-readiness platform that delivers practical training and internship programs across Artificial Intelligence, Machine Learning, Data Science, and emerging digital technologies. The organization focuses on real-world exposure, industry-relevant projects, and guided mentorship to prepare learners for successful careers in data-driven fields.Role OverviewAs a Data Science Intern at SKOOLAGE, you will work on end-to-end data science projects involving data preprocessing, exploratory analysis, machine learning model development, and predictive analytics. This internship is ideal for candidates aiming to strengthen their applied data science and AI skills through hands-on experience.Key ResponsibilitiesPerform data cleaning, preprocessing, feature engineering, and Exploratory Data Analysis (EDA)Build, train, test, and evaluate machine learning models using Scikit-learnVisualize data insights using tools such as Matplotlib, Seaborn, or Power BIWork with real-world datasets to develop predictive and analytical solutionsCollaborate with mentors to improve model accuracy, performance, and scalabilityDocument findings and present insights in a clear, structured mannerEligibility & RequirementsWorking knowledge of Python, Pandas, NumPy, Scikit-learn, and MatplotlibUnderstanding of machine learning algorithms, data preprocessing techniques, and evaluation metricsFamiliarity with SQL and Jupyter NotebooksStrong analytical thinking, curiosity, and problem-solving skillsPrior coursework, certifications, or personal projects in data science or ML are an added advantageWhat You Will GainPaid stipend of up to \u20b97,500 (Performance-Based)Certificate of Internship from SKOOLAGEHands-on experience with real-world AI and machine learning projectsMentorship from experienced data science professionalsOpportunity to build portfolio-ready data science projectsNetworking opportunities, career guidance, and placement supportPotential full-time employment opportunity based on performance",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/data-science-intern-at-skoollage-4368148919?position=40&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=vhzN5Hq7%2FJLhwyO7H1bujg%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:15:10.663381"
  },
  {
    "job_id": "linkedin_senior-data-scientist-at-gitaa-4367789900",
    "title": "Senior Data Scientist",
    "company": "GITAA",
    "location": "Chennai, Tamil Nadu, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "About GITAA:GITAA, an IIT Madras incubated company, is founded by experienced academics from the Indian Institute of Technology, Madras. Our founders bring in a wealth of expertise and knowledge in data science and engineering disciplines. GITAA is a leading provider of edtech solutions, training and technology consulting services. We build custom AI & ML solutions that turn data into business outcomes. Recent work spans retail analytics (SERVQUAL-based customer segmentation on service-request data to drive upsell, cross-sell, and loyalty), engineering analytics in manufacturing (self-supervised anomaly detection under sparse labels to cut scrap and downtime), data audit & governance (DGQI evaluations with IIT Madras to close policy\u2013practice gaps), sports analytics (real-time cricket innings forecasts and dynamic win probabilities), and aviation\u2014including regional carriers like FLY91\u2014(network and revenue optimization across route profitability, demand forecasting, dynamic pricing, on-time performance, and customer segmentation). These are a few of our focus areas; we\u2019re continually expanding into new domains.Job Description:We are looking for Senior Data Scientists who are passionate about advanced data science, machine learning, and AI-driven innovations. You will develop data-driven applications, mentor junior team members, and collaborate with subject matter experts to design scalable and impactful solutions.Responsibilities:Design, develop and deploy advanced data science and machine learning models.Provide technical mentorship to junior data scientists.Conceptualize and deliver solutions in core areas such as deep learning, natural language processing (NLP), and advanced statistical modeling.Collaborate with cross-functional teams to translate business needs into data-driven strategies.Drive research and innovation in AI/ML applications for the education and corporate training sector.Ensure best practices in coding, model validation, version control, and reproducibility.MLOps ownership: define the ML platform roadmap and standards (CI/CD, registry, feature store, observability), ensuring alerting, incident response, and rollback are in place.Proven production experience with LLM/GenAI: prompts/embeddings, RAG, PEFT/fine-tuning, evaluation, and safety/guardrails.Qualifications:B.Tech, Dual Degree, M.Tech, or Master\u2019s in Engineering, Computer Science or Data Science from a reputed institution, with a minimum CGPA of 7.5.Minimum 3+ years of industry or research experience in data science and machine learning.Demonstrated expertise in deep learning frameworks (TensorFlow, PyTorch), big data technologies, and scalable ML systems.Required Skills:Strong foundation in advanced statistics, machine learning algorithms, and optimization techniques.Experience with cloud platforms (AWS, GCP, or Azure) and deployment of ML pipelines. Docker/Kubernetes or managed ML.Strong background in NLP, computer vision, or recommender systems.Expertise in Python with IDEs (PyCharm, VS Code) plus proficiency in Git/GitHub and modern team practices (branching, PRs, reviews, CI/CD).Hands-on experience with MySQL and PostgreSQL.Excellent problem-solving and communication skills.AI algorithms & foundations beyond the basics: regularization, ensembles, search/optimization heuristics.Reinforcement learning basics: MDPs, bandits, policy/value methods; exposure to Gym or RLlib is a plus.Big data & systems: willingness to explore front-end/back-end concepts and big data frameworks (e.g., Spark, Kafka);LLM/GenAI: prompts, embeddings, RAG, fine-tuning/PEFT, evaluation & safety.What We Offer:A collaborative, intellectually rich environment in Chennai.Opportunities to cutting-edge EdTech innovations.Exposure to real-world AI/ML applications at scale.Mentorship and collaboration with IITM professors and leading industry specialists.Competitive salary commensurate with experience and qualifications.Interested candidates may send their resume to:\ud83d\udce7admin@gitaa.in\ud83d\udce7shreenithiya@gitaa.inTo know more about us, visit www.gitaa.in",
    "requirements": "About GITAA:GITAA, an IIT Madras incubated company, is founded by experienced academics from the Indian Institute of Technology, Madras. Our founders bring in a wealth of expertise and knowledge in data science and engineering disciplines. GITAA is a leading provider of edtech solutions, training and technology consulting services. We build custom AI & ML solutions that turn data into business outcomes. Recent work spans retail analytics (SERVQUAL-based customer segmentation on service-request data to drive upsell, cross-sell, and loyalty), engineering analytics in manufacturing (self-supervised anomaly detection under sparse labels to cut scrap and downtime), data audit & governance (DGQI evaluations with IIT Madras to close policy\u2013practice gaps), sports analytics (real-time cricket innings forecasts and dynamic win probabilities), and aviation\u2014including regional carriers like FLY91\u2014(network and revenue optimization across route profitability, demand forecasting, dynamic pricing, on-time performance, and customer segmentation). These are a few of our focus areas; we\u2019re continually expanding into new domains.Job Description:We are looking for Senior Data Scientists who are passionate about advanced data science, machine learning, and AI-driven innovations. You will develop data-driven applications, mentor junior team members, and collaborate with subject matter experts to design scalable and impactful solutions.Responsibilities:Design, develop and deploy advanced data science and machine learning models.Provide technical mentorship to junior data scientists.Conceptualize and deliver solutions in core areas such as deep learning, natural language processing (NLP), and advanced statistical modeling.Collaborate with cross-functional teams to translate business needs into data-driven strategies.Drive research and innovation in AI/ML applications for the education and corporate training sector.Ensure best practices in coding, model validation, version control, and reproducibility.MLOps ownership: define the ML platform roadmap and standards (CI/CD, registry, feature store, observability), ensuring alerting, incident response, and rollback are in place.Proven production experience with LLM/GenAI: prompts/embeddings, RAG, PEFT/fine-tuning, evaluation, and safety/guardrails.Qualifications:B.Tech, Dual Degree, M.Tech, or Master\u2019s in Engineering, Computer Science or Data Science from a reputed institution, with a minimum CGPA of 7.5.Minimum 3+ years of industry or research experience in data science and machine learning.Demonstrated expertise in deep learning frameworks (TensorFlow, PyTorch), big data technologies, and scalable ML systems.Required Skills:Strong foundation in advanced statistics, machine learning algorithms, and optimization techniques.Experience with cloud platforms (AWS, GCP, or Azure) and deployment of ML pipelines. Docker/Kubernetes or managed ML.Strong background in NLP, computer vision, or recommender systems.Expertise in Python with IDEs (PyCharm, VS Code) plus proficiency in Git/GitHub and modern team practices (branching, PRs, reviews, CI/CD).Hands-on experience with MySQL and PostgreSQL.Excellent problem-solving and communication skills.AI algorithms & foundations beyond the basics: regularization, ensembles, search/optimization heuristics.Reinforcement learning basics: MDPs, bandits, policy/value methods; exposure to Gym or RLlib is a plus.Big data & systems: willingness to explore front-end/back-end concepts and big data frameworks (e.g., Spark, Kafka);LLM/GenAI: prompts, embeddings, RAG, fine-tuning/PEFT, evaluation & safety.What We Offer:A collaborative, intellectually rich environment in Chennai.Opportunities to cutting-edge EdTech innovations.Exposure to real-world AI/ML applications at scale.Mentorship and collaboration with IITM professors and leading industry specialists.Competitive salary commensurate with experience and qualifications.Interested candidates may send their resume to:\ud83d\udce7admin@gitaa.in\ud83d\udce7shreenithiya@gitaa.inTo know more about us, visit www.gitaa.in",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/senior-data-scientist-at-gitaa-4367789900?position=41&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=OKmChQzHUn%2BGWl1ylo7zYQ%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:15:14.533238"
  },
  {
    "job_id": "linkedin_lead-machine-learning-engineer-at-data-hat-ai-4367725357",
    "title": "Lead Machine Learning Engineer",
    "company": "Data-Hat AI",
    "location": "India",
    "job_type": "Full-time",
    "work_mode": "Remote",
    "salary": null,
    "description": "Company Overview\u00a0DataHat\u00a0AI is building the next generation of intelligent decision systems for the fashion and retail ecosystem. We help global fashion brands and retailers\u00a0optimize\u00a0demand forecasting, inventory planning, replenishment, and omnichannel fulfillment using a combination of machine learning, deep learning, computer vision, and generative AI.\u00a0Our platform goes beyond dashboards and static models\u2014we design agentic.\u00a0At\u00a0DataHat\u00a0AI,\u00a0you\u2019ll\u00a0work at the intersection of real-world supply chain problems,\u00a0cutting-edge\u00a0AI, and high-impact business outcomes\u2014with the freedom of a remote-first culture and the ambition of a product-led AI company.\u00a0Role Overview\u00a0We are looking for a Lead Machine Learning Engineer who can own end-to-end ML systems\u2014from problem framing and feature design to model orchestration, evaluation, and production deployment.\u00a0This role is ideal for someone who:\u00a0Loves complex, messy real-world data\u00a0Enjoys blending statistical ML, deep learning, and GenAI\u00a0Thinks in systems and workflows, not just models\u00a0Can translate business problems into scalable, explainable AI solutions\u00a0You will play a key role in shaping how AI agents, forecasting models, and optimization engines are built and deployed across fashion retail, physical stores, and e-commerce.\u00a0What\u00a0You\u2019ll\u00a0Work On\u00a0Forecasting That Actually Works\u00a0Build\u00a0real-world demand forecasting systems\u00a0for fashion using ML, deep learning, and statistical models.\u00a0Tackle messy problems like\u00a0intermittent demand, stockouts, seasonality, and cold starts\u00a0across stores and e-commerce.\u00a0Design\u00a0segmented and ensemble models\u00a0that balance accuracy, stability, and business risk.\u00a0Data/Features\u00a0Engineering, Not Guesswork\u00a0Design semantic data models that encode business meaning, hierarchies, and relationships\u00a0Create\u00a0high-signal features\u00a0from sales, pricing, inventory, calendars, weather, and store performance.\u00a0Set\u00a0data quality and imputation rules\u00a0that prevent leakage, bias, and false insights.\u00a0Make models\u00a0explainable and trustworthy, not black boxes.\u00a0Agentic AI in Production\u00a0Build\u00a0AI agents\u00a0that reason, plan, and critique forecasts and replenishment decisions.\u00a0Use\u00a0LLMs to orchestrate workflows, apply business constraints, and explain outcomes in plain language.\u00a0Turn model outputs into\u00a0actionable decisions, not just numbers.\u00a0Vision-Powered Fashion Intelligence\u00a0Use\u00a0computer vision\u00a0to extract visual signals from product images\u2014similarity, style, warmth, and more.\u00a0Solve\u00a0cold-start and substitution problems\u00a0with visual embeddings.\u00a0Go beyond transactional data to understand\u00a0why products sell.\u00a0Ship ML That\u00a0Is Secure and\u00a0Scales\u00a0Own models from\u00a0idea \u2192 production \u2192 monitoring.\u00a0Build systems that are\u00a0fast, reliable, and\u00a0battle tested.\u00a0Build systems that are\u00a0secure,\u00a0observable\u00a0and auditable.\u00a0Work closely with product and engineering to turn AI into\u00a0measurable business impact.\u00a0What\u00a0We\u2019re\u00a0Looking For\u00a0Strong ML Foundations\u00a07\u201310\u00a0years of hands-on experience building\u00a0applied ML systems\u00a0(not just experiments).\u00a0Deep understanding of\u00a0statistical ML, time-series forecasting, and model evaluation.\u00a0Fluent in\u00a0Python\u00a0and the modern data stack (Pandas, NumPy, scikit-learn).\u00a0Modern AI Builder Mindset\u00a0Experience with\u00a0deep learning and Transformers\u2014and strong judgment on\u00a0when not to use them.\u00a0Hands-on exposure to\u00a0Generative AI, LLMs, and agentic AI patterns\u00a0(tool use, planning, critique).\u00a0Hands-on experience with frameworks like\u00a0Langchain,\u00a0LangGraph,\u00a0AutoGen\u00a0etc.\u00a0Comfortable blending\u00a0ML + rules + reasoning\u00a0to solve\u00a0real business\u00a0problems.\u00a0Computer Vision & Representation Learning\u00a0Experience working with\u00a0image embeddings, similarity search, and clustering.\u00a0Ability to extract meaningful signals from\u00a0product images\u00a0(style, structure, visual similarity).\u00a0Fashion or retail CV experience is a strong plus.\u00a0Systems & Domain Thinking\u00a0Ability to reason about\u00a0end-to-end systems, not isolated models.\u00a0Experience working on\u00a0retail, fashion, supply chain, or e-commerce\u00a0problems (preferred).\u00a0Experience working with\u00a0large, noisy, real-world\u00a0datasets\u00a0and imperfect signals.\u00a0Strong intuition for\u00a0constraints, trade-offs, and operational realities.\u00a0Leadership, Ownership & Impact\u00a0Demonstrated ability to\u00a0own ambiguous problems, define success metrics, and drive solutions to production.\u00a0Strong communication\u00a0skills\u2014able to explain complex models, assumptions, and limitations clearly to technical and non-technical stakeholders.\u00a0Track record\u00a0of influencing\u00a0product, engineering, and business decisions\u00a0through data and models.\u00a0Bias toward\u00a0shipping, learning, and iterating\u00a0over perfect theory.\u00a0Mentorship mindset and willingness to raise the technical bar of the team.\u00a0Why Join Us\u00a0Solve real, high-impact business problems with AI\u00a0Work on GenAI +\u00a0Agents +\u00a0ML + CV in production, not just experiments\u00a0Build end-to-end systems, not isolated models\u00a0Fully remote-first, outcome-driven culture\u00a0High ownership, high learning, high impact",
    "requirements": "Company Overview\u00a0DataHat\u00a0AI is building the next generation of intelligent decision systems for the fashion and retail ecosystem. We help global fashion brands and retailers\u00a0optimize\u00a0demand forecasting, inventory planning, replenishment, and omnichannel fulfillment using a combination of machine learning, deep learning, computer vision, and generative AI.\u00a0Our platform goes beyond dashboards and static models\u2014we design agentic.\u00a0At\u00a0DataHat\u00a0AI,\u00a0you\u2019ll\u00a0work at the intersection of real-world supply chain problems,\u00a0cutting-edge\u00a0AI, and high-impact business outcomes\u2014with the freedom of a remote-first culture and the ambition of a product-led AI company.\u00a0Role Overview\u00a0We are looking for a Lead Machine Learning Engineer who can own end-to-end ML systems\u2014from problem framing and feature design to model orchestration, evaluation, and production deployment.\u00a0This role is ideal for someone who:\u00a0Loves complex, messy real-world data\u00a0Enjoys blending statistical ML, deep learning, and GenAI\u00a0Thinks in systems and workflows, not just models\u00a0Can translate business problems into scalable, explainable AI solutions\u00a0You will play a key role in shaping how AI agents, forecasting models, and optimization engines are built and deployed across fashion retail, physical stores, and e-commerce.\u00a0What\u00a0You\u2019ll\u00a0Work On\u00a0Forecasting That Actually Works\u00a0Build\u00a0real-world demand forecasting systems\u00a0for fashion using ML, deep learning, and statistical models.\u00a0Tackle messy problems like\u00a0intermittent demand, stockouts, seasonality, and cold starts\u00a0across stores and e-commerce.\u00a0Design\u00a0segmented and ensemble models\u00a0that balance accuracy, stability, and business risk.\u00a0Data/Features\u00a0Engineering, Not Guesswork\u00a0Design semantic data models that encode business meaning, hierarchies, and relationships\u00a0Create\u00a0high-signal features\u00a0from sales, pricing, inventory, calendars, weather, and store performance.\u00a0Set\u00a0data quality and imputation rules\u00a0that prevent leakage, bias, and false insights.\u00a0Make models\u00a0explainable and trustworthy, not black boxes.\u00a0Agentic AI in Production\u00a0Build\u00a0AI agents\u00a0that reason, plan, and critique forecasts and replenishment decisions.\u00a0Use\u00a0LLMs to orchestrate workflows, apply business constraints, and explain outcomes in plain language.\u00a0Turn model outputs into\u00a0actionable decisions, not just numbers.\u00a0Vision-Powered Fashion Intelligence\u00a0Use\u00a0computer vision\u00a0to extract visual signals from product images\u2014similarity, style, warmth, and more.\u00a0Solve\u00a0cold-start and substitution problems\u00a0with visual embeddings.\u00a0Go beyond transactional data to understand\u00a0why products sell.\u00a0Ship ML That\u00a0Is Secure and\u00a0Scales\u00a0Own models from\u00a0idea \u2192 production \u2192 monitoring.\u00a0Build systems that are\u00a0fast, reliable, and\u00a0battle tested.\u00a0Build systems that are\u00a0secure,\u00a0observable\u00a0and auditable.\u00a0Work closely with product and engineering to turn AI into\u00a0measurable business impact.\u00a0What\u00a0We\u2019re\u00a0Looking For\u00a0Strong ML Foundations\u00a07\u201310\u00a0years of hands-on experience building\u00a0applied ML systems\u00a0(not just experiments).\u00a0Deep understanding of\u00a0statistical ML, time-series forecasting, and model evaluation.\u00a0Fluent in\u00a0Python\u00a0and the modern data stack (Pandas, NumPy, scikit-learn).\u00a0Modern AI Builder Mindset\u00a0Experience with\u00a0deep learning and Transformers\u2014and strong judgment on\u00a0when not to use them.\u00a0Hands-on exposure to\u00a0Generative AI, LLMs, and agentic AI patterns\u00a0(tool use, planning, critique).\u00a0Hands-on experience with frameworks like\u00a0Langchain,\u00a0LangGraph,\u00a0AutoGen\u00a0etc.\u00a0Comfortable blending\u00a0ML + rules + reasoning\u00a0to solve\u00a0real business\u00a0problems.\u00a0Computer Vision & Representation Learning\u00a0Experience working with\u00a0image embeddings, similarity search, and clustering.\u00a0Ability to extract meaningful signals from\u00a0product images\u00a0(style, structure, visual similarity).\u00a0Fashion or retail CV experience is a strong plus.\u00a0Systems & Domain Thinking\u00a0Ability to reason about\u00a0end-to-end systems, not isolated models.\u00a0Experience working on\u00a0retail, fashion, supply chain, or e-commerce\u00a0problems (preferred).\u00a0Experience working with\u00a0large, noisy, real-world\u00a0datasets\u00a0and imperfect signals.\u00a0Strong intuition for\u00a0constraints, trade-offs, and operational realities.\u00a0Leadership, Ownership & Impact\u00a0Demonstrated ability to\u00a0own ambiguous problems, define success metrics, and drive solutions to production.\u00a0Strong communication\u00a0skills\u2014able to explain complex models, assumptions, and limitations clearly to technical and non-technical stakeholders.\u00a0Track record\u00a0of influencing\u00a0product, engineering, and business decisions\u00a0through data and models.\u00a0Bias toward\u00a0shipping, learning, and iterating\u00a0over perfect theory.\u00a0Mentorship mindset and willingness to raise the technical bar of the team.\u00a0Why Join Us\u00a0Solve real, high-impact business problems with AI\u00a0Work on GenAI +\u00a0Agents +\u00a0ML + CV in production, not just experiments\u00a0Build end-to-end systems, not isolated models\u00a0Fully remote-first, outcome-driven culture\u00a0High ownership, high learning, high impact",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/lead-machine-learning-engineer-at-data-hat-ai-4367725357?position=42&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=vH2WFCT0ZuYK%2BPKIDFqlmw%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:15:18.173170"
  },
  {
    "job_id": "linkedin_data-scientist-gbs-commercial-at-ab-inbev-apac-4360653727",
    "title": "Data Scientist - GBS Commercial",
    "company": "AB InBev APAC",
    "location": "Greater Kolkata Area",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "Dreaming big is in our DNA. It\u2019s who we are as a company. It\u2019s our culture. It\u2019s our heritage. And more than ever, it\u2019s our future. A future where we\u2019re always looking forward. Always serving up new ways to meet life\u2019s moments. A future where we keep dreaming bigger. We look for people with passion, talent, and curiosity, and provide them with the teammates, resources and opportunities to unleash their full potential. The power we create together \u2013 when we combine your strengths with ours \u2013 is unstoppable. Are you ready to join a team that dreams as big as you do?AB InBev GCC was incorporated in 2014 as a strategic partner for Anheuser-Busch InBev. The center leverages the power of data and analytics to drive growth for critical business functions such as operations, finance, people, and technology. The teams are transforming Operations through Tech and Analytics. Do You Dream Big? We Need You.Job DescriptionJob Title: Data Scientist \u2013 GBS CommercialLocation: BangaloreReporting to: Senior Manager \u2013 GBS Commercial Purpose of the roleWe are looking for a Data Scientist to analyze large amounts of raw information to find patterns that will help improve our company. We will rely on you to build data products to extract valuable business insights. In this role, you should be highly analytical with a knack for analysis, math and statistics. Critical thinking and problem-solving skills are essential for interpreting data. We also want to see a passion for machine-learning and research. Key tasks & accountabilitiesIdentify valuable data sources and automate collection processesUndertake preprocessing of structured and unstructured dataAnalyze large amounts of information to discover trends and patternsBuild predictive models and machine-learning algorithmsCombine models through ensemble modelingPresent information using data visualization techniquesPropose solutions and strategies to business challengesCollaborate with engineering and product development teams Qualifications, Experience, SkillsLevel of educational attainment required:BSc/BA in Computer Science, Engineering or relevant field; graduate degree in Data Science or other quantitative field is preferredPrevious work experience required:Proven experience as a Data Scientist or Data AnalystExperience in data miningUnderstanding of machine-learning and operations researchTechnical skills required:Knowledge of R, SQL and Python; familiarity with Scala, Java or C++ is an assetExperience using business intelligence tools (e.g. PowerBI) and data frameworks (e.g. Hadoop)Analytical mind and business acumenStrong math skills (e.g. statistics, algebra)And above all of this, an undying love for beer!We dream big to create future with more cheers.",
    "requirements": "Dreaming big is in our DNA. It\u2019s who we are as a company. It\u2019s our culture. It\u2019s our heritage. And more than ever, it\u2019s our future. A future where we\u2019re always looking forward. Always serving up new ways to meet life\u2019s moments. A future where we keep dreaming bigger. We look for people with passion, talent, and curiosity, and provide them with the teammates, resources and opportunities to unleash their full potential. The power we create together \u2013 when we combine your strengths with ours \u2013 is unstoppable. Are you ready to join a team that dreams as big as you do?AB InBev GCC was incorporated in 2014 as a strategic partner for Anheuser-Busch InBev. The center leverages the power of data and analytics to drive growth for critical business functions such as operations, finance, people, and technology. The teams are transforming Operations through Tech and Analytics. Do You Dream Big? We Need You.Job DescriptionJob Title: Data Scientist \u2013 GBS CommercialLocation: BangaloreReporting to: Senior Manager \u2013 GBS Commercial Purpose of the roleWe are looking for a Data Scientist to analyze large amounts of raw information to find patterns that will help improve our company. We will rely on you to build data products to extract valuable business insights. In this role, you should be highly analytical with a knack for analysis, math and statistics. Critical thinking and problem-solving skills are essential for interpreting data. We also want to see a passion for machine-learning and research. Key tasks & accountabilitiesIdentify valuable data sources and automate collection processesUndertake preprocessing of structured and unstructured dataAnalyze large amounts of information to discover trends and patternsBuild predictive models and machine-learning algorithmsCombine models through ensemble modelingPresent information using data visualization techniquesPropose solutions and strategies to business challengesCollaborate with engineering and product development teams Qualifications, Experience, SkillsLevel of educational attainment required:BSc/BA in Computer Science, Engineering or relevant field; graduate degree in Data Science or other quantitative field is preferredPrevious work experience required:Proven experience as a Data Scientist or Data AnalystExperience in data miningUnderstanding of machine-learning and operations researchTechnical skills required:Knowledge of R, SQL and Python; familiarity with Scala, Java or C++ is an assetExperience using business intelligence tools (e.g. PowerBI) and data frameworks (e.g. Hadoop)Analytical mind and business acumenStrong math skills (e.g. statistics, algebra)And above all of this, an undying love for beer!We dream big to create future with more cheers.",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/data-scientist-gbs-commercial-at-ab-inbev-apac-4360653727?position=43&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=f82L1SoxL8eeJ3anKuweKg%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:15:21.533927"
  },
  {
    "job_id": "linkedin_senior-software-engineer-machine-learning-data-platforms-at-roku-4368122702",
    "title": "Senior Software Engineer, Machine Learning - Data Platforms",
    "company": "Roku",
    "location": "Bengaluru, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Remote",
    "salary": null,
    "description": "Teamwork makes the stream work.\u00a0Roku is changing how the world watches TVRoku is the #1 TV streaming platform in the U.S., Canada, and Mexico, and we've set our sights on powering every television in the world. Roku pioneered streaming to the TV. Our mission is to be the TV streaming platform that connects the entire TV ecosystem. We connect consumers to the content they love, enable content publishers to build and monetize large audiences, and provide advertisers unique capabilities to engage consumers.From your first day at Roku, you'll make a valuable - and valued - contribution. We're a fast-growing public company where no one is a bystander. We offer you the opportunity to delight millions of TV streamers around the world while gaining meaningful experience across a variety of disciplines.\u00a0 About the team\u00a0A reliable, privacy-safe, and scalable data foundation is critical to Roku\u2019s rapidly growing advertising business. The Ad Data Activation organization builds the identity systems,\u00a0device\u00a0graph pipelines, audience platforms, insights tooling, and data collaboration capabilities that power targeting, measurement, and reporting across Roku Ads.\u00a0We are hiring a Senior Machine Learning Engineer to help drive intelligence across these systems. You will work at the intersection of large-scale data platforms, applied machine learning, and generative AI \u2014 building capabilities that make Roku's advertising data more actionable for internal teams and advertisers. This includes building core generative AI platform features for Roku Advertising, while also applying traditional ML techniques to improve accuracy, automation, and decisioning across the ecosystem. If you enjoy working across data, ML, and new Gen-AI patterns \u2014 and want to shape how intelligence shows up inside Roku Ads \u2014 this role is for you.\u00a0About the role\u00a0In this role, you will design, build, and productionize intelligent capabilities that combine agentic Gen-AI systems with conventional ML pipelines across identity resolution, audience\u00a0modeling, attribution, and optimization workflows. You will work with massive\u00a0datasets, develop pipelines that transform raw signals into actionable features, and partner closely with product, data science, and platform teams.\u00a0\u00a0What you will be doing\u00a0Develop scalable and effective ML models and data pipelines to power identity, graph enrichment, audience segmentation, and campaign performance intelligence\u00a0Design and run experiments, measure impact, and translate results into product decisions and customer outcomes\u00a0Build and productionize agentic, generative-AI features \u2014 including reporting and insights agents, campaign-monitoring agents (with human-in-the-loop controls), and a semantic layer for reliable, natural-language analytics\u00a0Improve automation, reliability, and scalability across model training, feature engineering, deployment, and monitoring frameworks\u00a0Work closely with software and ML engineers to deliver end-to-end solutions from data ingestion through downstream systems\u00a0Partner with senior stakeholders to shape ML and Gen-AI strategy for Ad Data Activation \u2014\u00a0identifying\u00a0the right problems for AI, ensuring safety, and driving advertiser productivity.\u00a0We\u2019re\u00a0excited if you have\u00a05+ years of experience applying ML or data science to\u00a0real business\u00a0problems at scale\u00a0Master\u2019s degree (or higher) and 4+ years of experience in CS, CE, ML, or a related field\u00a0Strong CS fundamentals and ability to design efficient algorithms and production systems\u00a0Experience with ML approaches used in large-scale data problems (e.g., regression, classification, tree-based methods, embeddings, sequence models, or basic NLP)\u00a0Strong intuition for defining KPIs, objective functions, and evaluation frameworks for ML-driven systems\u00a0\u00a0PREFERRED QUALIFICATIONS\u00a0Knowledge of programming languages such as Python,\u00a0Scala/Java, C/C++, or similar\u00a0Experience working with large-scale data platforms (Spark, Presto/Trino, feature stores, data lakes, etc.)\u00a0Experience building or integrating with LLM/Gen-AI pipelines (prompting, evaluation, retrieval, safety) is a plus\u00a0Prior publications, patents, or open-source contributions are a plus\u00a0 \u00a0Our Hybrid Work ApproachRoku fosters an inclusive and collaborative environment where teams work in the office Monday through Thursday. Fridays are flexible for remote work except for employees whose roles are required to be in the office five days a week or employees who are in offices with a five day in office policy.\u00a0BenefitsRoku is committed to offering a diverse range of benefits as part of our compensation package to support our employees and their families. Our comprehensive benefits include global access to mental health and financial wellness support and resources. Local benefits include statutory and voluntary benefits which may include healthcare (medical, dental, and vision), life, accident, disability, commuter, and retirement options (401(k)/pension). Our employees can take time off work for vacation and other personal reasons to balance their evolving work and life needs. It's important to note that not every benefit is available in all locations or for every role. For details specific to your location, please consult with your recruiter.\u00a0AccommodationsRoku welcomes applicants of all backgrounds and provides reasonable accommodations and adjustments in accordance with applicable law. If you require reasonable accommodation at any point in the hiring process, please direct your inquiries to EmployeeRelations@Roku.com.\u00a0The Roku CultureRoku is a great place for people who want to work in a fast-paced environment where everyone is focused on the company's success rather than their own. We try to surround ourselves with people who are great at their jobs, who are easy to work with, and who keep their egos in check. We appreciate a sense of humor. We believe a fewer number of very talented folks can do more for less cost than a larger number of less talented teams. We're independent thinkers with big ideas who act boldly, move fast and accomplish extraordinary things through collaboration and trust. In short, at Roku you'll be part of a company that's changing how the world watches TV.\u202fWe have a unique culture that we are proud of. We think of ourselves primarily as problem-solvers, which itself is a two-part idea. We come up with the solution, but the solution isn't real until it is built and delivered to the customer. That penchant for action gives us a pragmatic approach to innovation, one that has served us well since 2002.\u202fTo learn more about Roku, our global footprint, and how we've grown, visit https://www.weareroku.com/factsheet.By providing your information, you acknowledge that you want Roku to contact you about job roles, that you have read Roku's Applicant Privacy Notice, and understand that Roku will use your information as described in that notice. If you do not wish to receive any communications from Roku regarding this role or similar roles in the future, you may unsubscribe at any time by emailing WorkforcePrivacy@Roku.com.",
    "requirements": "Teamwork makes the stream work.\u00a0Roku is changing how the world watches TVRoku is the #1 TV streaming platform in the U.S., Canada, and Mexico, and we've set our sights on powering every television in the world. Roku pioneered streaming to the TV. Our mission is to be the TV streaming platform that connects the entire TV ecosystem. We connect consumers to the content they love, enable content publishers to build and monetize large audiences, and provide advertisers unique capabilities to engage consumers.From your first day at Roku, you'll make a valuable - and valued - contribution. We're a fast-growing public company where no one is a bystander. We offer you the opportunity to delight millions of TV streamers around the world while gaining meaningful experience across a variety of disciplines.\u00a0 About the team\u00a0A reliable, privacy-safe, and scalable data foundation is critical to Roku\u2019s rapidly growing advertising business. The Ad Data Activation organization builds the identity systems,\u00a0device\u00a0graph pipelines, audience platforms, insights tooling, and data collaboration capabilities that power targeting, measurement, and reporting across Roku Ads.\u00a0We are hiring a Senior Machine Learning Engineer to help drive intelligence across these systems. You will work at the intersection of large-scale data platforms, applied machine learning, and generative AI \u2014 building capabilities that make Roku's advertising data more actionable for internal teams and advertisers. This includes building core generative AI platform features for Roku Advertising, while also applying traditional ML techniques to improve accuracy, automation, and decisioning across the ecosystem. If you enjoy working across data, ML, and new Gen-AI patterns \u2014 and want to shape how intelligence shows up inside Roku Ads \u2014 this role is for you.\u00a0About the role\u00a0In this role, you will design, build, and productionize intelligent capabilities that combine agentic Gen-AI systems with conventional ML pipelines across identity resolution, audience\u00a0modeling, attribution, and optimization workflows. You will work with massive\u00a0datasets, develop pipelines that transform raw signals into actionable features, and partner closely with product, data science, and platform teams.\u00a0\u00a0What you will be doing\u00a0Develop scalable and effective ML models and data pipelines to power identity, graph enrichment, audience segmentation, and campaign performance intelligence\u00a0Design and run experiments, measure impact, and translate results into product decisions and customer outcomes\u00a0Build and productionize agentic, generative-AI features \u2014 including reporting and insights agents, campaign-monitoring agents (with human-in-the-loop controls), and a semantic layer for reliable, natural-language analytics\u00a0Improve automation, reliability, and scalability across model training, feature engineering, deployment, and monitoring frameworks\u00a0Work closely with software and ML engineers to deliver end-to-end solutions from data ingestion through downstream systems\u00a0Partner with senior stakeholders to shape ML and Gen-AI strategy for Ad Data Activation \u2014\u00a0identifying\u00a0the right problems for AI, ensuring safety, and driving advertiser productivity.\u00a0We\u2019re\u00a0excited if you have\u00a05+ years of experience applying ML or data science to\u00a0real business\u00a0problems at scale\u00a0Master\u2019s degree (or higher) and 4+ years of experience in CS, CE, ML, or a related field\u00a0Strong CS fundamentals and ability to design efficient algorithms and production systems\u00a0Experience with ML approaches used in large-scale data problems (e.g., regression, classification, tree-based methods, embeddings, sequence models, or basic NLP)\u00a0Strong intuition for defining KPIs, objective functions, and evaluation frameworks for ML-driven systems\u00a0\u00a0PREFERRED QUALIFICATIONS\u00a0Knowledge of programming languages such as Python,\u00a0Scala/Java, C/C++, or similar\u00a0Experience working with large-scale data platforms (Spark, Presto/Trino, feature stores, data lakes, etc.)\u00a0Experience building or integrating with LLM/Gen-AI pipelines (prompting, evaluation, retrieval, safety) is a plus\u00a0Prior publications, patents, or open-source contributions are a plus\u00a0 \u00a0Our Hybrid Work ApproachRoku fosters an inclusive and collaborative environment where teams work in the office Monday through Thursday. Fridays are flexible for remote work except for employees whose roles are required to be in the office five days a week or employees who are in offices with a five day in office policy.\u00a0BenefitsRoku is committed to offering a diverse range of benefits as part of our compensation package to support our employees and their families. Our comprehensive benefits include global access to mental health and financial wellness support and resources. Local benefits include statutory and voluntary benefits which may include healthcare (medical, dental, and vision), life, accident, disability, commuter, and retirement options (401(k)/pension). Our employees can take time off work for vacation and other personal reasons to balance their evolving work and life needs. It's important to note that not every benefit is available in all locations or for every role. For details specific to your location, please consult with your recruiter.\u00a0AccommodationsRoku welcomes applicants of all backgrounds and provides reasonable accommodations and adjustments in accordance with applicable law. If you require reasonable accommodation at any point in the hiring process, please direct your inquiries to EmployeeRelations@Roku.com.\u00a0The Roku CultureRoku is a great place for people who want to work in a fast-paced environment where everyone is focused on the company's success rather than their own. We try to surround ourselves with people who are great at their jobs, who are easy to work with, and who keep their egos in check. We appreciate a sense of humor. We believe a fewer number of very talented folks can do more for less cost than a larger number of less talented teams. We're independent thinkers with big ideas who act boldly, move fast and accomplish extraordinary things through collaboration and trust. In short, at Roku you'll be part of a company that's changing how the world watches TV.\u202fWe have a unique culture that we are proud of. We think of ourselves primarily as problem-solvers, which itself is a two-part idea. We come up with the solution, but the solution isn't real until it is built and delivered to the customer. That penchant for action gives us a pragmatic approach to innovation, one that has served us well since 2002.\u202fTo learn more about Roku, our global footprint, and how we've grown, visit https://www.weareroku.com/factsheet.By providing your information, you acknowledge that you want Roku to contact you about job roles, that you have read Roku's Applicant Privacy Notice, and understand that Roku will use your information as described in that notice. If you do not wish to receive any communications from Roku regarding this role or similar roles in the future, you may unsubscribe at any time by emailing WorkforcePrivacy@Roku.com.",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/senior-software-engineer-machine-learning-data-platforms-at-roku-4368122702?position=44&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=VLBKbMAd9VKDCQGtrnJ%2Bbg%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:15:24.807968"
  },
  {
    "job_id": "linkedin_mlops-engineer-at-infosys-4367774341",
    "title": "MLOps Engineer",
    "company": "Infosys",
    "location": "Bengaluru East, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Hybrid",
    "salary": null,
    "description": "Required Skills: Strong proficiency in Python and ML frameworks (TensorFlow, PyTorch, Scikit-learn). Experience with containerization (Docker) and orchestration (Kubernetes). Familiarity with cloud platforms (AWS, Azure, GCP) and ML services. Expertise in CI/CD tools (GitHub Actions, Jenkins, Argo). Knowledge of feature stores, model registries, and ML observability tools. Understanding of data versioning and experiment tracking (MLflow, DVC). Key Responsibilities: Develop and maintain CI/CD pipelines for ML models and data workflows. Automate model training, testing, deployment, and rollback processes. Implement monitoring and alerting for model performance and data drift. Optimize infrastructure for cost, scalability, and reliability (cloud or hybrid environments). Collaborate with data scientists and software engineers to integrate ML models into production. Ensure compliance with security, governance, and reproducibility standards. Experience: 5\u20138 years of experience in software engineering or data engineering, with at least 3+ years in MLOps. Preferred Qualifications: Experience with large-scale ML systems and distributed training. Familiarity with GenAI model deployment and optimization. Strong problem-solving and debugging skills in production environments",
    "requirements": "Required Skills: Strong proficiency in Python and ML frameworks (TensorFlow, PyTorch, Scikit-learn). Experience with containerization (Docker) and orchestration (Kubernetes). Familiarity with cloud platforms (AWS, Azure, GCP) and ML services. Expertise in CI/CD tools (GitHub Actions, Jenkins, Argo). Knowledge of feature stores, model registries, and ML observability tools. Understanding of data versioning and experiment tracking (MLflow, DVC). Key Responsibilities: Develop and maintain CI/CD pipelines for ML models and data workflows. Automate model training, testing, deployment, and rollback processes. Implement monitoring and alerting for model performance and data drift. Optimize infrastructure for cost, scalability, and reliability (cloud or hybrid environments). Collaborate with data scientists and software engineers to integrate ML models into production. Ensure compliance with security, governance, and reproducibility standards. Experience: 5\u20138 years of experience in software engineering or data engineering, with at least 3+ years in MLOps. Preferred Qualifications: Experience with large-scale ML systems and distributed training. Familiarity with GenAI model deployment and optimization. Strong problem-solving and debugging skills in production environments",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/mlops-engineer-at-infosys-4367774341?position=45&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=XcBfO3BME9qDJ%2BhD8eOJlw%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:15:28.947641"
  },
  {
    "job_id": "linkedin_data-science-senior-associate-at-salesforce-4368136292",
    "title": "Data Science Senior Associate",
    "company": "Salesforce",
    "location": "Bengaluru, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.Job CategoryDataJob DetailsAbout SalesforceSalesforce is the #1 AI CRM, where humans with agents drive customer success together. Here, ambition meets action. Tech meets trust. And innovation isn\u2019t a buzzword \u2014 it\u2019s a way of life. The world of work as we know it is changing and we're looking for Trailblazers who are passionate about bettering business and the world through AI, driving innovation, and keeping Salesforce's core values at the heart of it all.Ready to level-up your career at the company leading workforce transformation in the agentic era? You\u2019re in the right place! Agentforce is the future of AI, and you are the future of Salesforce.Salesforce is the global leader in Cloud-based (SaaS) solutions that enable the world\u2019s premier brands to maintain a robust online presence with high ROI. We do this by providing a highly scalable, integrated cloud platform that allows our clients to rapidly launch and manage e-commerce stores, initiate unique marketing campaigns, build service agents, and drive customer traffic across a global footprint.We are looking for a top-notch AI scientist to join our applied science team. The team is tasked with building, optimizing, and innovating across a number of product lines including agentic enterprise search, commerce cloud, and salesforce personalization. We produce performant machine learning models, architect components to improve our agents, build benchmarks, and tune prompts to enhance relevance, personalization, and efficiency. Our goal is to deliver better shopper experiences as well as enterprise user experiences. We work on search agents, retrieval strategies, product recommendations, content and promotion selection, next-best-action, and much more.In this role, you will utilize frontier foundational models as well as open-source models for real-world use cases. You will research, design, and prototype in close collaboration with engineering and product teams, learning from customer deployments. This is a collaborative, agile team that values technical ownership and customer value. We are looking for someone who gets a kick out of staying on top of the latest AI literature, tools, and techniques, and figuring out the best way to apply them to practical solutions. We encourage contribution to tools and knowledge sharing within the team, the company, and the industry.ResponsibilitiesWork with product management and leadership to translate business problems into applied science problems.Research, prototype, and build demonstrations of AI ideas for quick validation and feedback.Design and build AI systems to hit accuracy and performance metric targets.Productize AI innovations in collaboration with engineering teams.Educate engineering and product teams about AI science during collaboration.Actively collaborate with and provide technical guidance to other members of the team.Share technical innovations with the team and across the company.Create innovations and contribute to conferences and/or open-source tools.Required QualificationsFluent in prototyping AI solutions, testing machine learning (ML) models, and wrangling small to medium datasets (e.g., data cleansing, feature engineering).BS/MS in a quantitative discipline with 2+ years of relevant experience.Expertise in classical machine learning, deep learning, and Large Language Models (LLMs).Avid experimenter in ML, LLMs, and agent systems, with a focus on innovating current AI solutions.Proficient in using Python scientific stack (e.g. Numpy, Pandas, PyTorch, SciPy, Jupyter).Proficient in shell scripting, Unix/Linux command-line tools, working with cloud infrastructure (AWS).Great communication skills: ability to discuss with scientists, engineers, designers, and product managers.Preferred QualificationsPh.D. with 1+ years of relevant experience.Deep knowledge of Reinforcement Learning, Deep Learning, Causal Inference, and Information Retrieval.Experience in building and shipping machine learning models and agent systems to production.Practical experience with MLOps best practices, including model serving, monitoring, and A/B testing in a production environment.Open-source machine learning code, project contributions, or implementations of published papers.Publications in any of {cvpr, iccv, eccv, neurips, iclr, icml, acl, emnlp, recsys, kdd}.Unleash Your PotentialWhen you join Salesforce, you\u2019ll be limitless in all areas of your life. Our benefits and resources support you to find balance and be your best, and our AI agents accelerate your impact so you can do your best. Together, we\u2019ll bring the power of Agentforce to organizations of all sizes and deliver amazing experiences that customers love. Apply today to not only shape the future \u2014 but to redefine what\u2019s possible \u2014 for yourself, for AI, and the world.AccommodationsIf you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.Posting StatementSalesforce is an equal opportunity employer and maintains a policy of non-discrimination with all employees and applicants for employment. What does that mean exactly? It means that at Salesforce, we believe in equality for all. And we believe we can lead the path to equality in part by creating a workplace that\u2019s inclusive, and free from discrimination. Know your rights: workplace discrimination is illegal. Any employee or potential employee will be assessed on the basis of merit, competence and qualifications \u2013 without regard to race, religion, color, national origin, sex, sexual orientation, gender expression or identity, transgender status, age, disability, veteran or marital status, political viewpoint, or other classifications protected by law. This policy applies to current and prospective employees, no matter where they are in their Salesforce employment journey. It also applies to recruiting, hiring, job assignment, compensation, promotion, benefits, training, assessment of job performance, discipline, termination, and everything in between. Recruiting, hiring, and promotion decisions at Salesforce are fair and based on merit. The same goes for compensation, benefits, promotions, transfers, reduction in workforce, recall, training, and education.",
    "requirements": "To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.Job CategoryDataJob DetailsAbout SalesforceSalesforce is the #1 AI CRM, where humans with agents drive customer success together. Here, ambition meets action. Tech meets trust. And innovation isn\u2019t a buzzword \u2014 it\u2019s a way of life. The world of work as we know it is changing and we're looking for Trailblazers who are passionate about bettering business and the world through AI, driving innovation, and keeping Salesforce's core values at the heart of it all.Ready to level-up your career at the company leading workforce transformation in the agentic era? You\u2019re in the right place! Agentforce is the future of AI, and you are the future of Salesforce.Salesforce is the global leader in Cloud-based (SaaS) solutions that enable the world\u2019s premier brands to maintain a robust online presence with high ROI. We do this by providing a highly scalable, integrated cloud platform that allows our clients to rapidly launch and manage e-commerce stores, initiate unique marketing campaigns, build service agents, and drive customer traffic across a global footprint.We are looking for a top-notch AI scientist to join our applied science team. The team is tasked with building, optimizing, and innovating across a number of product lines including agentic enterprise search, commerce cloud, and salesforce personalization. We produce performant machine learning models, architect components to improve our agents, build benchmarks, and tune prompts to enhance relevance, personalization, and efficiency. Our goal is to deliver better shopper experiences as well as enterprise user experiences. We work on search agents, retrieval strategies, product recommendations, content and promotion selection, next-best-action, and much more.In this role, you will utilize frontier foundational models as well as open-source models for real-world use cases. You will research, design, and prototype in close collaboration with engineering and product teams, learning from customer deployments. This is a collaborative, agile team that values technical ownership and customer value. We are looking for someone who gets a kick out of staying on top of the latest AI literature, tools, and techniques, and figuring out the best way to apply them to practical solutions. We encourage contribution to tools and knowledge sharing within the team, the company, and the industry.ResponsibilitiesWork with product management and leadership to translate business problems into applied science problems.Research, prototype, and build demonstrations of AI ideas for quick validation and feedback.Design and build AI systems to hit accuracy and performance metric targets.Productize AI innovations in collaboration with engineering teams.Educate engineering and product teams about AI science during collaboration.Actively collaborate with and provide technical guidance to other members of the team.Share technical innovations with the team and across the company.Create innovations and contribute to conferences and/or open-source tools.Required QualificationsFluent in prototyping AI solutions, testing machine learning (ML) models, and wrangling small to medium datasets (e.g., data cleansing, feature engineering).BS/MS in a quantitative discipline with 2+ years of relevant experience.Expertise in classical machine learning, deep learning, and Large Language Models (LLMs).Avid experimenter in ML, LLMs, and agent systems, with a focus on innovating current AI solutions.Proficient in using Python scientific stack (e.g. Numpy, Pandas, PyTorch, SciPy, Jupyter).Proficient in shell scripting, Unix/Linux command-line tools, working with cloud infrastructure (AWS).Great communication skills: ability to discuss with scientists, engineers, designers, and product managers.Preferred QualificationsPh.D. with 1+ years of relevant experience.Deep knowledge of Reinforcement Learning, Deep Learning, Causal Inference, and Information Retrieval.Experience in building and shipping machine learning models and agent systems to production.Practical experience with MLOps best practices, including model serving, monitoring, and A/B testing in a production environment.Open-source machine learning code, project contributions, or implementations of published papers.Publications in any of {cvpr, iccv, eccv, neurips, iclr, icml, acl, emnlp, recsys, kdd}.Unleash Your PotentialWhen you join Salesforce, you\u2019ll be limitless in all areas of your life. Our benefits and resources support you to find balance and be your best, and our AI agents accelerate your impact so you can do your best. Together, we\u2019ll bring the power of Agentforce to organizations of all sizes and deliver amazing experiences that customers love. Apply today to not only shape the future \u2014 but to redefine what\u2019s possible \u2014 for yourself, for AI, and the world.AccommodationsIf you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.Posting StatementSalesforce is an equal opportunity employer and maintains a policy of non-discrimination with all employees and applicants for employment. What does that mean exactly? It means that at Salesforce, we believe in equality for all. And we believe we can lead the path to equality in part by creating a workplace that\u2019s inclusive, and free from discrimination. Know your rights: workplace discrimination is illegal. Any employee or potential employee will be assessed on the basis of merit, competence and qualifications \u2013 without regard to race, religion, color, national origin, sex, sexual orientation, gender expression or identity, transgender status, age, disability, veteran or marital status, political viewpoint, or other classifications protected by law. This policy applies to current and prospective employees, no matter where they are in their Salesforce employment journey. It also applies to recruiting, hiring, job assignment, compensation, promotion, benefits, training, assessment of job performance, discipline, termination, and everything in between. Recruiting, hiring, and promotion decisions at Salesforce are fair and based on merit. The same goes for compensation, benefits, promotions, transfers, reduction in workforce, recall, training, and education.",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/data-science-senior-associate-at-salesforce-4368136292?position=46&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=MDSrz72Hd4ygPDdxvyRwSg%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:15:33.104275"
  },
  {
    "job_id": "linkedin_senior-data-scientist-at-infosys-4367733398",
    "title": "Senior Data Scientist",
    "company": "Infosys",
    "location": "Bengaluru East, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "Technical skills Programming: Python, R, SQL ML algorithms: Statistical ML algorithms Deep Neural Network architectures Model ensembling Generative AI models ML for Responsible AI AI domains - NLP, speech, computer vision, structured data Learning patterns \u2013 supervised, unsupervised, reinforcement learning Tools for data analysis, auto ML, model deployment & scaling, model fine tuning Knowledge of different Model fine tuning approaches for Large models Knowledge of datasets, pre-built models available in open community and 3rd party providers Knowledge of software development & architectures Knowledge of hyperscalers & their AI capabilities \u2013 Azure, AWS, GCP Knowledge of Model Quantization and Pruning Past experience playing a Data Scientist role Technical skills Programming: Python, R, SQL ML algorithms: Statistical ML algorithms Deep Neural Network architectures Model ensembling Generative AI models ML for Responsible AI AI domains - NLP, speech, computer vision, structured data Learning patterns \u2013 supervised, unsupervised, reinforcement learning Tools for data analysis, auto ML, model deployment & scaling, model fine tuning Knowledge of different Model fine tuning approaches for Large models Knowledge of datasets, pre-built models available in open community and 3rd party providers Knowledge of software development & architectures Knowledge of hyperscalers & their AI capabilities \u2013 Azure, AWS, GCP Knowledge of Model Quantization and Pruning Past experience playing a Data Scientist role",
    "requirements": "Technical skills Programming: Python, R, SQL ML algorithms: Statistical ML algorithms Deep Neural Network architectures Model ensembling Generative AI models ML for Responsible AI AI domains - NLP, speech, computer vision, structured data Learning patterns \u2013 supervised, unsupervised, reinforcement learning Tools for data analysis, auto ML, model deployment & scaling, model fine tuning Knowledge of different Model fine tuning approaches for Large models Knowledge of datasets, pre-built models available in open community and 3rd party providers Knowledge of software development & architectures Knowledge of hyperscalers & their AI capabilities \u2013 Azure, AWS, GCP Knowledge of Model Quantization and Pruning Past experience playing a Data Scientist role Technical skills Programming: Python, R, SQL ML algorithms: Statistical ML algorithms Deep Neural Network architectures Model ensembling Generative AI models ML for Responsible AI AI domains - NLP, speech, computer vision, structured data Learning patterns \u2013 supervised, unsupervised, reinforcement learning Tools for data analysis, auto ML, model deployment & scaling, model fine tuning Knowledge of different Model fine tuning approaches for Large models Knowledge of datasets, pre-built models available in open community and 3rd party providers Knowledge of software development & architectures Knowledge of hyperscalers & their AI capabilities \u2013 Azure, AWS, GCP Knowledge of Model Quantization and Pruning Past experience playing a Data Scientist role",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/senior-data-scientist-at-infosys-4367733398?position=47&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=2%2BAZ%2BNDkzdcZuaB5Ex4%2BNA%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:15:36.829844"
  },
  {
    "job_id": "linkedin_machine-learning-engineer-%E2%80%94-ai-native-language-systems-at-visionary-4356899996",
    "title": "Machine Learning Engineer \u2014 AI & Native Language Systems",
    "company": "Visionary",
    "location": "India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "Role DescriptionAs a Machine Learning Engineer at Visionary, you will build and ship the intelligence layer that powers personalized learning, native-language explanations, and adaptive tutoring. You will work on real production systems used by learners, not research prototypes.This role is central to how Visionary solves the learning duration problem.ResponsibilitiesDesign, train, and deploy machine learning models for personalized learning and adaptive content delivery.Build and improve NLP systems for explanation, question answering, and concept understanding.Develop and fine-tune models for Indian native languages (text and/or speech).Work with LLMs to power AI tutor workflows, including retrieval-augmented generation (RAG).Define and track model success metrics tied to learning outcomes, not just accuracy.Optimize models for latency, cost, and reliability in production environments.Collaborate closely with Product and Engineering to translate learning problems into deployable AI systems.Requirements (must)4+ years of experience in machine learning or applied AI.Strong proficiency in Python.Hands-on experience with PyTorch or TensorFlow.Solid understanding of NLP fundamentals (tokenization, embeddings, transformers).Experience deploying ML models into production systems.Ability to work end-to-end: data \u2192 model \u2192 evaluation \u2192 deployment.Experience with visualization libraries, WebGL/three.js is a plus.Experience working with AI/ML integrations or serving models.Experience in low-bandwidth optimisation and progressive web app techniques.Preferred Qualification:Experience working with LLMs (fine-tuning, prompting, evaluation).Experience with RAG pipelines, vector databases, or semantic search.Experience with ASR / TTS systems or speech-based models.Exposure to Indian languages (Hindi, Bengali, Tamil, Telugu, etc.).What you get1.5% equity as part of the founding engineering team.Ownership of core AI systems that define Visionary\u2019s product.Opportunity to build AI systems used by real learners at scale.",
    "requirements": "Role DescriptionAs a Machine Learning Engineer at Visionary, you will build and ship the intelligence layer that powers personalized learning, native-language explanations, and adaptive tutoring. You will work on real production systems used by learners, not research prototypes.This role is central to how Visionary solves the learning duration problem.ResponsibilitiesDesign, train, and deploy machine learning models for personalized learning and adaptive content delivery.Build and improve NLP systems for explanation, question answering, and concept understanding.Develop and fine-tune models for Indian native languages (text and/or speech).Work with LLMs to power AI tutor workflows, including retrieval-augmented generation (RAG).Define and track model success metrics tied to learning outcomes, not just accuracy.Optimize models for latency, cost, and reliability in production environments.Collaborate closely with Product and Engineering to translate learning problems into deployable AI systems.Requirements (must)4+ years of experience in machine learning or applied AI.Strong proficiency in Python.Hands-on experience with PyTorch or TensorFlow.Solid understanding of NLP fundamentals (tokenization, embeddings, transformers).Experience deploying ML models into production systems.Ability to work end-to-end: data \u2192 model \u2192 evaluation \u2192 deployment.Experience with visualization libraries, WebGL/three.js is a plus.Experience working with AI/ML integrations or serving models.Experience in low-bandwidth optimisation and progressive web app techniques.Preferred Qualification:Experience working with LLMs (fine-tuning, prompting, evaluation).Experience with RAG pipelines, vector databases, or semantic search.Experience with ASR / TTS systems or speech-based models.Exposure to Indian languages (Hindi, Bengali, Tamil, Telugu, etc.).What you get1.5% equity as part of the founding engineering team.Ownership of core AI systems that define Visionary\u2019s product.Opportunity to build AI systems used by real learners at scale.",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/machine-learning-engineer-%E2%80%94-ai-native-language-systems-at-visionary-4356899996?position=48&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=ZQJe%2F%2Fqe0gS3zT7pG6f6ig%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:15:40.184838"
  },
  {
    "job_id": "linkedin_senior-data-scientist-at-ebay-4313078792",
    "title": "Senior Data Scientist",
    "company": "eBay",
    "location": "Bengaluru, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "At eBay, we're more than a global ecommerce leader \u2014 we\u2019re changing the way the world shops and sells. Our platform empowers millions of buyers and sellers in more than 190 markets around the world. We\u2019re committed to pushing boundaries and leaving our mark as we reinvent the future of ecommerce for enthusiasts.Our customers are our compass, authenticity thrives, bold ideas are welcome, and everyone can bring their unique selves to work \u2014 every day. We're in this together, sustaining the future of our customers, our company, and our planet.Join a team of passionate thinkers, innovators, and dreamers \u2014 and help us connect people and build communities to create economic opportunity for all.Looking for a company that inspires passion, courage and creativity, where you can be on the team shaping the future of global commerce? Want to shape how millions of people buy, sell, connect, and share around the world? If you\u2019re interested in joining a purpose driven community that is dedicated to crafting an ambitious and inclusive work environment, join eBay \u2013 a company you can be proud to be with.Our Shipping team is at the heart of the e-commerce experience, influencing key buying/selling decisions by surfacing the best shipping options and ensuring a seamless post-purchase delivery journey for millions of buyers and sellers. Shipping is a critical component of trust and satisfaction on our platform. Our team develops and deploys sophisticated machine learning models to solve complex logistics challenges, such as predicting accurate delivery dates, optimizing shipping costs and options, and modeling complex carrier networks. We operate at a massive scale, leveraging advanced MLOps to deliver these critical services in a high-volume, low latency global e-commerce environment.As a Senior Data Scientist, you will take a hands-on role building our cutting-edge shipping intelligence platform. Using the latest ML, deep learning, and AI techniques, you will research and deploy sophisticated models to solve tangible problems like optimizing logistics. You will partner with product managers, engineers, and researchers to get these data-driven solutions into production at eBay's global scale, directly enabling a delightful and efficient shipping experience for millions of users.What We\u2019re Looking For6 Years experience in analytics, data science roleStrong Data & Analytics Skills \u2013 Proficiency in SQL & Python for data wrangling, analytics, and automationExperience in building and operating Machine Learning, Deep Learning, Natural Language Processing (NLP) and Large Language Model solutions in large production scale environmentsStrong Communication \u2013 Ability to turn complex findings into actionable recommendations for Product, AI, and Engineering teamsAI/LLM Experience \u2013 Hands-on experience with LLMs, prompt engineering, and retrieval-augmented generation (RAG) for AI-powered insights (Preferred)Model Evaluation Know-How \u2013 Ability to define metrics and evaluation frameworks for assessing ML-driven taxonomy and classification modelsStartup DNA \u2013 High agency, thrive in fast-paced, iterative environments with deep cross-functional collaborationPlease see the Talent Privacy Notice for information regarding how eBay handles your personal data collected when you use the eBay Careers website or apply for a job with eBay.eBay is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you have a need that requires accommodation, please contact us at talent@ebay.com. We will make every effort to respond to your request for accommodation as soon as possible. View our accessibility statement to learn more about eBay's commitment to ensuring digital accessibility for people with disabilities.The eBay Jobs website uses cookies to enhance your experience. By continuing to browse the site, you agree to our use of cookies. Visit our Privacy Center for more information.",
    "requirements": "At eBay, we're more than a global ecommerce leader \u2014 we\u2019re changing the way the world shops and sells. Our platform empowers millions of buyers and sellers in more than 190 markets around the world. We\u2019re committed to pushing boundaries and leaving our mark as we reinvent the future of ecommerce for enthusiasts.Our customers are our compass, authenticity thrives, bold ideas are welcome, and everyone can bring their unique selves to work \u2014 every day. We're in this together, sustaining the future of our customers, our company, and our planet.Join a team of passionate thinkers, innovators, and dreamers \u2014 and help us connect people and build communities to create economic opportunity for all.Looking for a company that inspires passion, courage and creativity, where you can be on the team shaping the future of global commerce? Want to shape how millions of people buy, sell, connect, and share around the world? If you\u2019re interested in joining a purpose driven community that is dedicated to crafting an ambitious and inclusive work environment, join eBay \u2013 a company you can be proud to be with.Our Shipping team is at the heart of the e-commerce experience, influencing key buying/selling decisions by surfacing the best shipping options and ensuring a seamless post-purchase delivery journey for millions of buyers and sellers. Shipping is a critical component of trust and satisfaction on our platform. Our team develops and deploys sophisticated machine learning models to solve complex logistics challenges, such as predicting accurate delivery dates, optimizing shipping costs and options, and modeling complex carrier networks. We operate at a massive scale, leveraging advanced MLOps to deliver these critical services in a high-volume, low latency global e-commerce environment.As a Senior Data Scientist, you will take a hands-on role building our cutting-edge shipping intelligence platform. Using the latest ML, deep learning, and AI techniques, you will research and deploy sophisticated models to solve tangible problems like optimizing logistics. You will partner with product managers, engineers, and researchers to get these data-driven solutions into production at eBay's global scale, directly enabling a delightful and efficient shipping experience for millions of users.What We\u2019re Looking For6 Years experience in analytics, data science roleStrong Data & Analytics Skills \u2013 Proficiency in SQL & Python for data wrangling, analytics, and automationExperience in building and operating Machine Learning, Deep Learning, Natural Language Processing (NLP) and Large Language Model solutions in large production scale environmentsStrong Communication \u2013 Ability to turn complex findings into actionable recommendations for Product, AI, and Engineering teamsAI/LLM Experience \u2013 Hands-on experience with LLMs, prompt engineering, and retrieval-augmented generation (RAG) for AI-powered insights (Preferred)Model Evaluation Know-How \u2013 Ability to define metrics and evaluation frameworks for assessing ML-driven taxonomy and classification modelsStartup DNA \u2013 High agency, thrive in fast-paced, iterative environments with deep cross-functional collaborationPlease see the Talent Privacy Notice for information regarding how eBay handles your personal data collected when you use the eBay Careers website or apply for a job with eBay.eBay is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you have a need that requires accommodation, please contact us at talent@ebay.com. We will make every effort to respond to your request for accommodation as soon as possible. View our accessibility statement to learn more about eBay's commitment to ensuring digital accessibility for people with disabilities.The eBay Jobs website uses cookies to enhance your experience. By continuing to browse the site, you agree to our use of cookies. Visit our Privacy Center for more information.",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/senior-data-scientist-at-ebay-4313078792?position=50&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=aDi%2FDqfdzmrhTdtw8%2FxoIQ%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:15:47.305218"
  },
  {
    "job_id": "linkedin_engineer-at-qualcomm-4367752134",
    "title": "Engineer",
    "company": "Qualcomm",
    "location": "Hyderabad, Telangana, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "CompanyQualcomm India Private LimitedJob AreaEngineering Group, Engineering Group > Software Test EngineeringGeneral SummaryAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Software Test Engineer, you will design, develop, create, and modify test cases and validate embedded software, cloud software, system algorithms, application software, automation, and/or specialized utility programs that launch cutting-edge, world class products. Qualcomm Software Test Engineers collaborate across various engineering teams and functions to design and implement test plans.Minimum Qualifications Bachelor's degree in Engineering, Information Systems, Computer Science, or related field.Preferred Qualifications Master's degree in Engineering, Information Systems, Computer Science, or related field. 1+ year of work or academic experience with Programming Language such as C, C++, Java, Python, etc. 1+ year of experience with Software Test or System Test, developing and automating test plans and/or tools (e.g., Source Code Control Systems, Continuous Integration Tools, and Bug Tracking Tools).Principal Duties And Responsibilities Applies software and systems knowledge to assist and support the design, development, creation, and modification of test cases and validation of embedded software, cloud software, system algorithms, application software, automation and/or specialized utility programs. Designs and implements basic test plans, scenarios, scripts, or procedures to identify a failure within a determined area of code. Writes functional tests for features to ensure functionality. Assists in the identification, analyses, and documentation of software defects. Collaborates with others inside of project team to accomplish project objectives and improve the overall quality of the product. Assists in the development of test case automations and/or scripts to improve productivity.Level Of Responsibility Working under supervision. Decision-making affects direct area of work and/or work group. Requires verbal and written communication skills to convey basic, routine factual information. Tasks require multiple steps which can be performed in various orders; some planning, problem-solving, and prioritization must occur to complete the tasks effectively.Applicants: Qualcomm is an equal opportunity employer. If you are an individual with a disability and need an accommodation during the application/hiring process, rest assured that Qualcomm is committed to providing an accessible process. You may e-mail disability-accomodations@qualcomm.com or call Qualcomm's toll-free number found here. Upon request, Qualcomm will provide reasonable accommodations to support individuals with disabilities to be able participate in the hiring process. Qualcomm is also committed to making our workplace accessible for individuals with disabilities. (Keep in mind that this email address is used to provide reasonable accommodations for individuals with disabilities. We will not respond here to requests for updates on applications or resume inquiries).Qualcomm expects its employees to abide by all applicable policies and procedures, including but not limited to security and other requirements regarding protection of Company confidential information and other confidential and/or proprietary information, to the extent those requirements are permissible under applicable law.To all Staffing and Recruiting Agencies: Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications.If you would like more information about this role, please contact Qualcomm Careers.",
    "requirements": "CompanyQualcomm India Private LimitedJob AreaEngineering Group, Engineering Group > Software Test EngineeringGeneral SummaryAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Software Test Engineer, you will design, develop, create, and modify test cases and validate embedded software, cloud software, system algorithms, application software, automation, and/or specialized utility programs that launch cutting-edge, world class products. Qualcomm Software Test Engineers collaborate across various engineering teams and functions to design and implement test plans.Minimum Qualifications Bachelor's degree in Engineering, Information Systems, Computer Science, or related field.Preferred Qualifications Master's degree in Engineering, Information Systems, Computer Science, or related field. 1+ year of work or academic experience with Programming Language such as C, C++, Java, Python, etc. 1+ year of experience with Software Test or System Test, developing and automating test plans and/or tools (e.g., Source Code Control Systems, Continuous Integration Tools, and Bug Tracking Tools).Principal Duties And Responsibilities Applies software and systems knowledge to assist and support the design, development, creation, and modification of test cases and validation of embedded software, cloud software, system algorithms, application software, automation and/or specialized utility programs. Designs and implements basic test plans, scenarios, scripts, or procedures to identify a failure within a determined area of code. Writes functional tests for features to ensure functionality. Assists in the identification, analyses, and documentation of software defects. Collaborates with others inside of project team to accomplish project objectives and improve the overall quality of the product. Assists in the development of test case automations and/or scripts to improve productivity.Level Of Responsibility Working under supervision. Decision-making affects direct area of work and/or work group. Requires verbal and written communication skills to convey basic, routine factual information. Tasks require multiple steps which can be performed in various orders; some planning, problem-solving, and prioritization must occur to complete the tasks effectively.Applicants: Qualcomm is an equal opportunity employer. If you are an individual with a disability and need an accommodation during the application/hiring process, rest assured that Qualcomm is committed to providing an accessible process. You may e-mail disability-accomodations@qualcomm.com or call Qualcomm's toll-free number found here. Upon request, Qualcomm will provide reasonable accommodations to support individuals with disabilities to be able participate in the hiring process. Qualcomm is also committed to making our workplace accessible for individuals with disabilities. (Keep in mind that this email address is used to provide reasonable accommodations for individuals with disabilities. We will not respond here to requests for updates on applications or resume inquiries).Qualcomm expects its employees to abide by all applicable policies and procedures, including but not limited to security and other requirements regarding protection of Company confidential information and other confidential and/or proprietary information, to the extent those requirements are permissible under applicable law.To all Staffing and Recruiting Agencies: Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications.If you would like more information about this role, please contact Qualcomm Careers.",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/engineer-at-qualcomm-4367752134?position=51&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=kXf%2BsUHwjnvwBdf1sPQgfw%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:15:50.885611"
  },
  {
    "job_id": "linkedin_mlops-engineer-at-capgemini-4366319591",
    "title": "MLOPS Engineer",
    "company": "Capgemini",
    "location": "Bengaluru, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Hybrid",
    "salary": null,
    "description": "Choosing Capgemini means choosing a company where you will be empowered to shape your career in the way you\u2019d like, where you\u2019ll be supported and inspired by\u202fa collaborative community of colleagues around the world, and where you\u2019ll be able to reimagine what\u2019s possible. Join us and help the world\u2019s leading organizations\u202funlock the value of technology and build a more sustainable, more inclusive world.Your RoleDesign, implement, and maintain end-to-end ML pipelines for model training, evaluation, and deploymentCollaborate with data scientists and software engineers to operationalize ML models, serving frameworks (TensorFlow Serving, TorchServe) and experience with MLOps toolsDevelop and maintain CI/CD pipelines for ML workflowsImplement monitoring and logging solutions for ML models, experience with ML model serving frameworks (TensorFlow Serving, TorchServe)Optimize ML infrastructure for performance, scalability, and cost-efficiencyYour ProfileStrong programming skills in Python (5+ years), with experience in ML frameworks; understanding of ML-specific testing and validation techniquesExpertise in containerization technologies (Docker) and orchestration platforms (Kubernetes), Knowledge of data versioning and model versioning techniquesProficiency in cloud platform (AWS) and their ML-specific services with atleast 2-3 years of experience.Strong understanding of DevOps practices and tools (GitLab, Artifactory, Gitflow etc.)Experience with monitoring and observability tools (Prometheus, Grafana, ELK stack) and knowledge of distributed training techniquesWhat You\u2019ll Love About Working HereWe recognise the significance of flexible work arrangements to provide support in hybrid mode, you will get an environment to maintain healthy work life balanceOur focus will be your career growth & professional development to support you in exploring the world of opportunities.Equip yourself with valuable certifications & training programmes in the latest technologies such as MLOps, Machine LearningCapgemini is a global business and technology transformation partner, helping organizations to accelerate their dual transition to a digital and sustainable world, while creating tangible impact for enterprises and society. It is a responsible and diverse group of 340,000 team members in more than 50 countries. With its strong over 55-year heritage, Capgemini is trusted by its clients to unlock the value of technology to address the entire breadth of their business needs. It delivers end-to-end services and solutions leveraging strengths from strategy and design to engineering, all fueled by its market leading capabilities in AI, generative AI, cloud and data, combined with its deep industry expertise and partner ecosystem.",
    "requirements": "Choosing Capgemini means choosing a company where you will be empowered to shape your career in the way you\u2019d like, where you\u2019ll be supported and inspired by\u202fa collaborative community of colleagues around the world, and where you\u2019ll be able to reimagine what\u2019s possible. Join us and help the world\u2019s leading organizations\u202funlock the value of technology and build a more sustainable, more inclusive world.Your RoleDesign, implement, and maintain end-to-end ML pipelines for model training, evaluation, and deploymentCollaborate with data scientists and software engineers to operationalize ML models, serving frameworks (TensorFlow Serving, TorchServe) and experience with MLOps toolsDevelop and maintain CI/CD pipelines for ML workflowsImplement monitoring and logging solutions for ML models, experience with ML model serving frameworks (TensorFlow Serving, TorchServe)Optimize ML infrastructure for performance, scalability, and cost-efficiencyYour ProfileStrong programming skills in Python (5+ years), with experience in ML frameworks; understanding of ML-specific testing and validation techniquesExpertise in containerization technologies (Docker) and orchestration platforms (Kubernetes), Knowledge of data versioning and model versioning techniquesProficiency in cloud platform (AWS) and their ML-specific services with atleast 2-3 years of experience.Strong understanding of DevOps practices and tools (GitLab, Artifactory, Gitflow etc.)Experience with monitoring and observability tools (Prometheus, Grafana, ELK stack) and knowledge of distributed training techniquesWhat You\u2019ll Love About Working HereWe recognise the significance of flexible work arrangements to provide support in hybrid mode, you will get an environment to maintain healthy work life balanceOur focus will be your career growth & professional development to support you in exploring the world of opportunities.Equip yourself with valuable certifications & training programmes in the latest technologies such as MLOps, Machine LearningCapgemini is a global business and technology transformation partner, helping organizations to accelerate their dual transition to a digital and sustainable world, while creating tangible impact for enterprises and society. It is a responsible and diverse group of 340,000 team members in more than 50 countries. With its strong over 55-year heritage, Capgemini is trusted by its clients to unlock the value of technology to address the entire breadth of their business needs. It delivers end-to-end services and solutions leveraging strengths from strategy and design to engineering, all fueled by its market leading capabilities in AI, generative AI, cloud and data, combined with its deep industry expertise and partner ecosystem.",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/mlops-engineer-at-capgemini-4366319591?position=52&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=5hYFdFahjPv4yakrli5Ylg%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:15:54.079698"
  },
  {
    "job_id": "linkedin_senior-research-associate-at-nielseniq-4367803499",
    "title": "Senior Research Associate",
    "company": "NielsenIQ",
    "location": "Vadodara, Gujarat, India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "Job DescriptionAnalytical support for senior team members and Client Business Partners. A BI Reporting Associates will be in support of one or several clients, operating as part of a broader international community, both analytical and commercial, working towards a common goal of supporting the Clients in achieving their strategic business objectives. What you\u2019ll do: Monitor BAU reports and automated processes Maintain regular client reports (refresh data, check or add comments,\u202fimplement changes, address technical issues, manage the delivery calendar\u202fand the deliveries) Review data for errors and inconsistencies, flag data quality issues Deliver quick turn requests Suggest and implement ways of improving/automating existing deliverables Share and actively search for best practice\u202fexamples, and\u202fimplement the\u202fapproach in own work whenever possible. QualificationsWe\u2019re looking for people who have: Master\u2019s in marketing, Economics or related field, or technical/engineering studies Graduate with 2-3 years of experience or MBA fresher Strong numerical and analytical skills Very good knowledge of Microsoft Excel (pivot tables, vlookup, conditional functions, conditional formatting, chart building, and formatting); knowledge of VBA is an asset, PowerPoint Basic Power BI knowledge is mandatory Automation & Process aware QA proficient\u202f Operational focus Proactive, flexible and self-motivated attitude Strong communication skills, ability to document, present and educate others Willingness to take ownership and see projects to completion Ability to anticipate the bigger picture and are holistic by nature Experience and desire to create process documentation Fluent communication in English - verbal and written (at least C1 level) Results-oriented personality and ability to work to tight deadlines Good time- and workload management skills Ability to work both independently and as a team player Experience in working in a virtual environment and in a multicultural setting Diligence and attention to detail Additional InformationOur BenefitsFlexible working environmentVolunteer time offLinkedIn LearningEmployee-Assistance-Program (EAP)NIQ may utilize artificial intelligence (AI) tools at various stages of the recruitment process, including r\u00e9sum\u00e9 screening, candidate assessments, interview scheduling, job matching, communication support, and certain administrative tasks that help streamline workflows. These tools are intended to improve efficiency and support fair and consistent evaluation based on job-related criteria. All use of AI is governed by NIQ\u2019s principles of fairness, transparency, human oversight, and inclusion. Final hiring decisions are made exclusively by humans. NIQ regularly reviews its AI tools to help mitigate bias and ensure compliance with applicable laws and regulations. If you have questions, require accommodations, or wish to request human review were permitted by law, please contact your local HR representative. For more information, please visit NIQ\u2019s AI Safety Policies and Guiding Principles: https://www.nielseniq.com/global/en/ai-safety-policies.                                      About NIQNIQ is the world\u2019s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights\u2014delivered with advanced analytics through state-of-the-art platforms\u2014NIQ delivers the Full View\u2122. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world\u2019s population.For more information, visit NIQ.comWant to keep up with our latest updates?Follow us on: LinkedIn | Instagram | Twitter | FacebookOur commitment to Diversity, Equity, and InclusionAt NIQ, we are steadfast in our commitment to fostering an inclusive workplace that mirrors the rich diversity of the communities and markets we serve. We believe that embracing a wide range of perspectives drives innovation and excellence.  All employment decisions at NIQ are made without regard to race, color, religion, sex (including pregnancy, sexual orientation, or gender identity), national origin, age, disability, genetic information, marital status, veteran status, or any other characteristic protected by applicable laws. We invite individuals who share our dedication to inclusivity and equity to join us in making a meaningful impact. To learn more about our ongoing efforts in diversity and inclusion, please visit the https://nielseniq.com/global/en/news-center/diversity-inclusion",
    "requirements": "Job DescriptionAnalytical support for senior team members and Client Business Partners. A BI Reporting Associates will be in support of one or several clients, operating as part of a broader international community, both analytical and commercial, working towards a common goal of supporting the Clients in achieving their strategic business objectives. What you\u2019ll do: Monitor BAU reports and automated processes Maintain regular client reports (refresh data, check or add comments,\u202fimplement changes, address technical issues, manage the delivery calendar\u202fand the deliveries) Review data for errors and inconsistencies, flag data quality issues Deliver quick turn requests Suggest and implement ways of improving/automating existing deliverables Share and actively search for best practice\u202fexamples, and\u202fimplement the\u202fapproach in own work whenever possible. QualificationsWe\u2019re looking for people who have: Master\u2019s in marketing, Economics or related field, or technical/engineering studies Graduate with 2-3 years of experience or MBA fresher Strong numerical and analytical skills Very good knowledge of Microsoft Excel (pivot tables, vlookup, conditional functions, conditional formatting, chart building, and formatting); knowledge of VBA is an asset, PowerPoint Basic Power BI knowledge is mandatory Automation & Process aware QA proficient\u202f Operational focus Proactive, flexible and self-motivated attitude Strong communication skills, ability to document, present and educate others Willingness to take ownership and see projects to completion Ability to anticipate the bigger picture and are holistic by nature Experience and desire to create process documentation Fluent communication in English - verbal and written (at least C1 level) Results-oriented personality and ability to work to tight deadlines Good time- and workload management skills Ability to work both independently and as a team player Experience in working in a virtual environment and in a multicultural setting Diligence and attention to detail Additional InformationOur BenefitsFlexible working environmentVolunteer time offLinkedIn LearningEmployee-Assistance-Program (EAP)NIQ may utilize artificial intelligence (AI) tools at various stages of the recruitment process, including r\u00e9sum\u00e9 screening, candidate assessments, interview scheduling, job matching, communication support, and certain administrative tasks that help streamline workflows. These tools are intended to improve efficiency and support fair and consistent evaluation based on job-related criteria. All use of AI is governed by NIQ\u2019s principles of fairness, transparency, human oversight, and inclusion. Final hiring decisions are made exclusively by humans. NIQ regularly reviews its AI tools to help mitigate bias and ensure compliance with applicable laws and regulations. If you have questions, require accommodations, or wish to request human review were permitted by law, please contact your local HR representative. For more information, please visit NIQ\u2019s AI Safety Policies and Guiding Principles: https://www.nielseniq.com/global/en/ai-safety-policies.                                      About NIQNIQ is the world\u2019s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights\u2014delivered with advanced analytics through state-of-the-art platforms\u2014NIQ delivers the Full View\u2122. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world\u2019s population.For more information, visit NIQ.comWant to keep up with our latest updates?Follow us on: LinkedIn | Instagram | Twitter | FacebookOur commitment to Diversity, Equity, and InclusionAt NIQ, we are steadfast in our commitment to fostering an inclusive workplace that mirrors the rich diversity of the communities and markets we serve. We believe that embracing a wide range of perspectives drives innovation and excellence.  All employment decisions at NIQ are made without regard to race, color, religion, sex (including pregnancy, sexual orientation, or gender identity), national origin, age, disability, genetic information, marital status, veteran status, or any other characteristic protected by applicable laws. We invite individuals who share our dedication to inclusivity and equity to join us in making a meaningful impact. To learn more about our ongoing efforts in diversity and inclusion, please visit the https://nielseniq.com/global/en/news-center/diversity-inclusion",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/senior-research-associate-at-nielseniq-4367803499?position=53&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=DA%2F1Tmc0VxAr5UvIeO9n8w%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:15:57.663632"
  },
  {
    "job_id": "linkedin_data-science-intern-at-infrabyte-consulting-4368152647",
    "title": "Data Science Intern",
    "company": "Infrabyte Consulting",
    "location": "India",
    "job_type": "Full-time",
    "work_mode": "Remote",
    "salary": null,
    "description": "Data Science Intern (Remote)Company: Infrabyte ConsultingInternship Type: Full-TimeDuration: 1\u20133 MonthsStipend: \u20b915,500 per monthLocation: Remote (India)About the InternshipInfrabyte Consulting is looking for a Data Science Intern who is passionate about working with data and building analytical solutions. This internship offers hands-on exposure to real-world datasets, data analysis, and basic modeling techniques in a professional, remote environment.Key Responsibilities\u2022 Collect, clean, and preprocess structured and unstructured data\u2022 Perform exploratory data analysis (EDA) to identify trends and patterns\u2022 Assist in building and evaluating basic statistical or machine learning models\u2022 Create reports and visualizations to communicate insights\u2022 Work with Python and common data science libraries\u2022 Collaborate with team members on data-driven projectsRequired Skills & Qualifications\u2022 Basic understanding of data science and analytics concepts\u2022 Familiarity with Python and libraries such as Pandas, NumPy, or Matplotlib\u2022 Basic knowledge of statistics is a plus\u2022 Familiarity with Excel or Google Sheets\u2022 Strong analytical and problem-solving skills\u2022 Willingness to learn and experiment with data\u2022 Ability to work independently in a remote setupWho Can Apply\u2022 Students or recent graduates from any technical or analytical background\u2022 Freshers interested in data science or analytics\u2022 Candidates looking to gain hands-on experience with real datasets\u2022 Applicants available for a full-time internship (1\u20133 months)What You\u2019ll Gain\u2022 Hands-on experience with real-world data science projects\u2022 Exposure to industry-relevant tools and workflows\u2022 Monthly stipend of \u20b915,500\u2022 Remote work flexibility\u2022 Internship completion certificate\u2022 Opportunity to build a strong data science portfolio",
    "requirements": "Data Science Intern (Remote)Company: Infrabyte ConsultingInternship Type: Full-TimeDuration: 1\u20133 MonthsStipend: \u20b915,500 per monthLocation: Remote (India)About the InternshipInfrabyte Consulting is looking for a Data Science Intern who is passionate about working with data and building analytical solutions. This internship offers hands-on exposure to real-world datasets, data analysis, and basic modeling techniques in a professional, remote environment.Key Responsibilities\u2022 Collect, clean, and preprocess structured and unstructured data\u2022 Perform exploratory data analysis (EDA) to identify trends and patterns\u2022 Assist in building and evaluating basic statistical or machine learning models\u2022 Create reports and visualizations to communicate insights\u2022 Work with Python and common data science libraries\u2022 Collaborate with team members on data-driven projectsRequired Skills & Qualifications\u2022 Basic understanding of data science and analytics concepts\u2022 Familiarity with Python and libraries such as Pandas, NumPy, or Matplotlib\u2022 Basic knowledge of statistics is a plus\u2022 Familiarity with Excel or Google Sheets\u2022 Strong analytical and problem-solving skills\u2022 Willingness to learn and experiment with data\u2022 Ability to work independently in a remote setupWho Can Apply\u2022 Students or recent graduates from any technical or analytical background\u2022 Freshers interested in data science or analytics\u2022 Candidates looking to gain hands-on experience with real datasets\u2022 Applicants available for a full-time internship (1\u20133 months)What You\u2019ll Gain\u2022 Hands-on experience with real-world data science projects\u2022 Exposure to industry-relevant tools and workflows\u2022 Monthly stipend of \u20b915,500\u2022 Remote work flexibility\u2022 Internship completion certificate\u2022 Opportunity to build a strong data science portfolio",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/data-science-intern-at-infrabyte-consulting-4368152647?position=54&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=ha7uQuUI2wJ82b6%2BxhKkdQ%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:16:01.622779"
  },
  {
    "job_id": "linkedin_ai-data-engineer-location-hyderabad-bangalore-chennai-pune-at-digihelic-solutions-pvt-ltd-4357411087",
    "title": "AI -Data Engineer (Location: Hyderabad, Bangalore, Chennai, Pune)",
    "company": "DigiHelic Solutions Pvt. Ltd.",
    "location": "India",
    "job_type": "Full-time",
    "work_mode": "Not specified",
    "salary": null,
    "description": "AI -Data EngineerExperience: 15 YearsLocation: Hyderabad, Bangalore, Chenani, PuneMandatory Skills :AI Engineer, NLP, LLM, Generative AI,data science,cloud data engineering,etl,data pipelines,Must-Have SkillsSolid experience with AI/ML techniques, including deep learning, NLP, and LLMs / Generative AI.Proven experience delivering AI-driven and analytical solutions for real-world business problemsStrong proficiency in Python for data engineering, analytics, and machine learning.Hands-on experience with Snowflake for cloud data warehousing and analytics.Experience designing and building data pipelines using Azure Data Factory (ADF) or equivalent ETL/ELT tools..Strong understanding of enterprise data modeling, data quality, and scalable pipeline design.Experience implementing CI/CD pipelines for data and ML workflows using modern DevOps practices.Experience building dashboards using Tableau or Power BI.Experience working on cloud platforms (Azure preferred; AWS/GCP acceptable).Strong communication skills with the ability to translate technical concepts into business insights.",
    "requirements": "AI -Data EngineerExperience: 15 YearsLocation: Hyderabad, Bangalore, Chenani, PuneMandatory Skills :AI Engineer, NLP, LLM, Generative AI,data science,cloud data engineering,etl,data pipelines,Must-Have SkillsSolid experience with AI/ML techniques, including deep learning, NLP, and LLMs / Generative AI.Proven experience delivering AI-driven and analytical solutions for real-world business problemsStrong proficiency in Python for data engineering, analytics, and machine learning.Hands-on experience with Snowflake for cloud data warehousing and analytics.Experience designing and building data pipelines using Azure Data Factory (ADF) or equivalent ETL/ELT tools..Strong understanding of enterprise data modeling, data quality, and scalable pipeline design.Experience implementing CI/CD pipelines for data and ML workflows using modern DevOps practices.Experience building dashboards using Tableau or Power BI.Experience working on cloud platforms (Azure preferred; AWS/GCP acceptable).Strong communication skills with the ability to translate technical concepts into business insights.",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/ai-data-engineer-location-hyderabad-bangalore-chennai-pune-at-digihelic-solutions-pvt-ltd-4357411087?position=56&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=doLf6MC6pGKyZTe3iL%2BNXw%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:16:09.529458"
  },
  {
    "job_id": "linkedin_machine-learning-engineer-at-miq-4367736263",
    "title": "Machine Learning Engineer",
    "company": "MiQ",
    "location": "Bengaluru, Karnataka, India",
    "job_type": "Full-time",
    "work_mode": "Hybrid",
    "salary": null,
    "description": "Role: Machine Learning Engineer IILocation: BengaluruWe\u2019re MiQ, a global programmatic media partner for marketers and agencies.Our people are at the heart of everything we do, so you will be too. No matterthe role or the location, we\u2019re all united in the vision to lead the programmaticindustry and make it better.What you\u2019ll bring -2 - 4 years of hands-on experience deploying and monitoring Machine Learning Models in production. -Strong proficiency in Python and familiarity with distributed data processing frameworks like PySpark.-Excellent grasp of the basics of Machine Learning, Statistics and Probability. -Experience with building scalable ETL pipelines for efficient storage, processing and retrieval of features to support ML model development.-Experience building and deploying in production end to end model training, inferencing and retraining pipelines . -Experience with data and model monitoring to ensure consistency and reliability of solutions in production. -Familiarity with standard best practices like version control and CI / CD for code management, unit testing and quality code standards. -Experience working in cross functional teams, consisting of Data Scientists, Data Engineers and Product Managers to deliver quality solutions that meet business goals. -Passion for self driven learning and an eagerness to keep up with continuously evolving MLOps / LLMOps technologies and best practices. -Hands on experience with distributed data processing frameworks like Ray. -Hands on experience with designing and maintaining Feature Stores. Values:Our values are so much more than statements. They unite MiQers in every corner of the world. They shape the way we work and the decisions we make. And they inspire us to stay true to ourselves and to aim for better. Our values are there to be embraced by everyone, so that we naturally live and breathe them. Just like inclusivity, our values flow through everything we do - no matter how big or small.\u2022 We do what we love - Passion\u2022 We figure it out - Determination\u2022 We anticipate the unexpected - Agility\u2022 We always unite - Unite\u2022 We dare to be unconventional - CourageBenefitsEvery region and office have specific perks and benefits, but every person joining MiQ can expect:\u2022 A hybrid work environment\u2022 New hire orientation with job specific onboarding and training\u2022 Internal and global mobility opportunities\u2022 Competitive healthcare benefits\u2022 Bonus and performance incentives\u2022 Generous annual PTO paid parental leave, with two additional paid days to acknowledge holidays, cultural events, or inclusion initiatives.\u2022 Employee resource groups designed to connect people across all MiQ regions, drive action, and support our communities.Apply today!Equal Opportunity Employer",
    "requirements": "Role: Machine Learning Engineer IILocation: BengaluruWe\u2019re MiQ, a global programmatic media partner for marketers and agencies.Our people are at the heart of everything we do, so you will be too. No matterthe role or the location, we\u2019re all united in the vision to lead the programmaticindustry and make it better.What you\u2019ll bring -2 - 4 years of hands-on experience deploying and monitoring Machine Learning Models in production. -Strong proficiency in Python and familiarity with distributed data processing frameworks like PySpark.-Excellent grasp of the basics of Machine Learning, Statistics and Probability. -Experience with building scalable ETL pipelines for efficient storage, processing and retrieval of features to support ML model development.-Experience building and deploying in production end to end model training, inferencing and retraining pipelines . -Experience with data and model monitoring to ensure consistency and reliability of solutions in production. -Familiarity with standard best practices like version control and CI / CD for code management, unit testing and quality code standards. -Experience working in cross functional teams, consisting of Data Scientists, Data Engineers and Product Managers to deliver quality solutions that meet business goals. -Passion for self driven learning and an eagerness to keep up with continuously evolving MLOps / LLMOps technologies and best practices. -Hands on experience with distributed data processing frameworks like Ray. -Hands on experience with designing and maintaining Feature Stores. Values:Our values are so much more than statements. They unite MiQers in every corner of the world. They shape the way we work and the decisions we make. And they inspire us to stay true to ourselves and to aim for better. Our values are there to be embraced by everyone, so that we naturally live and breathe them. Just like inclusivity, our values flow through everything we do - no matter how big or small.\u2022 We do what we love - Passion\u2022 We figure it out - Determination\u2022 We anticipate the unexpected - Agility\u2022 We always unite - Unite\u2022 We dare to be unconventional - CourageBenefitsEvery region and office have specific perks and benefits, but every person joining MiQ can expect:\u2022 A hybrid work environment\u2022 New hire orientation with job specific onboarding and training\u2022 Internal and global mobility opportunities\u2022 Competitive healthcare benefits\u2022 Bonus and performance incentives\u2022 Generous annual PTO paid parental leave, with two additional paid days to acknowledge holidays, cultural events, or inclusion initiatives.\u2022 Employee resource groups designed to connect people across all MiQ regions, drive action, and support our communities.Apply today!Equal Opportunity Employer",
    "posted_date": "2026-02-01",
    "apply_url": "https://in.linkedin.com/jobs/view/machine-learning-engineer-at-miq-4367736263?position=57&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=kq0yADLrwdsOabEe5dUjzQ%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:16:12.960684"
  },
  {
    "job_id": "linkedin_data-science-intern-at-webboost-solution-it-services-4368150794",
    "title": "Data Science Intern",
    "company": "WEBBOOST SOLUTION IT SERVICES",
    "location": "India",
    "job_type": "Full-time",
    "work_mode": "Remote",
    "salary": null,
    "description": "Data Science Intern (Paid)Company: WebBoost IT ServicesLocation: RemoteDuration: 3 Months\ud83d\udcc5 Application Deadline: 03rd February 2026Opportunity & Benefits\ud83d\udcb0 Performance-based stipend up to \u20b97,499\ud83c\udf81 Swags and goodies\ud83d\udcdc Certificate of Internship\u2709\ufe0f Letter of Recommendation (based on performance)\ud83c\udf1f Potential full-time role based on performance\ud83d\udcca Hands-on experience with real-world data science projectsAbout WebBoost IT ServicesWebBoost IT Services provides aspiring data professionals with practical, hands-on exposure to data science through real-world projects and structured mentorship. The internship focuses on building strong analytical, statistical, and machine learning skills essential for success in the data industry.Roles & ResponsibilitiesCollect, clean, preprocess, and analyze large datasetsPerform Exploratory Data Analysis (EDA) to extract meaningful insightsDevelop predictive models and machine learning algorithmsCreate data visualizations and dashboards to communicate findingsCollaborate with cross-functional teams to deliver data-driven solutions and recommendationsRequirementsCurrently enrolled in or graduated from Data Science, Computer Science, Statistics, or related fieldsProficiency in Python for data analysis and machine learningFamiliarity with machine learning libraries such as scikit-learn, TensorFlow, or PyTorch (preferred)Experience with data visualization tools like Tableau, Power BI, or MatplotlibStrong analytical, critical thinking, and problem-solving abilitiesGood communication and teamwork skillsWhat You Will GainHands-on experience working on real-world data science projectsPerformance-based stipend up to \u20b97,499Swags and goodiesCertificate of Internship upon completionLetter of Recommendation based on performanceOpportunity to build a strong professional portfolioPotential full-time role based on performanceHow to ApplySend your resume and cover letter with the subject line:\u201cData Science Intern Application \u2013 WebBoost IT Services\u201dEqual Opportunity StatementWebBoost IT Services is an equal opportunity organization and is committed to fostering a diverse, inclusive, and growth-oriented work environment.",
    "requirements": "Data Science Intern (Paid)Company: WebBoost IT ServicesLocation: RemoteDuration: 3 Months\ud83d\udcc5 Application Deadline: 03rd February 2026Opportunity & Benefits\ud83d\udcb0 Performance-based stipend up to \u20b97,499\ud83c\udf81 Swags and goodies\ud83d\udcdc Certificate of Internship\u2709\ufe0f Letter of Recommendation (based on performance)\ud83c\udf1f Potential full-time role based on performance\ud83d\udcca Hands-on experience with real-world data science projectsAbout WebBoost IT ServicesWebBoost IT Services provides aspiring data professionals with practical, hands-on exposure to data science through real-world projects and structured mentorship. The internship focuses on building strong analytical, statistical, and machine learning skills essential for success in the data industry.Roles & ResponsibilitiesCollect, clean, preprocess, and analyze large datasetsPerform Exploratory Data Analysis (EDA) to extract meaningful insightsDevelop predictive models and machine learning algorithmsCreate data visualizations and dashboards to communicate findingsCollaborate with cross-functional teams to deliver data-driven solutions and recommendationsRequirementsCurrently enrolled in or graduated from Data Science, Computer Science, Statistics, or related fieldsProficiency in Python for data analysis and machine learningFamiliarity with machine learning libraries such as scikit-learn, TensorFlow, or PyTorch (preferred)Experience with data visualization tools like Tableau, Power BI, or MatplotlibStrong analytical, critical thinking, and problem-solving abilitiesGood communication and teamwork skillsWhat You Will GainHands-on experience working on real-world data science projectsPerformance-based stipend up to \u20b97,499Swags and goodiesCertificate of Internship upon completionLetter of Recommendation based on performanceOpportunity to build a strong professional portfolioPotential full-time role based on performanceHow to ApplySend your resume and cover letter with the subject line:\u201cData Science Intern Application \u2013 WebBoost IT Services\u201dEqual Opportunity StatementWebBoost IT Services is an equal opportunity organization and is committed to fostering a diverse, inclusive, and growth-oriented work environment.",
    "posted_date": "2026-02-02",
    "apply_url": "https://in.linkedin.com/jobs/view/data-science-intern-at-webboost-solution-it-services-4368150794?position=59&pageNum=0&refId=qiu20FyxKHAs2Sfr7Tx0JQ%3D%3D&trackingId=t00SrOB7wga1d1pnPpx5mw%3D%3D",
    "source": "linkedin",
    "scraped_at": "2026-02-02 12:16:20.851207"
  }
]